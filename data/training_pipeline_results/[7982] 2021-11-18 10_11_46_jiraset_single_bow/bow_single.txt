USING:

{'cpu_count': -1,
 'random_seed': 1,
 'training_path': 'LSST_Data_Management_issues_cleaned_more_balanced.csv',
 'variables': {'base_fields': ['points', 'sprint_count']},
 'verbosity': 4,
 'y_column': 'status'}




Fitting 3 folds for each of 160 candidates, totalling 480 fits
[CV 1/3] END algorithm=auto, n_neighbors=2, weights=distance;, score=0.627 total time=   8.2s
[CV 1/3] END algorithm=auto, n_neighbors=4, weights=uniform;, score=0.656 total time=   8.1s
[CV 2/3] END algorithm=auto, n_neighbors=6, weights=distance;, score=0.613 total time=   7.6s
[CV 2/3] END algorithm=auto, n_neighbors=9, weights=uniform;, score=0.656 total time=   7.8s
[CV 3/3] END algorithm=auto, n_neighbors=11, weights=distance;, score=0.649 total time=   7.6s
[CV 1/3] END algorithm=auto, n_neighbors=14, weights=distance;, score=0.664 total time=   7.6s
[CV 2/3] END algorithm=auto, n_neighbors=17, weights=uniform;, score=0.644 total time=   7.6s
[CV 3/3] END algorithm=auto, n_neighbors=19, weights=distance;, score=0.663 total time=   7.6s
[CV 1/3] END algorithm=ball_tree, n_neighbors=2, weights=distance;, score=0.627 total time= 1.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=5, weights=distance;, score=0.599 total time= 1.4min
[CV 3/3] END algorithm=ball_tree, n_neighbors=7, weights=distance;, score=0.636 total time= 1.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=10, weights=distance;, score=0.644 total time= 1.4min
[CV 3/3] END algorithm=ball_tree, n_neighbors=12, weights=distance;, score=0.654 total time= 1.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=15, weights=distance;, score=0.642 total time= 1.4min
[CV 2/3] END algorithm=ball_tree, n_neighbors=18, weights=uniform;, score=0.658 total time= 1.4min
[CV 1/3] END algorithm=ball_tree, n_neighbors=20, weights=distance;, score=0.663 total time= 1.3min
[CV 3/3] END algorithm=kd_tree, n_neighbors=2, weights=distance;, score=0.613 total time= 2.0min
[CV 2/3] END algorithm=kd_tree, n_neighbors=5, weights=uniform;, score=0.638 total time= 2.3min
[CV 1/3] END algorithm=kd_tree, n_neighbors=8, weights=uniform;, score=0.661 total time= 2.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=10, weights=distance;, score=0.644 total time= 2.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=13, weights=uniform;, score=0.652 total time= 2.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=16, weights=uniform;, score=0.662 total time= 2.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=18, weights=distance;, score=0.657 total time= 2.4min
[CV 1/3] END algorithm=brute, n_neighbors=1, weights=distance;, score=0.627 total time=   5.8s
[CV 2/3] END algorithm=brute, n_neighbors=2, weights=uniform;, score=0.617 total time=   5.9s
[CV 3/3] END algorithm=brute, n_neighbors=2, weights=distance;, score=0.613 total time=   5.8s
[CV 1/3] END algorithm=brute, n_neighbors=4, weights=uniform;, score=0.656 total time=   6.0s
[CV 3/3] END algorithm=brute, n_neighbors=4, weights=distance;, score=0.635 total time=   6.0s
[CV 1/3] END algorithm=brute, n_neighbors=6, weights=uniform;, score=0.658 total time=   6.0s
[CV 1/3] END algorithm=brute, n_neighbors=7, weights=distance;, score=0.662 total time=   6.0s
[CV 3/3] END algorithm=brute, n_neighbors=8, weights=distance;, score=0.652 total time=   6.0s
[CV 1/3] END algorithm=brute, n_neighbors=10, weights=uniform;, score=0.660 total time=   6.0s
[CV 1/3] END algorithm=brute, n_neighbors=11, weights=distance;, score=0.665 total time=   5.9s
[CV 3/3] END algorithm=brute, n_neighbors=13, weights=uniform;, score=0.652 total time=   6.0s
[CV 2/3] END algorithm=brute, n_neighbors=15, weights=uniform;, score=0.647 total time=   7.5s
[CV 3/3] END algorithm=brute, n_neighbors=17, weights=uniform;, score=0.658 total time=   7.7s
[CV 2/3] END algorithm=brute, n_neighbors=19, weights=distance;, score=0.654 total time=   7.6s
[CV 3/3] END class_weight=balanced, gamma=scale, kernel=poly;, score=0.673 total time=20.0min
[CV 1/3] END class_weight=None, gamma=scale, kernel=sigmoid;, score=0.667 total time=12.4min
[CV 1/3] END class_weight=None, gamma=auto, kernel=sigmoid;, score=0.657 total time=10.4min
[CV 1/3] END algorithm=auto, n_neighbors=1, weights=distance;, score=0.627 total time=   8.3s
[CV 2/3] END algorithm=auto, n_neighbors=4, weights=uniform;, score=0.603 total time=   8.2s
[CV 3/3] END algorithm=auto, n_neighbors=6, weights=distance;, score=0.641 total time=   7.9s
[CV 1/3] END algorithm=auto, n_neighbors=9, weights=distance;, score=0.664 total time=   7.6s
[CV 2/3] END algorithm=auto, n_neighbors=12, weights=uniform;, score=0.648 total time=   7.7s
[CV 3/3] END algorithm=auto, n_neighbors=14, weights=distance;, score=0.658 total time=   7.6s
[CV 1/3] END algorithm=auto, n_neighbors=17, weights=distance;, score=0.662 total time=   7.6s
[CV 2/3] END algorithm=auto, n_neighbors=20, weights=uniform;, score=0.657 total time=   7.7s
[CV 2/3] END algorithm=ball_tree, n_neighbors=2, weights=distance;, score=0.540 total time= 1.4min
[CV 1/3] END algorithm=ball_tree, n_neighbors=5, weights=uniform;, score=0.662 total time= 1.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=7, weights=distance;, score=0.623 total time= 1.4min
[CV 2/3] END algorithm=ball_tree, n_neighbors=10, weights=uniform;, score=0.649 total time= 1.4min
[CV 2/3] END algorithm=ball_tree, n_neighbors=12, weights=distance;, score=0.644 total time= 1.4min
[CV 2/3] END algorithm=ball_tree, n_neighbors=15, weights=uniform;, score=0.647 total time= 1.4min
[CV 1/3] END algorithm=ball_tree, n_neighbors=17, weights=distance;, score=0.662 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=20, weights=uniform;, score=0.661 total time= 1.3min
[CV 1/3] END algorithm=kd_tree, n_neighbors=2, weights=distance;, score=0.627 total time= 2.0min
[CV 3/3] END algorithm=kd_tree, n_neighbors=5, weights=uniform;, score=0.626 total time= 2.3min
[CV 3/3] END algorithm=kd_tree, n_neighbors=7, weights=distance;, score=0.636 total time= 2.3min
[CV 3/3] END algorithm=kd_tree, n_neighbors=10, weights=uniform;, score=0.647 total time= 2.3min
[CV 1/3] END algorithm=kd_tree, n_neighbors=13, weights=uniform;, score=0.660 total time= 2.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=15, weights=distance;, score=0.642 total time= 2.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=18, weights=uniform;, score=0.657 total time= 2.4min
[CV 1/3] END algorithm=brute, n_neighbors=1, weights=uniform;, score=0.627 total time=   5.8s
[CV 3/3] END algorithm=brute, n_neighbors=1, weights=uniform;, score=0.613 total time=   5.8s
[CV 1/3] END algorithm=brute, n_neighbors=2, weights=uniform;, score=0.658 total time=   5.9s
[CV 2/3] END algorithm=brute, n_neighbors=2, weights=distance;, score=0.540 total time=   5.8s
[CV 3/3] END algorithm=brute, n_neighbors=3, weights=distance;, score=0.612 total time=   5.9s
[CV 1/3] END algorithm=brute, n_neighbors=4, weights=distance;, score=0.652 total time=   6.0s
[CV 3/3] END algorithm=brute, n_neighbors=5, weights=distance;, score=0.620 total time=   6.0s
[CV 3/3] END algorithm=brute, n_neighbors=7, weights=uniform;, score=0.637 total time=   6.0s
[CV 2/3] END algorithm=brute, n_neighbors=8, weights=distance;, score=0.620 total time=   6.0s
[CV 2/3] END algorithm=brute, n_neighbors=9, weights=distance;, score=0.629 total time=   5.9s
[CV 3/3] END algorithm=brute, n_neighbors=11, weights=uniform;, score=0.652 total time=   6.0s
[CV 2/3] END algorithm=brute, n_neighbors=13, weights=uniform;, score=0.650 total time=   6.0s
[CV 3/3] END algorithm=brute, n_neighbors=14, weights=distance;, score=0.658 total time=   6.0s
[CV 1/3] END algorithm=brute, n_neighbors=16, weights=distance;, score=0.665 total time=   6.0s
[CV 1/3] END algorithm=brute, n_neighbors=18, weights=distance;, score=0.659 total time=   6.0s
[CV 2/3] END algorithm=brute, n_neighbors=20, weights=distance;, score=0.657 total time=   6.7s
[CV 1/3] END class_weight=balanced, gamma=auto, kernel=sigmoid;, score=0.657 total time=20.7min
[CV 2/3] END class_weight=None, gamma=scale, kernel=linear;, score=0.631 total time=13.2min
[CV 2/3] END class_weight=None, gamma=auto, kernel=sigmoid;, score=0.658 total time=10.5min
[CV 1/3] END algorithm=auto, n_neighbors=3, weights=distance;, score=0.648 total time=   8.2s
[CV 2/3] END algorithm=auto, n_neighbors=5, weights=uniform;, score=0.638 total time=   8.3s
[CV 2/3] END algorithm=auto, n_neighbors=7, weights=distance;, score=0.623 total time=   7.8s
[CV 3/3] END algorithm=auto, n_neighbors=9, weights=distance;, score=0.646 total time=   7.7s
[CV 1/3] END algorithm=auto, n_neighbors=12, weights=distance;, score=0.661 total time=   7.7s
[CV 1/3] END algorithm=auto, n_neighbors=15, weights=uniform;, score=0.660 total time=   7.8s
[CV 3/3] END algorithm=auto, n_neighbors=17, weights=distance;, score=0.667 total time=   7.6s
[CV 1/3] END algorithm=auto, n_neighbors=20, weights=distance;, score=0.663 total time=   7.7s
[CV 1/3] END algorithm=ball_tree, n_neighbors=3, weights=uniform;, score=0.658 total time= 1.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=5, weights=distance;, score=0.664 total time= 1.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=8, weights=distance;, score=0.620 total time= 1.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=11, weights=uniform;, score=0.662 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=13, weights=distance;, score=0.657 total time= 1.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=16, weights=distance;, score=0.665 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=19, weights=uniform;, score=0.660 total time= 1.5min
[CV 1/3] END algorithm=kd_tree, n_neighbors=2, weights=uniform;, score=0.658 total time= 2.1min
[CV 2/3] END algorithm=kd_tree, n_neighbors=4, weights=distance;, score=0.592 total time= 2.3min
[CV 3/3] END algorithm=kd_tree, n_neighbors=7, weights=uniform;, score=0.637 total time= 2.3min
[CV 1/3] END algorithm=kd_tree, n_neighbors=10, weights=uniform;, score=0.660 total time= 2.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=12, weights=distance;, score=0.644 total time= 2.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=15, weights=uniform;, score=0.654 total time= 2.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=18, weights=uniform;, score=0.659 total time= 2.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=20, weights=distance;, score=0.657 total time= 2.7min
[CV 3/3] END class_weight=balanced, gamma=auto, kernel=sigmoid;, score=0.220 total time=20.7min
[CV 1/3] END class_weight=None, gamma=scale, kernel=linear;, score=0.623 total time=13.5min
[CV 3/3] END class_weight=None, gamma=auto, kernel=sigmoid;, score=0.658 total time=10.4min
[CV 1/3] END algorithm=auto, n_neighbors=1, weights=uniform;, score=0.627 total time=   8.4s
[CV 3/3] END algorithm=auto, n_neighbors=4, weights=distance;, score=0.635 total time=   8.4s
[CV 3/3] END algorithm=auto, n_neighbors=8, weights=uniform;, score=0.647 total time=   8.4s
[CV 1/3] END algorithm=auto, n_neighbors=11, weights=uniform;, score=0.662 total time=   8.1s
[CV 1/3] END algorithm=auto, n_neighbors=13, weights=distance;, score=0.663 total time=   7.8s
[CV 3/3] END algorithm=auto, n_neighbors=15, weights=distance;, score=0.662 total time=   7.8s
[CV 1/3] END algorithm=auto, n_neighbors=18, weights=distance;, score=0.659 total time=   7.8s
[CV 2/3] END algorithm=ball_tree, n_neighbors=1, weights=uniform;, score=0.539 total time= 1.4min
[CV 2/3] END algorithm=ball_tree, n_neighbors=3, weights=distance;, score=0.569 total time= 1.4min
[CV 3/3] END algorithm=ball_tree, n_neighbors=6, weights=uniform;, score=0.636 total time= 1.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=9, weights=uniform;, score=0.660 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=11, weights=distance;, score=0.649 total time= 1.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=14, weights=distance;, score=0.652 total time= 1.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=17, weights=uniform;, score=0.645 total time= 1.4min
[CV 2/3] END algorithm=ball_tree, n_neighbors=19, weights=distance;, score=0.653 total time= 1.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=2, weights=uniform;, score=0.656 total time= 2.0min
[CV 1/3] END algorithm=kd_tree, n_neighbors=5, weights=uniform;, score=0.662 total time= 2.3min
[CV 2/3] END algorithm=kd_tree, n_neighbors=7, weights=distance;, score=0.623 total time= 2.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=10, weights=distance;, score=0.661 total time= 2.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=13, weights=uniform;, score=0.650 total time= 2.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=15, weights=distance;, score=0.662 total time= 2.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=18, weights=distance;, score=0.659 total time= 2.4min
[CV 2/3] END algorithm=brute, n_neighbors=1, weights=uniform;, score=0.539 total time=   5.8s
[CV 2/3] END algorithm=brute, n_neighbors=1, weights=distance;, score=0.539 total time=   5.8s
[CV 3/3] END algorithm=brute, n_neighbors=2, weights=uniform;, score=0.656 total time=   5.9s
[CV 3/3] END algorithm=brute, n_neighbors=3, weights=uniform;, score=0.624 total time=   7.4s
[CV 2/3] END algorithm=brute, n_neighbors=4, weights=distance;, score=0.592 total time=   7.7s
[CV 2/3] END algorithm=brute, n_neighbors=6, weights=uniform;, score=0.635 total time=   7.7s
[CV 3/3] END algorithm=brute, n_neighbors=7, weights=distance;, score=0.636 total time=   7.5s
[CV 1/3] END algorithm=brute, n_neighbors=9, weights=distance;, score=0.664 total time=   7.5s
[CV 2/3] END algorithm=brute, n_neighbors=11, weights=distance;, score=0.639 total time=   7.5s
[CV 1/3] END algorithm=brute, n_neighbors=13, weights=distance;, score=0.663 total time=   7.5s
[CV 1/3] END algorithm=brute, n_neighbors=16, weights=uniform;, score=0.662 total time=   7.6s
[CV 3/3] END algorithm=brute, n_neighbors=18, weights=uniform;, score=0.657 total time=   7.6s
[CV 3/3] END algorithm=brute, n_neighbors=20, weights=distance;, score=0.665 total time=   4.7s
[CV 2/3] END class_weight=balanced, gamma=scale, kernel=rbf;, score=0.619 total time=21.3min
[CV 3/3] END class_weight=None, gamma=scale, kernel=linear;, score=0.616 total time=13.5min
[CV 2/3] END class_weight=None, gamma=auto, kernel=linear;, score=0.631 total time=10.8min
[CV 2/3] END algorithm=auto, n_neighbors=3, weights=uniform;, score=0.613 total time=   8.4s
[CV 3/3] END algorithm=auto, n_neighbors=5, weights=distance;, score=0.620 total time=   8.1s
[CV 1/3] END algorithm=auto, n_neighbors=7, weights=uniform;, score=0.661 total time=   7.9s
[CV 2/3] END algorithm=auto, n_neighbors=9, weights=distance;, score=0.629 total time=   7.7s
[CV 3/3] END algorithm=auto, n_neighbors=12, weights=uniform;, score=0.651 total time=   7.8s
[CV 2/3] END algorithm=auto, n_neighbors=15, weights=uniform;, score=0.647 total time=   7.8s
[CV 2/3] END algorithm=auto, n_neighbors=17, weights=distance;, score=0.646 total time=   7.6s
[CV 3/3] END algorithm=auto, n_neighbors=20, weights=uniform;, score=0.661 total time=   7.8s
[CV 2/3] END algorithm=ball_tree, n_neighbors=3, weights=uniform;, score=0.613 total time= 1.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=5, weights=uniform;, score=0.638 total time= 1.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=8, weights=uniform;, score=0.661 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=10, weights=distance;, score=0.648 total time= 1.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=13, weights=distance;, score=0.643 total time= 1.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=16, weights=uniform;, score=0.651 total time= 1.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=18, weights=distance;, score=0.659 total time= 1.5min
[CV 3/3] END algorithm=kd_tree, n_neighbors=1, weights=uniform;, score=0.613 total time= 1.7min
[CV 3/3] END algorithm=kd_tree, n_neighbors=3, weights=distance;, score=0.612 total time= 2.2min
[CV 3/3] END algorithm=kd_tree, n_neighbors=6, weights=uniform;, score=0.636 total time= 2.3min
[CV 1/3] END algorithm=kd_tree, n_neighbors=9, weights=uniform;, score=0.660 total time= 2.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=11, weights=distance;, score=0.639 total time= 2.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=14, weights=uniform;, score=0.655 total time= 2.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=17, weights=uniform;, score=0.658 total time= 2.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=19, weights=distance;, score=0.653 total time= 2.4min
[CV 3/3] END algorithm=brute, n_neighbors=6, weights=distance;, score=0.641 total time=   6.0s
[CV 2/3] END algorithm=brute, n_neighbors=7, weights=distance;, score=0.623 total time=   6.0s
[CV 2/3] END algorithm=brute, n_neighbors=9, weights=uniform;, score=0.656 total time=   6.0s
[CV 1/3] END algorithm=brute, n_neighbors=11, weights=uniform;, score=0.662 total time=   6.0s
[CV 2/3] END algorithm=brute, n_neighbors=12, weights=distance;, score=0.644 total time=   6.0s
[CV 3/3] END algorithm=brute, n_neighbors=13, weights=distance;, score=0.657 total time=   6.0s
[CV 3/3] END algorithm=brute, n_neighbors=15, weights=distance;, score=0.662 total time=   6.0s
[CV 3/3] END algorithm=brute, n_neighbors=17, weights=distance;, score=0.667 total time=   6.0s
[CV 1/3] END algorithm=brute, n_neighbors=19, weights=uniform;, score=0.660 total time=   6.0s
[CV 3/3] END class_weight=balanced, gamma=scale, kernel=sigmoid;, score=0.506 total time=16.5min
[CV 3/3] END class_weight=balanced, gamma=auto, kernel=poly;, score=0.220 total time=20.2min
[CV 1/3] END class_weight=None, gamma=auto, kernel=poly;, score=0.657 total time= 9.0min
[CV 3/3] END algorithm=auto, n_neighbors=1, weights=uniform;, score=0.613 total time=   8.3s
[CV 1/3] END algorithm=auto, n_neighbors=4, weights=distance;, score=0.652 total time=   8.3s
[CV 1/3] END algorithm=auto, n_neighbors=7, weights=distance;, score=0.662 total time=   8.3s
[CV 2/3] END algorithm=auto, n_neighbors=10, weights=uniform;, score=0.649 total time=   8.2s
[CV 2/3] END algorithm=auto, n_neighbors=13, weights=uniform;, score=0.650 total time=   8.2s
[CV 1/3] END algorithm=auto, n_neighbors=16, weights=uniform;, score=0.662 total time=   8.2s
[CV 2/3] END algorithm=auto, n_neighbors=18, weights=distance;, score=0.657 total time=   8.1s
[CV 3/3] END algorithm=ball_tree, n_neighbors=1, weights=uniform;, score=0.613 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=4, weights=uniform;, score=0.647 total time= 1.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=7, weights=uniform;, score=0.649 total time= 1.4min
[CV 1/3] END algorithm=ball_tree, n_neighbors=9, weights=distance;, score=0.664 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=12, weights=uniform;, score=0.651 total time= 1.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=15, weights=uniform;, score=0.660 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=17, weights=distance;, score=0.667 total time= 1.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=20, weights=distance;, score=0.657 total time= 1.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=3, weights=uniform;, score=0.624 total time= 2.1min
[CV 1/3] END algorithm=kd_tree, n_neighbors=5, weights=distance;, score=0.664 total time= 2.3min
[CV 3/3] END algorithm=kd_tree, n_neighbors=8, weights=uniform;, score=0.647 total time= 2.3min
[CV 3/3] END algorithm=kd_tree, n_neighbors=10, weights=distance;, score=0.648 total time= 2.3min
[CV 1/3] END algorithm=kd_tree, n_neighbors=13, weights=distance;, score=0.663 total time= 2.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=16, weights=uniform;, score=0.651 total time= 2.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=18, weights=distance;, score=0.660 total time= 2.4min
[CV 3/3] END algorithm=brute, n_neighbors=1, weights=distance;, score=0.613 total time=   5.8s
[CV 1/3] END algorithm=brute, n_neighbors=2, weights=distance;, score=0.627 total time=   5.8s
[CV 2/3] END algorithm=brute, n_neighbors=3, weights=uniform;, score=0.613 total time=   8.0s
[CV 1/3] END algorithm=brute, n_neighbors=5, weights=uniform;, score=0.662 total time=   8.1s
[CV 1/3] END algorithm=brute, n_neighbors=6, weights=distance;, score=0.659 total time=   8.0s
[CV 2/3] END algorithm=brute, n_neighbors=8, weights=uniform;, score=0.633 total time=   8.0s
[CV 2/3] END algorithm=brute, n_neighbors=10, weights=uniform;, score=0.649 total time=   8.0s
[CV 3/3] END algorithm=brute, n_neighbors=12, weights=uniform;, score=0.651 total time=   8.1s
[CV 1/3] END algorithm=brute, n_neighbors=14, weights=distance;, score=0.664 total time=   8.1s
[CV 3/3] END algorithm=brute, n_neighbors=16, weights=distance;, score=0.659 total time=   8.1s
[CV 2/3] END algorithm=brute, n_neighbors=19, weights=uniform;, score=0.654 total time=   7.6s
[CV 3/3] END class_weight=balanced, gamma=scale, kernel=linear;, score=0.550 total time=14.2min
[CV 2/3] END class_weight=balanced, gamma=auto, kernel=linear;, score=0.557 total time=14.6min
[CV 3/3] END class_weight=None, gamma=scale, kernel=poly;, score=0.672 total time=17.8min
[CV 3/3] END algorithm=auto, n_neighbors=3, weights=uniform;, score=0.624 total time=   8.4s
[CV 2/3] END algorithm=auto, n_neighbors=6, weights=uniform;, score=0.635 total time=   8.1s
[CV 3/3] END algorithm=auto, n_neighbors=7, weights=uniform;, score=0.637 total time=   8.0s
[CV 1/3] END algorithm=auto, n_neighbors=10, weights=uniform;, score=0.660 total time=   7.8s
[CV 2/3] END algorithm=auto, n_neighbors=12, weights=distance;, score=0.644 total time=   7.7s
[CV 3/3] END algorithm=auto, n_neighbors=15, weights=uniform;, score=0.654 total time=   7.8s
[CV 1/3] END algorithm=auto, n_neighbors=18, weights=uniform;, score=0.659 total time=   7.7s
[CV 2/3] END algorithm=auto, n_neighbors=20, weights=distance;, score=0.657 total time=   7.6s
[CV 3/3] END algorithm=ball_tree, n_neighbors=3, weights=uniform;, score=0.624 total time= 1.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=6, weights=uniform;, score=0.635 total time= 1.4min
[CV 3/3] END algorithm=ball_tree, n_neighbors=8, weights=uniform;, score=0.647 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=11, weights=uniform;, score=0.652 total time= 1.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=14, weights=uniform;, score=0.666 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=16, weights=distance;, score=0.659 total time= 1.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=19, weights=distance;, score=0.663 total time= 1.5min
[CV 2/3] END algorithm=kd_tree, n_neighbors=2, weights=uniform;, score=0.617 total time= 2.2min
[CV 3/3] END algorithm=kd_tree, n_neighbors=4, weights=distance;, score=0.635 total time= 2.2min
[CV 1/3] END algorithm=kd_tree, n_neighbors=7, weights=distance;, score=0.662 total time= 2.3min
[CV 2/3] END algorithm=kd_tree, n_neighbors=10, weights=uniform;, score=0.649 total time= 2.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=12, weights=distance;, score=0.654 total time= 2.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=15, weights=distance;, score=0.663 total time= 2.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=18, weights=uniform;, score=0.658 total time= 2.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=20, weights=distance;, score=0.665 total time= 2.6min
[CV 1/3] END class_weight=balanced, gamma=auto, kernel=linear;, score=0.569 total time=15.1min
[CV 2/3] END class_weight=balanced, gamma=auto, kernel=poly;, score=0.220 total time=20.7min
[CV 3/3] END class_weight=None, gamma=auto, kernel=linear;, score=0.616 total time=11.1min
[CV 1/3] END algorithm=auto, n_neighbors=3, weights=uniform;, score=0.658 total time=   8.4s
[CV 1/3] END algorithm=auto, n_neighbors=6, weights=uniform;, score=0.658 total time=   8.4s
[CV 3/3] END algorithm=auto, n_neighbors=8, weights=distance;, score=0.652 total time=   8.3s
[CV 2/3] END algorithm=auto, n_neighbors=11, weights=uniform;, score=0.646 total time=   8.4s
[CV 3/3] END algorithm=auto, n_neighbors=13, weights=distance;, score=0.657 total time=   8.2s
[CV 1/3] END algorithm=auto, n_neighbors=16, weights=distance;, score=0.665 total time=   8.1s
[CV 2/3] END algorithm=auto, n_neighbors=19, weights=uniform;, score=0.654 total time=   8.3s
[CV 3/3] END algorithm=ball_tree, n_neighbors=1, weights=distance;, score=0.613 total time= 1.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=4, weights=distance;, score=0.592 total time= 1.4min
[CV 1/3] END algorithm=ball_tree, n_neighbors=7, weights=uniform;, score=0.661 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=9, weights=distance;, score=0.646 total time= 1.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=12, weights=distance;, score=0.661 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=15, weights=uniform;, score=0.654 total time= 1.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=18, weights=uniform;, score=0.659 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=20, weights=distance;, score=0.665 total time= 1.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=3, weights=distance;, score=0.648 total time= 2.2min
[CV 1/3] END algorithm=kd_tree, n_neighbors=6, weights=uniform;, score=0.658 total time= 2.3min
[CV 2/3] END algorithm=kd_tree, n_neighbors=8, weights=distance;, score=0.620 total time= 2.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=11, weights=uniform;, score=0.652 total time= 2.3min
[CV 1/3] END algorithm=kd_tree, n_neighbors=14, weights=uniform;, score=0.666 total time= 2.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=16, weights=distance;, score=0.649 total time= 2.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=19, weights=uniform;, score=0.660 total time= 2.4min
[CV 1/3] END algorithm=brute, n_neighbors=3, weights=uniform;, score=0.658 total time=   6.0s
[CV 3/3] END algorithm=brute, n_neighbors=4, weights=uniform;, score=0.647 total time=   7.6s
[CV 2/3] END algorithm=brute, n_neighbors=5, weights=distance;, score=0.599 total time=   7.6s
[CV 2/3] END algorithm=brute, n_neighbors=7, weights=uniform;, score=0.649 total time=   7.6s
[CV 1/3] END algorithm=brute, n_neighbors=9, weights=uniform;, score=0.660 total time=   7.7s
[CV 3/3] END algorithm=brute, n_neighbors=10, weights=distance;, score=0.648 total time=   7.5s
[CV 1/3] END algorithm=brute, n_neighbors=13, weights=uniform;, score=0.660 total time=   7.6s
[CV 1/3] END algorithm=brute, n_neighbors=15, weights=uniform;, score=0.660 total time=   7.6s
[CV 2/3] END algorithm=brute, n_neighbors=17, weights=uniform;, score=0.644 total time=   7.7s
[CV 1/3] END algorithm=brute, n_neighbors=19, weights=distance;, score=0.663 total time=   6.8s
[CV 1/3] END class_weight=balanced, gamma=scale, kernel=linear;, score=0.569 total time=15.1min
[CV 1/3] END class_weight=balanced, gamma=auto, kernel=poly;, score=0.657 total time=19.6min
[CV 1/3] END class_weight=None, gamma=auto, kernel=linear;, score=0.623 total time=12.3min
[CV 3/3] END algorithm=auto, n_neighbors=2, weights=uniform;, score=0.656 total time=   8.4s
[CV 1/3] END algorithm=auto, n_neighbors=5, weights=distance;, score=0.664 total time=   8.3s
[CV 1/3] END algorithm=auto, n_neighbors=8, weights=uniform;, score=0.661 total time=   8.4s
[CV 2/3] END algorithm=auto, n_neighbors=10, weights=distance;, score=0.644 total time=   8.1s
[CV 3/3] END algorithm=auto, n_neighbors=13, weights=uniform;, score=0.652 total time=   8.3s
[CV 2/3] END algorithm=auto, n_neighbors=16, weights=uniform;, score=0.651 total time=   8.2s
[CV 3/3] END algorithm=auto, n_neighbors=18, weights=distance;, score=0.660 total time=   8.1s
[CV 1/3] END algorithm=ball_tree, n_neighbors=1, weights=distance;, score=0.627 total time= 1.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=4, weights=uniform;, score=0.603 total time= 1.4min
[CV 1/3] END algorithm=ball_tree, n_neighbors=6, weights=distance;, score=0.659 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=9, weights=uniform;, score=0.647 total time= 1.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=12, weights=uniform;, score=0.648 total time= 1.4min
[CV 1/3] END algorithm=ball_tree, n_neighbors=14, weights=distance;, score=0.664 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=17, weights=uniform;, score=0.658 total time= 1.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=20, weights=uniform;, score=0.657 total time= 1.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=2, weights=distance;, score=0.540 total time= 2.2min
[CV 2/3] END algorithm=kd_tree, n_neighbors=5, weights=distance;, score=0.599 total time= 2.3min
[CV 1/3] END algorithm=kd_tree, n_neighbors=8, weights=distance;, score=0.662 total time= 2.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=11, weights=uniform;, score=0.646 total time= 2.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=13, weights=distance;, score=0.657 total time= 2.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=16, weights=distance;, score=0.665 total time= 2.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=19, weights=uniform;, score=0.654 total time= 2.5min
[CV 1/3] END algorithm=brute, n_neighbors=3, weights=distance;, score=0.648 total time=   8.0s
[CV 2/3] END algorithm=brute, n_neighbors=5, weights=uniform;, score=0.638 total time=   7.8s
[CV 3/3] END algorithm=brute, n_neighbors=6, weights=uniform;, score=0.636 total time=   7.7s
[CV 1/3] END algorithm=brute, n_neighbors=8, weights=uniform;, score=0.661 total time=   7.8s
[CV 3/3] END algorithm=brute, n_neighbors=9, weights=distance;, score=0.646 total time=   7.6s
[CV 3/3] END algorithm=brute, n_neighbors=11, weights=distance;, score=0.649 total time=   7.6s
[CV 1/3] END algorithm=brute, n_neighbors=14, weights=uniform;, score=0.666 total time=   7.7s
[CV 3/3] END algorithm=brute, n_neighbors=16, weights=uniform;, score=0.660 total time=   7.6s
[CV 2/3] END algorithm=brute, n_neighbors=18, weights=distance;, score=0.657 total time=   7.5s
[CV 1/3] END class_weight=balanced, gamma=scale, kernel=sigmoid;, score=0.527 total time=17.6min
[CV 2/3] END class_weight=balanced, gamma=auto, kernel=rbf;, score=0.220 total time=22.5min
[CV 2/3] END class_weight=None, gamma=auto, kernel=poly;, score=0.658 total time= 7.2min
[CV 2/3] END algorithm=auto, n_neighbors=2, weights=uniform;, score=0.617 total time=   8.4s
[CV 3/3] END algorithm=auto, n_neighbors=5, weights=uniform;, score=0.626 total time=   8.4s
[CV 2/3] END algorithm=auto, n_neighbors=8, weights=distance;, score=0.620 total time=   8.3s
[CV 3/3] END algorithm=auto, n_neighbors=10, weights=distance;, score=0.648 total time=   8.3s
[CV 2/3] END algorithm=auto, n_neighbors=13, weights=distance;, score=0.643 total time=   8.2s
[CV 3/3] END algorithm=auto, n_neighbors=16, weights=uniform;, score=0.660 total time=   8.2s
[CV 1/3] END algorithm=auto, n_neighbors=19, weights=uniform;, score=0.660 total time=   8.3s
[CV 2/3] END algorithm=ball_tree, n_neighbors=1, weights=distance;, score=0.539 total time= 1.4min
[CV 1/3] END algorithm=ball_tree, n_neighbors=4, weights=uniform;, score=0.656 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=6, weights=distance;, score=0.641 total time= 1.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=9, weights=distance;, score=0.629 total time= 1.4min
[CV 1/3] END algorithm=ball_tree, n_neighbors=12, weights=uniform;, score=0.660 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=14, weights=distance;, score=0.658 total time= 1.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=17, weights=distance;, score=0.647 total time= 1.4min
[CV 1/3] END algorithm=ball_tree, n_neighbors=20, weights=uniform;, score=0.658 total time= 1.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=3, weights=uniform;, score=0.613 total time= 2.3min
[CV 2/3] END algorithm=kd_tree, n_neighbors=6, weights=uniform;, score=0.635 total time= 2.3min
[CV 3/3] END algorithm=kd_tree, n_neighbors=8, weights=distance;, score=0.652 total time= 2.3min
[CV 1/3] END algorithm=kd_tree, n_neighbors=11, weights=distance;, score=0.665 total time= 2.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=14, weights=uniform;, score=0.654 total time= 2.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=16, weights=distance;, score=0.659 total time= 2.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=19, weights=distance;, score=0.663 total time= 2.4min
[CV 2/3] END algorithm=brute, n_neighbors=4, weights=uniform;, score=0.603 total time=   7.8s
[CV 1/3] END algorithm=brute, n_neighbors=5, weights=distance;, score=0.664 total time=   7.4s
[CV 1/3] END algorithm=brute, n_neighbors=7, weights=uniform;, score=0.661 total time=   7.7s
[CV 1/3] END algorithm=brute, n_neighbors=8, weights=distance;, score=0.662 total time=   7.4s
[CV 3/3] END algorithm=brute, n_neighbors=10, weights=uniform;, score=0.647 total time=   7.6s
[CV 2/3] END algorithm=brute, n_neighbors=12, weights=uniform;, score=0.648 total time=   7.7s
[CV 3/3] END algorithm=brute, n_neighbors=14, weights=uniform;, score=0.655 total time=   7.6s
[CV 2/3] END algorithm=brute, n_neighbors=16, weights=distance;, score=0.649 total time=   7.4s
[CV 3/3] END algorithm=brute, n_neighbors=18, weights=distance;, score=0.660 total time=   7.5s
[CV 2/3] END class_weight=balanced, gamma=scale, kernel=sigmoid;, score=0.498 total time=17.4min
[CV 1/3] END class_weight=balanced, gamma=auto, kernel=rbf;, score=0.657 total time=23.0min
[CV 3/3] END class_weight=None, gamma=auto, kernel=poly;, score=0.658 total time= 7.6min
[CV 3/3] END algorithm=auto, n_neighbors=2, weights=distance;, score=0.613 total time=   8.2s
[CV 3/3] END algorithm=auto, n_neighbors=3, weights=distance;, score=0.612 total time=   8.1s
[CV 1/3] END algorithm=auto, n_neighbors=6, weights=distance;, score=0.659 total time=   7.8s
[CV 3/3] END algorithm=auto, n_neighbors=9, weights=uniform;, score=0.647 total time=   7.7s
[CV 1/3] END algorithm=auto, n_neighbors=12, weights=uniform;, score=0.660 total time=   7.7s
[CV 2/3] END algorithm=auto, n_neighbors=14, weights=distance;, score=0.652 total time=   7.7s
[CV 3/3] END algorithm=auto, n_neighbors=17, weights=uniform;, score=0.658 total time=   7.7s
[CV 1/3] END algorithm=auto, n_neighbors=20, weights=uniform;, score=0.658 total time=   7.7s
[CV 3/3] END algorithm=ball_tree, n_neighbors=2, weights=distance;, score=0.613 total time= 1.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=6, weights=uniform;, score=0.658 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=8, weights=distance;, score=0.652 total time= 1.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=11, weights=distance;, score=0.665 total time= 1.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=14, weights=uniform;, score=0.654 total time= 1.4min
[CV 2/3] END algorithm=ball_tree, n_neighbors=16, weights=distance;, score=0.649 total time= 1.4min
[CV 1/3] END algorithm=ball_tree, n_neighbors=19, weights=uniform;, score=0.660 total time= 1.5min
[CV 3/3] END algorithm=kd_tree, n_neighbors=1, weights=distance;, score=0.613 total time= 1.7min
[CV 1/3] END algorithm=kd_tree, n_neighbors=4, weights=uniform;, score=0.656 total time= 2.3min
[CV 2/3] END algorithm=kd_tree, n_neighbors=6, weights=distance;, score=0.613 total time= 2.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=9, weights=distance;, score=0.664 total time= 2.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=12, weights=uniform;, score=0.648 total time= 2.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=14, weights=distance;, score=0.658 total time= 2.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=17, weights=distance;, score=0.662 total time= 2.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=20, weights=uniform;, score=0.657 total time= 2.4min
[CV 3/3] END algorithm=brute, n_neighbors=9, weights=uniform;, score=0.647 total time=   6.0s
[CV 2/3] END algorithm=brute, n_neighbors=11, weights=uniform;, score=0.646 total time=   6.0s
[CV 3/3] END algorithm=brute, n_neighbors=12, weights=distance;, score=0.654 total time=   6.0s
[CV 2/3] END algorithm=brute, n_neighbors=14, weights=uniform;, score=0.654 total time=   6.0s
[CV 2/3] END algorithm=brute, n_neighbors=16, weights=uniform;, score=0.651 total time=   6.0s
[CV 2/3] END algorithm=brute, n_neighbors=18, weights=uniform;, score=0.658 total time=   6.0s
[CV 2/3] END algorithm=brute, n_neighbors=20, weights=uniform;, score=0.657 total time=   6.0s
[CV 2/3] END class_weight=balanced, gamma=scale, kernel=linear;, score=0.557 total time=14.8min
[CV 3/3] END class_weight=balanced, gamma=auto, kernel=linear;, score=0.550 total time=14.8min
[CV 1/3] END class_weight=None, gamma=scale, kernel=rbf;, score=0.675 total time=18.3min
[CV 3/3] END algorithm=auto, n_neighbors=1, weights=distance;, score=0.613 total time=   8.3s
[CV 3/3] END algorithm=auto, n_neighbors=4, weights=uniform;, score=0.647 total time=   8.4s
[CV 3/3] END algorithm=auto, n_neighbors=7, weights=distance;, score=0.636 total time=   8.3s
[CV 1/3] END algorithm=auto, n_neighbors=10, weights=distance;, score=0.661 total time=   8.0s
[CV 1/3] END algorithm=auto, n_neighbors=13, weights=uniform;, score=0.660 total time=   7.8s
[CV 2/3] END algorithm=auto, n_neighbors=15, weights=distance;, score=0.642 total time=   7.7s
[CV 3/3] END algorithm=auto, n_neighbors=18, weights=uniform;, score=0.657 total time=   7.8s
[CV 1/3] END algorithm=ball_tree, n_neighbors=1, weights=uniform;, score=0.627 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=3, weights=distance;, score=0.612 total time= 1.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=6, weights=distance;, score=0.613 total time= 1.4min
[CV 2/3] END algorithm=ball_tree, n_neighbors=9, weights=uniform;, score=0.656 total time= 1.4min
[CV 2/3] END algorithm=ball_tree, n_neighbors=11, weights=distance;, score=0.639 total time= 1.4min
[CV 3/3] END algorithm=ball_tree, n_neighbors=14, weights=uniform;, score=0.655 total time= 1.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=17, weights=uniform;, score=0.658 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=19, weights=distance;, score=0.663 total time= 1.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=3, weights=uniform;, score=0.658 total time= 2.2min
[CV 3/3] END algorithm=kd_tree, n_neighbors=5, weights=distance;, score=0.620 total time= 2.3min
[CV 2/3] END algorithm=kd_tree, n_neighbors=8, weights=uniform;, score=0.633 total time= 2.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=11, weights=uniform;, score=0.662 total time= 2.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=13, weights=distance;, score=0.643 total time= 2.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=16, weights=uniform;, score=0.660 total time= 2.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=19, weights=uniform;, score=0.660 total time= 2.5min
[CV 2/3] END algorithm=brute, n_neighbors=3, weights=distance;, score=0.569 total time=   7.7s
[CV 3/3] END algorithm=brute, n_neighbors=5, weights=uniform;, score=0.626 total time=   8.2s
[CV 2/3] END algorithm=brute, n_neighbors=6, weights=distance;, score=0.613 total time=   8.0s
[CV 3/3] END algorithm=brute, n_neighbors=8, weights=uniform;, score=0.647 total time=   8.1s
[CV 1/3] END algorithm=brute, n_neighbors=10, weights=distance;, score=0.661 total time=   7.9s
[CV 1/3] END algorithm=brute, n_neighbors=12, weights=distance;, score=0.661 total time=   8.0s
[CV 2/3] END algorithm=brute, n_neighbors=14, weights=distance;, score=0.652 total time=   8.1s
[CV 1/3] END algorithm=brute, n_neighbors=17, weights=uniform;, score=0.658 total time=   8.2s
[CV 3/3] END algorithm=brute, n_neighbors=19, weights=uniform;, score=0.660 total time=   7.8s
[CV 1/3] END class_weight=balanced, gamma=scale, kernel=poly;, score=0.674 total time=20.2min
[CV 3/3] END class_weight=None, gamma=scale, kernel=sigmoid;, score=0.669 total time=12.2min
[CV 3/3] END class_weight=None, gamma=scale, kernel=rbf;, score=0.673 total time=16.3min
[CV 2/3] END algorithm=auto, n_neighbors=2, weights=distance;, score=0.540 total time=   8.3s
[CV 2/3] END algorithm=auto, n_neighbors=4, weights=distance;, score=0.592 total time=   8.4s
[CV 1/3] END algorithm=auto, n_neighbors=8, weights=distance;, score=0.662 total time=   8.1s
[CV 3/3] END algorithm=auto, n_neighbors=10, weights=uniform;, score=0.647 total time=   7.9s
[CV 3/3] END algorithm=auto, n_neighbors=12, weights=distance;, score=0.654 total time=   7.6s
[CV 1/3] END algorithm=auto, n_neighbors=15, weights=distance;, score=0.663 total time=   7.7s
[CV 2/3] END algorithm=auto, n_neighbors=18, weights=uniform;, score=0.658 total time=   7.8s
[CV 3/3] END algorithm=auto, n_neighbors=20, weights=distance;, score=0.665 total time=   7.5s
[CV 1/3] END algorithm=ball_tree, n_neighbors=3, weights=distance;, score=0.648 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=5, weights=distance;, score=0.620 total time= 1.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=8, weights=distance;, score=0.662 total time= 1.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=11, weights=uniform;, score=0.646 total time= 1.4min
[CV 1/3] END algorithm=ball_tree, n_neighbors=13, weights=distance;, score=0.663 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=15, weights=distance;, score=0.662 total time= 1.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=18, weights=distance;, score=0.657 total time= 1.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=1, weights=uniform;, score=0.539 total time= 1.8min
[CV 3/3] END algorithm=kd_tree, n_neighbors=4, weights=uniform;, score=0.647 total time= 2.2min
[CV 3/3] END algorithm=kd_tree, n_neighbors=6, weights=distance;, score=0.641 total time= 2.3min
[CV 3/3] END algorithm=kd_tree, n_neighbors=9, weights=uniform;, score=0.647 total time= 2.3min
[CV 1/3] END algorithm=kd_tree, n_neighbors=12, weights=uniform;, score=0.660 total time= 2.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=14, weights=distance;, score=0.652 total time= 2.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=17, weights=uniform;, score=0.658 total time= 2.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=20, weights=uniform;, score=0.658 total time= 3.0min
[CV 3/3] END algorithm=brute, n_neighbors=19, weights=distance;, score=0.663 total time=   7.2s
[CV 2/3] END class_weight=balanced, gamma=scale, kernel=poly;, score=0.674 total time=20.1min
[CV 2/3] END class_weight=None, gamma=scale, kernel=sigmoid;, score=0.659 total time=11.9min
[CV 2/3] END class_weight=None, gamma=scale, kernel=rbf;, score=0.667 total time=16.8min
[CV 2/3] END algorithm=auto, n_neighbors=1, weights=distance;, score=0.539 total time=   8.1s
[CV 2/3] END algorithm=auto, n_neighbors=3, weights=distance;, score=0.569 total time=   7.9s
[CV 3/3] END algorithm=auto, n_neighbors=6, weights=uniform;, score=0.636 total time=   7.8s
[CV 1/3] END algorithm=auto, n_neighbors=9, weights=uniform;, score=0.660 total time=   7.7s
[CV 2/3] END algorithm=auto, n_neighbors=11, weights=distance;, score=0.639 total time=   7.7s
[CV 3/3] END algorithm=auto, n_neighbors=14, weights=uniform;, score=0.655 total time=   7.7s
[CV 1/3] END algorithm=auto, n_neighbors=17, weights=uniform;, score=0.658 total time=   7.7s
[CV 2/3] END algorithm=auto, n_neighbors=19, weights=distance;, score=0.654 total time=   7.6s
[CV 3/3] END algorithm=ball_tree, n_neighbors=2, weights=uniform;, score=0.656 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=5, weights=uniform;, score=0.626 total time= 1.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=8, weights=uniform;, score=0.633 total time= 1.4min
[CV 1/3] END algorithm=ball_tree, n_neighbors=10, weights=distance;, score=0.661 total time= 1.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=13, weights=uniform;, score=0.650 total time= 1.4min
[CV 1/3] END algorithm=ball_tree, n_neighbors=15, weights=distance;, score=0.663 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=18, weights=uniform;, score=0.657 total time= 1.5min
[CV 1/3] END algorithm=kd_tree, n_neighbors=1, weights=uniform;, score=0.627 total time= 1.7min
[CV 2/3] END algorithm=kd_tree, n_neighbors=3, weights=distance;, score=0.569 total time= 2.3min
[CV 1/3] END algorithm=kd_tree, n_neighbors=6, weights=distance;, score=0.659 total time= 2.3min
[CV 2/3] END algorithm=kd_tree, n_neighbors=9, weights=uniform;, score=0.656 total time= 2.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=11, weights=distance;, score=0.649 total time= 2.3min
[CV 1/3] END algorithm=kd_tree, n_neighbors=14, weights=distance;, score=0.664 total time= 2.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=17, weights=uniform;, score=0.645 total time= 2.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=19, weights=distance;, score=0.663 total time= 2.9min
[CV 3/3] END algorithm=brute, n_neighbors=15, weights=uniform;, score=0.654 total time=   7.7s
[CV 1/3] END algorithm=brute, n_neighbors=17, weights=distance;, score=0.662 total time=   7.6s
[CV 1/3] END algorithm=brute, n_neighbors=20, weights=uniform;, score=0.658 total time=   7.6s
[CV 3/3] END class_weight=balanced, gamma=scale, kernel=rbf;, score=0.599 total time=21.6min
[CV 1/3] END class_weight=None, gamma=scale, kernel=poly;, score=0.668 total time=19.6min
[CV 2/3] END class_weight=None, gamma=auto, kernel=rbf;, score=0.658 total time= 8.1min
[CV 1/3] END algorithm=auto, n_neighbors=2, weights=uniform;, score=0.658 total time=   8.4s
[CV 2/3] END algorithm=auto, n_neighbors=5, weights=distance;, score=0.599 total time=   8.1s
[CV 2/3] END algorithm=auto, n_neighbors=7, weights=uniform;, score=0.649 total time=   8.6s
[CV 3/3] END algorithm=auto, n_neighbors=11, weights=uniform;, score=0.652 total time=   8.4s
[CV 2/3] END algorithm=auto, n_neighbors=14, weights=uniform;, score=0.654 total time=   8.3s
[CV 3/3] END algorithm=auto, n_neighbors=16, weights=distance;, score=0.659 total time=   8.2s
[CV 1/3] END algorithm=auto, n_neighbors=19, weights=distance;, score=0.663 total time=   8.2s
[CV 2/3] END algorithm=ball_tree, n_neighbors=2, weights=uniform;, score=0.617 total time= 1.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=4, weights=distance;, score=0.652 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=7, weights=uniform;, score=0.637 total time= 1.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=10, weights=uniform;, score=0.660 total time= 1.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=13, weights=uniform;, score=0.660 total time= 1.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=16, weights=uniform;, score=0.662 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=18, weights=distance;, score=0.660 total time= 1.5min
[CV 2/3] END algorithm=kd_tree, n_neighbors=1, weights=distance;, score=0.539 total time= 1.9min
[CV 1/3] END algorithm=kd_tree, n_neighbors=4, weights=distance;, score=0.652 total time= 2.3min
[CV 2/3] END algorithm=kd_tree, n_neighbors=7, weights=uniform;, score=0.649 total time= 2.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=9, weights=distance;, score=0.646 total time= 2.3min
[CV 1/3] END algorithm=kd_tree, n_neighbors=12, weights=distance;, score=0.661 total time= 2.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=15, weights=uniform;, score=0.647 total time= 2.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=17, weights=distance;, score=0.667 total time= 2.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=20, weights=distance;, score=0.663 total time= 2.5min
[CV 1/3] END algorithm=brute, n_neighbors=15, weights=distance;, score=0.663 total time=   7.6s
[CV 2/3] END algorithm=brute, n_neighbors=17, weights=distance;, score=0.646 total time=   7.6s
[CV 3/3] END algorithm=brute, n_neighbors=20, weights=uniform;, score=0.661 total time=   7.0s
[CV 1/3] END class_weight=balanced, gamma=scale, kernel=rbf;, score=0.618 total time=21.7min
[CV 2/3] END class_weight=None, gamma=scale, kernel=poly;, score=0.670 total time=19.2min
[CV 1/3] END class_weight=None, gamma=auto, kernel=rbf;, score=0.657 total time= 8.5min
[CV 2/3] END algorithm=auto, n_neighbors=1, weights=uniform;, score=0.539 total time=   8.4s
[CV 1/3] END algorithm=auto, n_neighbors=5, weights=uniform;, score=0.662 total time=   8.4s
[CV 2/3] END algorithm=auto, n_neighbors=8, weights=uniform;, score=0.633 total time=   8.4s
[CV 1/3] END algorithm=auto, n_neighbors=11, weights=distance;, score=0.665 total time=   8.4s
[CV 1/3] END algorithm=auto, n_neighbors=14, weights=uniform;, score=0.666 total time=   8.3s
[CV 2/3] END algorithm=auto, n_neighbors=16, weights=distance;, score=0.649 total time=   8.2s
[CV 3/3] END algorithm=auto, n_neighbors=19, weights=uniform;, score=0.660 total time=   8.3s
[CV 1/3] END algorithm=ball_tree, n_neighbors=2, weights=uniform;, score=0.658 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=4, weights=distance;, score=0.635 total time= 1.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=7, weights=distance;, score=0.662 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=10, weights=uniform;, score=0.647 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=13, weights=uniform;, score=0.652 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=16, weights=uniform;, score=0.660 total time= 1.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=19, weights=uniform;, score=0.654 total time= 1.5min
[CV 1/3] END algorithm=kd_tree, n_neighbors=1, weights=distance;, score=0.627 total time= 1.7min
[CV 2/3] END algorithm=kd_tree, n_neighbors=4, weights=uniform;, score=0.603 total time= 2.3min
[CV 1/3] END algorithm=kd_tree, n_neighbors=7, weights=uniform;, score=0.661 total time= 2.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=9, weights=distance;, score=0.629 total time= 2.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=12, weights=uniform;, score=0.651 total time= 2.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=15, weights=uniform;, score=0.660 total time= 2.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=17, weights=distance;, score=0.647 total time= 2.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=20, weights=uniform;, score=0.661 total time= 2.4min
[CV 2/3] END algorithm=brute, n_neighbors=10, weights=distance;, score=0.644 total time=   6.0s
[CV 1/3] END algorithm=brute, n_neighbors=12, weights=uniform;, score=0.660 total time=   6.0s
[CV 2/3] END algorithm=brute, n_neighbors=13, weights=distance;, score=0.643 total time=   5.8s
[CV 2/3] END algorithm=brute, n_neighbors=15, weights=distance;, score=0.642 total time=   7.7s
[CV 1/3] END algorithm=brute, n_neighbors=18, weights=uniform;, score=0.659 total time=   7.8s
[CV 1/3] END algorithm=brute, n_neighbors=20, weights=distance;, score=0.663 total time=   6.9s
[CV 2/3] END class_weight=balanced, gamma=auto, kernel=sigmoid;, score=0.220 total time=19.9min
[CV 3/3] END class_weight=balanced, gamma=auto, kernel=rbf;, score=0.220 total time=21.9min
[CV 3/3] END class_weight=None, gamma=auto, kernel=rbf;, score=0.658 total time= 8.0min
saving: KNN_no_linked_1637232131 as png
saving: DT_no_linked_1637232229 as png
Fitting 3 folds for each of 16 candidates, totalling 48 fits
saving: SVC_no_linked_1637236208 as png
Fitting 3 folds for each of 168 candidates, totalling 504 fits
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=hinge, penalty=l1;, score=0.559 total time=  25.3s
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=perceptron, penalty=l2;, score=0.465 total time=   2.0s
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=perceptron, penalty=l2;, score=0.430 total time=   2.8s
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=perceptron, penalty=elasticnet;, score=0.485 total time=   8.1s
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=squared_loss, penalty=l1;, score=0.308 total time=   6.5s
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=huber, penalty=l2;, score=0.232 total time=   2.4s
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=hinge, penalty=l2;, score=0.562 total time=   7.0s
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=hinge, penalty=elasticnet;, score=0.582 total time=  35.5s
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=modified_huber, penalty=l1;, score=0.561 total time= 1.0min
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=squared_loss, penalty=l1;, score=0.350 total time=13.9min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=log, penalty=elasticnet;, score=0.592 total time= 1.6min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_hinge, penalty=l2;, score=0.555 total time= 1.9min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_hinge, penalty=l1;, score=0.552 total time= 4.8min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=huber, penalty=l2;, score=0.609 total time=  32.9s
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=huber, penalty=l2;, score=0.603 total time=  32.3s
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=huber, penalty=l1;, score=0.663 total time= 1.1min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=huber, penalty=elasticnet;, score=0.661 total time= 1.7min
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=squared_hinge, penalty=l2;, score=0.658 total time=   1.8s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=squared_hinge, penalty=l1;, score=0.533 total time=  27.5s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=huber, penalty=l2;, score=0.522 total time=   3.9s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=hinge, penalty=l2;, score=0.657 total time=   2.1s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=hinge, penalty=l1;, score=0.658 total time=   3.6s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=log, penalty=l1;, score=0.657 total time=   4.4s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=modified_huber, penalty=l2;, score=0.661 total time=   4.4s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=squared_hinge, penalty=l2;, score=0.659 total time=   7.4s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=squared_hinge, penalty=elasticnet;, score=0.654 total time= 1.1min
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=hinge, penalty=elasticnet;, score=0.657 total time=  18.3s
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=log, penalty=l2;, score=0.658 total time=   8.9s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=log, penalty=elasticnet;, score=0.658 total time=  14.4s
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=modified_huber, penalty=l1;, score=0.657 total time=  28.5s
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=modified_huber, penalty=elasticnet;, score=0.658 total time=  34.8s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=squared_hinge, penalty=elasticnet;, score=0.658 total time=  35.7s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=perceptron, penalty=l1;, score=0.220 total time=  18.9s
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=squared_loss, penalty=l2;, score=0.658 total time=  18.6s
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=huber, penalty=l2;, score=0.657 total time=   3.3s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=huber, penalty=l2;, score=0.658 total time=   3.3s
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=huber, penalty=l2;, score=0.658 total time=   3.3s
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=huber, penalty=l1;, score=0.657 total time=   4.7s
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=huber, penalty=l1;, score=0.658 total time=   4.7s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=huber, penalty=elasticnet;, score=0.658 total time=   4.7s
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=hinge, penalty=l2;, score=0.658 total time=  21.1s
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=hinge, penalty=elasticnet;, score=0.657 total time=  41.5s
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=log, penalty=l2;, score=0.658 total time=  34.0s
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=log, penalty=elasticnet;, score=0.657 total time=  51.9s
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=modified_huber, penalty=l2;, score=0.660 total time=  30.3s
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=modified_huber, penalty=elasticnet;, score=0.657 total time=  53.6s
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=squared_hinge, penalty=elasticnet;, score=0.658 total time=  55.8s
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=perceptron, penalty=l1;, score=0.658 total time=  35.1s
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=squared_loss, penalty=l2;, score=0.658 total time=  31.4s
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=squared_loss, penalty=elasticnet;, score=0.658 total time= 1.0min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=hinge, penalty=l2;, score=0.422 total time=   2.2s
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=modified_huber, penalty=l2;, score=0.564 total time=   2.4s
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=modified_huber, penalty=l2;, score=0.349 total time=   2.2s
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=modified_huber, penalty=elasticnet;, score=0.533 total time=  10.3s
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=squared_hinge, penalty=l1;, score=0.577 total time=  31.9s
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=hinge, penalty=l1;, score=0.554 total time=  39.7s
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=modified_huber, penalty=l1;, score=0.551 total time= 1.2min
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=huber, penalty=l2;, score=0.597 total time=  11.7s
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=huber, penalty=l1;, score=0.634 total time=  22.6s
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=hinge, penalty=l1;, score=0.560 total time= 1.0min
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=log, penalty=elasticnet;, score=0.598 total time=  38.1s
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=modified_huber, penalty=elasticnet;, score=0.561 total time=  53.7s
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_hinge, penalty=elasticnet;, score=0.556 total time= 1.2min
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=perceptron, penalty=elasticnet;, score=0.576 total time=  34.9s
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_loss, penalty=elasticnet;, score=0.362 total time=18.0min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=huber, penalty=l2;, score=0.612 total time=  30.6s
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=huber, penalty=l1;, score=0.653 total time= 1.1min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=huber, penalty=elasticnet;, score=0.657 total time= 1.5min
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=squared_hinge, penalty=elasticnet;, score=0.658 total time=   5.7s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=perceptron, penalty=l1;, score=0.658 total time=   5.8s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=squared_loss, penalty=l2;, score=0.645 total time=   3.5s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=squared_loss, penalty=elasticnet;, score=0.220 total time=   8.2s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=huber, penalty=l1;, score=0.657 total time=   4.7s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=hinge, penalty=l2;, score=0.658 total time=   2.2s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=hinge, penalty=elasticnet;, score=0.658 total time=   3.5s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=log, penalty=elasticnet;, score=0.657 total time=   4.7s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=modified_huber, penalty=l1;, score=0.658 total time=   5.6s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=squared_hinge, penalty=l1;, score=0.520 total time= 9.6min
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=perceptron, penalty=elasticnet;, score=0.479 total time=  38.3s
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=squared_loss, penalty=elasticnet;, score=0.657 total time=  56.6s
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=huber, penalty=l1;, score=0.657 total time=  43.5s
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=log, penalty=l1;, score=0.572 total time=  36.6s
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=squared_loss, penalty=l1;, score=0.529 total time=   6.6s
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=huber, penalty=l2;, score=0.372 total time=   2.4s
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=huber, penalty=l1;, score=0.640 total time=  23.1s
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=log, penalty=elasticnet;, score=0.588 total time=  32.8s
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=squared_hinge, penalty=l1;, score=0.549 total time=  48.6s
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=squared_loss, penalty=l2;, score=0.342 total time= 6.0min
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=huber, penalty=l2;, score=0.623 total time=   7.0s
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=huber, penalty=l2;, score=0.615 total time=   7.0s
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=huber, penalty=l2;, score=0.627 total time=   6.6s
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=huber, penalty=l1;, score=0.641 total time=  16.9s
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=huber, penalty=l1;, score=0.637 total time=  16.3s
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=huber, penalty=l1;, score=0.641 total time=  16.3s
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=huber, penalty=elasticnet;, score=0.632 total time=  19.7s
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=huber, penalty=elasticnet;, score=0.613 total time=  19.7s
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=huber, penalty=elasticnet;, score=0.627 total time=  18.1s
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=hinge, penalty=l2;, score=0.572 total time=  13.9s
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=hinge, penalty=l2;, score=0.573 total time=  13.2s
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=hinge, penalty=l2;, score=0.571 total time=  14.1s
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=hinge, penalty=l1;, score=0.556 total time= 2.0min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=hinge, penalty=elasticnet;, score=0.578 total time= 1.5min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=log, penalty=l2;, score=0.582 total time=  32.9s
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=log, penalty=elasticnet;, score=0.598 total time= 1.9min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=modified_huber, penalty=l2;, score=0.561 total time=  17.1s
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=modified_huber, penalty=l1;, score=0.548 total time= 2.1min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_hinge, penalty=l1;, score=0.554 total time= 4.7min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_loss, penalty=elasticnet;, score=0.371 total time=16.5min
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=huber, penalty=elasticnet;, score=0.658 total time=  25.0s
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=log, penalty=l1;, score=0.582 total time=  48.5s
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=hinge, penalty=l2;, score=0.558 total time=  10.4s
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=log, penalty=l2;, score=0.591 total time=   9.8s
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=log, penalty=elasticnet;, score=0.593 total time=  30.7s
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=squared_hinge, penalty=l2;, score=0.572 total time=   9.6s
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=perceptron, penalty=l2;, score=0.580 total time=   6.9s
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=perceptron, penalty=l1;, score=0.568 total time=  43.6s
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=squared_loss, penalty=elasticnet;, score=0.349 total time=17.7min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=perceptron, penalty=l2;, score=0.557 total time=  12.6s
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=perceptron, penalty=l2;, score=0.561 total time=  13.6s
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=perceptron, penalty=l1;, score=0.550 total time= 1.7min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_loss, penalty=l2;, score=0.323 total time= 5.7min
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=log, penalty=l1;, score=0.658 total time=   7.2s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=modified_huber, penalty=l2;, score=0.657 total time=   2.7s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=modified_huber, penalty=l2;, score=0.650 total time=   2.3s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=modified_huber, penalty=l1;, score=0.658 total time=   5.3s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=squared_hinge, penalty=l2;, score=0.220 total time=   1.9s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=squared_hinge, penalty=l1;, score=0.567 total time=  28.7s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=huber, penalty=elasticnet;, score=0.658 total time=   5.2s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=hinge, penalty=elasticnet;, score=0.657 total time=   3.4s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=log, penalty=l1;, score=0.658 total time=   4.3s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=modified_huber, penalty=l2;, score=0.660 total time=   3.6s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=modified_huber, penalty=elasticnet;, score=0.658 total time=   5.7s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=squared_hinge, penalty=elasticnet;, score=0.657 total time=   9.1s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=perceptron, penalty=l1;, score=0.122 total time=   3.2s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=perceptron, penalty=elasticnet;, score=0.220 total time=   3.2s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=squared_loss, penalty=l2;, score=0.658 total time=   3.0s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=squared_loss, penalty=l1;, score=0.658 total time=   5.1s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=squared_loss, penalty=elasticnet;, score=0.657 total time=   4.4s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=squared_loss, penalty=elasticnet;, score=0.658 total time=   4.5s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=huber, penalty=l2;, score=0.657 total time=   2.3s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=huber, penalty=l2;, score=0.658 total time=   2.3s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=huber, penalty=l1;, score=0.658 total time=   3.9s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=huber, penalty=elasticnet;, score=0.658 total time=   3.9s
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=hinge, penalty=l2;, score=0.658 total time=   9.8s
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=hinge, penalty=l1;, score=0.658 total time=  18.5s
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=hinge, penalty=elasticnet;, score=0.658 total time=  21.0s
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=log, penalty=elasticnet;, score=0.657 total time=  15.0s
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=modified_huber, penalty=l2;, score=0.625 total time=  14.6s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=modified_huber, penalty=elasticnet;, score=0.658 total time=  28.1s
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=squared_hinge, penalty=l1;, score=0.551 total time= 1.0min
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=perceptron, penalty=l1;, score=0.658 total time=  17.1s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=squared_loss, penalty=l2;, score=0.658 total time=  15.5s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=squared_loss, penalty=elasticnet;, score=0.658 total time=  26.6s
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=hinge, penalty=l2;, score=0.657 total time=  18.5s
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=hinge, penalty=l1;, score=0.658 total time=  38.8s
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=hinge, penalty=elasticnet;, score=0.658 total time=  40.0s
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=log, penalty=l1;, score=0.658 total time=  49.6s
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=modified_huber, penalty=l2;, score=0.661 total time=  25.2s
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=modified_huber, penalty=l1;, score=0.658 total time=  51.2s
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=squared_hinge, penalty=l1;, score=0.558 total time= 3.7min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=hinge, penalty=l2;, score=0.546 total time=   2.1s
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=log, penalty=elasticnet;, score=0.639 total time=  14.0s
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=modified_huber, penalty=elasticnet;, score=0.503 total time=   9.5s
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=perceptron, penalty=l2;, score=0.552 total time=   2.2s
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=perceptron, penalty=l1;, score=0.576 total time=  27.5s
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=hinge, penalty=elasticnet;, score=0.584 total time=  45.2s
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=squared_hinge, penalty=l1;, score=0.552 total time=  54.9s
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=squared_loss, penalty=l1;, score=0.349 total time=11.2min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=hinge, penalty=elasticnet;, score=0.571 total time= 1.3min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=log, penalty=l1;, score=0.554 total time= 2.4min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=modified_huber, penalty=l1;, score=0.553 total time= 2.9min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=perceptron, penalty=l2;, score=0.557 total time=  13.4s
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=perceptron, penalty=l1;, score=0.557 total time= 1.8min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_loss, penalty=l2;, score=0.356 total time= 5.9min
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=log, penalty=elasticnet;, score=0.657 total time=   6.8s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=modified_huber, penalty=l2;, score=0.122 total time=   2.7s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=modified_huber, penalty=l1;, score=0.624 total time=   4.6s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=modified_huber, penalty=elasticnet;, score=0.658 total time=   5.3s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=squared_hinge, penalty=elasticnet;, score=0.220 total time=   6.0s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=perceptron, penalty=l2;, score=0.658 total time=   2.3s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=perceptron, penalty=l1;, score=0.657 total time=   4.1s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=perceptron, penalty=elasticnet;, score=0.220 total time=   4.1s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=squared_loss, penalty=l2;, score=0.122 total time=   4.8s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=squared_loss, penalty=elasticnet;, score=0.220 total time=   6.4s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=huber, penalty=elasticnet;, score=0.657 total time=   4.1s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=hinge, penalty=l1;, score=0.658 total time=   3.4s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=log, penalty=l2;, score=0.657 total time=   2.6s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=log, penalty=elasticnet;, score=0.658 total time=   4.3s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=modified_huber, penalty=l1;, score=0.658 total time=   5.0s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=squared_hinge, penalty=l2;, score=0.657 total time=   6.5s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=perceptron, penalty=l2;, score=0.591 total time=   1.4s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=perceptron, penalty=l2;, score=0.621 total time=   1.4s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=perceptron, penalty=l2;, score=0.560 total time=   1.4s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=perceptron, penalty=l1;, score=0.122 total time=   3.2s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=perceptron, penalty=elasticnet;, score=0.127 total time=   3.2s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=squared_loss, penalty=l2;, score=0.658 total time=   3.0s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=squared_loss, penalty=l1;, score=0.654 total time=  14.5s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=squared_loss, penalty=elasticnet;, score=0.658 total time=   4.4s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=huber, penalty=l1;, score=0.658 total time=   4.1s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=huber, penalty=elasticnet;, score=0.658 total time=   3.9s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=hinge, penalty=l2;, score=0.658 total time=   9.7s
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=hinge, penalty=l1;, score=0.657 total time=  17.6s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=hinge, penalty=elasticnet;, score=0.658 total time=  20.0s
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=log, penalty=l1;, score=0.657 total time=  11.0s
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=modified_huber, penalty=l2;, score=0.659 total time=  18.3s
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=modified_huber, penalty=elasticnet;, score=0.220 total time=  27.3s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=squared_hinge, penalty=l2;, score=0.656 total time=  13.9s
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=squared_hinge, penalty=l1;, score=0.561 total time= 1.0min
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=perceptron, penalty=elasticnet;, score=0.658 total time=  19.0s
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=squared_loss, penalty=elasticnet;, score=0.657 total time=  20.6s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=huber, penalty=l1;, score=0.658 total time=   4.7s
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=huber, penalty=elasticnet;, score=0.657 total time=   4.5s
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=huber, penalty=elasticnet;, score=0.658 total time=   4.4s
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=hinge, penalty=l1;, score=0.657 total time=  37.3s
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=hinge, penalty=elasticnet;, score=0.658 total time=  36.8s
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=log, penalty=l2;, score=0.658 total time=  28.0s
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=log, penalty=elasticnet;, score=0.658 total time=  49.3s
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=modified_huber, penalty=l1;, score=0.657 total time=  51.3s
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=squared_hinge, penalty=l2;, score=0.661 total time=  26.3s
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=squared_hinge, penalty=l1;, score=0.552 total time= 2.5min
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=huber, penalty=l2;, score=0.658 total time=  27.0s
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=huber, penalty=l1;, score=0.658 total time=  37.1s
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=hinge, penalty=elasticnet;, score=0.523 total time=  16.2s
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=squared_hinge, penalty=l2;, score=0.400 total time=   3.1s
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=squared_hinge, penalty=l1;, score=0.560 total time=  31.7s
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=hinge, penalty=l1;, score=0.576 total time=  43.2s
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=modified_huber, penalty=elasticnet;, score=0.552 total time=  48.7s
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=perceptron, penalty=elasticnet;, score=0.571 total time=  43.9s
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=hinge, penalty=l2;, score=0.581 total time=   6.7s
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=hinge, penalty=l1;, score=0.574 total time=  59.5s
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=log, penalty=elasticnet;, score=0.584 total time=  44.1s
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_hinge, penalty=l2;, score=0.555 total time=  10.6s
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_hinge, penalty=l2;, score=0.554 total time=   6.8s
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_hinge, penalty=l2;, score=0.549 total time=   9.3s
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_hinge, penalty=l1;, score=0.546 total time=  53.1s
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=perceptron, penalty=l2;, score=0.573 total time=   5.3s
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=perceptron, penalty=l2;, score=0.544 total time=   5.6s
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=perceptron, penalty=l2;, score=0.579 total time=   5.4s
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=perceptron, penalty=l1;, score=0.576 total time=  50.6s
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_loss, penalty=l2;, score=0.338 total time= 6.0min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=hinge, penalty=elasticnet;, score=0.578 total time= 1.5min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=log, penalty=l2;, score=0.589 total time=  33.0s
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=log, penalty=l1;, score=0.546 total time= 2.5min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=modified_huber, penalty=elasticnet;, score=0.561 total time= 1.9min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_hinge, penalty=l1;, score=0.545 total time= 3.4min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_loss, penalty=l1;, score=0.343 total time=16.2min
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=squared_loss, penalty=l2;, score=0.657 total time=  32.1s
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=squared_loss, penalty=elasticnet;, score=0.658 total time=  59.1s
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=huber, penalty=l1;, score=0.658 total time=  42.4s
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=log, penalty=l2;, score=0.524 total time=   3.2s
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=modified_huber, penalty=l2;, score=0.600 total time=   2.1s
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=modified_huber, penalty=l1;, score=0.569 total time=  40.6s
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=huber, penalty=elasticnet;, score=0.319 total time=  46.6s
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=modified_huber, penalty=elasticnet;, score=0.571 total time=  53.7s
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=squared_loss, penalty=l2;, score=0.338 total time= 5.9min
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_loss, penalty=elasticnet;, score=0.328 total time=18.8min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=huber, penalty=elasticnet;, score=0.641 total time= 1.6min
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=perceptron, penalty=elasticnet;, score=0.657 total time=   4.1s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=squared_loss, penalty=l2;, score=0.147 total time=   3.0s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=squared_loss, penalty=l1;, score=0.530 total time=   6.9s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=squared_loss, penalty=elasticnet;, score=0.186 total time=   5.7s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=huber, penalty=elasticnet;, score=0.658 total time=   5.3s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=log, penalty=l2;, score=0.658 total time=   2.9s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=log, penalty=elasticnet;, score=0.658 total time=   4.6s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=modified_huber, penalty=elasticnet;, score=0.658 total time=   5.3s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=squared_hinge, penalty=l1;, score=0.545 total time= 8.0min
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=squared_hinge, penalty=l2;, score=0.660 total time=  30.3s
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=squared_hinge, penalty=elasticnet;, score=0.657 total time=  52.6s
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=perceptron, penalty=l1;, score=0.657 total time=  35.2s
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=squared_loss, penalty=l2;, score=0.658 total time=  35.6s
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=huber, penalty=l2;, score=0.657 total time=  27.4s
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=huber, penalty=l2;, score=0.658 total time=  27.1s
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=huber, penalty=elasticnet;, score=0.657 total time=  39.6s
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=log, penalty=elasticnet;, score=0.653 total time=  17.1s
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=squared_hinge, penalty=l2;, score=0.655 total time=   3.3s
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=squared_hinge, penalty=elasticnet;, score=0.623 total time=   9.4s
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=perceptron, penalty=l1;, score=0.578 total time=  23.6s
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=hinge, penalty=elasticnet;, score=0.576 total time=  42.0s
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=squared_hinge, penalty=l2;, score=0.561 total time=   8.7s
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=squared_hinge, penalty=elasticnet;, score=0.568 total time= 1.0min
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=huber, penalty=l1;, score=0.626 total time=  19.8s
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=hinge, penalty=l2;, score=0.565 total time=   7.9s
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=hinge, penalty=l1;, score=0.570 total time=  44.1s
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=log, penalty=l2;, score=0.604 total time=  12.6s
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=log, penalty=elasticnet;, score=0.602 total time=  42.6s
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=modified_huber, penalty=elasticnet;, score=0.555 total time=  45.5s
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_hinge, penalty=l1;, score=0.545 total time= 1.8min
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_loss, penalty=l1;, score=0.364 total time=14.4min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=perceptron, penalty=elasticnet;, score=0.562 total time= 1.5min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_loss, penalty=elasticnet;, score=0.298 total time=18.2min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=log, penalty=l1;, score=0.539 total time=  38.7s
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=squared_loss, penalty=elasticnet;, score=0.348 total time=   7.4s
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=huber, penalty=elasticnet;, score=0.523 total time=  53.3s
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=squared_hinge, penalty=l1;, score=0.563 total time= 1.4min
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=huber, penalty=elasticnet;, score=0.617 total time=  31.0s
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=log, penalty=l2;, score=0.593 total time=  12.2s
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=log, penalty=l2;, score=0.593 total time=  11.6s
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=log, penalty=l1;, score=0.593 total time=  41.5s
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=modified_huber, penalty=l1;, score=0.552 total time= 1.1min
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_hinge, penalty=l1;, score=0.551 total time= 1.0min
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=perceptron, penalty=elasticnet;, score=0.560 total time=  36.8s
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_loss, penalty=l1;, score=0.333 total time=14.6min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=perceptron, penalty=elasticnet;, score=0.563 total time= 1.3min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_loss, penalty=elasticnet;, score=0.317 total time=17.4min
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=huber, penalty=elasticnet;, score=0.658 total time=  39.5s
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=log, penalty=l2;, score=0.552 total time=   4.9s
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=modified_huber, penalty=l1;, score=0.552 total time=  35.4s
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=squared_loss, penalty=elasticnet;, score=0.235 total time=   7.4s
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=hinge, penalty=l2;, score=0.577 total time=   8.2s
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=log, penalty=l2;, score=0.574 total time=  12.1s
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=log, penalty=l1;, score=0.569 total time=  42.8s
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=perceptron, penalty=l1;, score=0.555 total time=  35.2s
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=perceptron, penalty=elasticnet;, score=0.568 total time=  34.8s
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=huber, penalty=elasticnet;, score=0.629 total time=  33.4s
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=hinge, penalty=elasticnet;, score=0.590 total time=  49.7s
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=modified_huber, penalty=l2;, score=0.561 total time=   7.6s
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=modified_huber, penalty=l2;, score=0.543 total time=   8.1s
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=modified_huber, penalty=l2;, score=0.568 total time=   7.6s
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=modified_huber, penalty=l1;, score=0.551 total time= 1.8min
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=perceptron, penalty=l1;, score=0.552 total time=  38.4s
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_loss, penalty=l2;, score=0.350 total time= 6.0min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=hinge, penalty=l1;, score=0.550 total time= 1.8min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=log, penalty=l2;, score=0.582 total time=  33.0s
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=log, penalty=elasticnet;, score=0.590 total time= 1.8min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=modified_huber, penalty=l2;, score=0.559 total time=  16.3s
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=modified_huber, penalty=elasticnet;, score=0.562 total time= 1.9min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_hinge, penalty=l2;, score=0.564 total time= 1.9min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=perceptron, penalty=elasticnet;, score=0.559 total time= 1.5min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_loss, penalty=l1;, score=0.294 total time=12.4min
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=log, penalty=l1;, score=0.657 total time=  47.9s
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=log, penalty=elasticnet;, score=0.658 total time=  53.2s
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=modified_huber, penalty=elasticnet;, score=0.658 total time=  47.7s
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=squared_hinge, penalty=l1;, score=0.544 total time= 3.9min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
saving: SGD_no_linked_1637239092 as png
Fitting 3 folds for each of 24 candidates, totalling 72 fits
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=hinge, penalty=elasticnet;, score=0.619 total time=  16.6s
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=squared_hinge, penalty=l2;, score=0.456 total time=   2.2s
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=squared_hinge, penalty=l1;, score=0.563 total time=  36.8s
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=log, penalty=l2;, score=0.593 total time=  10.2s
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=log, penalty=l1;, score=0.569 total time=  44.0s
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=perceptron, penalty=l2;, score=0.563 total time=   6.9s
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=perceptron, penalty=elasticnet;, score=0.570 total time=  43.1s
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=squared_loss, penalty=elasticnet;, score=0.333 total time=17.6min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_hinge, penalty=elasticnet;, score=0.551 total time=10.8min
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=log, penalty=l1;, score=0.658 total time=  10.4s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=modified_huber, penalty=l2;, score=0.651 total time=  15.1s
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=modified_huber, penalty=l1;, score=0.658 total time=  31.0s
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=squared_hinge, penalty=l2;, score=0.591 total time=  20.4s
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=squared_hinge, penalty=elasticnet;, score=0.122 total time=  31.2s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=perceptron, penalty=l2;, score=0.633 total time=   9.6s
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=perceptron, penalty=l1;, score=0.657 total time=  17.9s
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=squared_loss, penalty=l2;, score=0.621 total time=  16.5s
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=squared_loss, penalty=elasticnet;, score=0.385 total time=  28.3s
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=hinge, penalty=l2;, score=0.658 total time=  20.1s
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=hinge, penalty=l1;, score=0.658 total time=  40.0s
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=log, penalty=l2;, score=0.657 total time=  32.6s
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=log, penalty=l1;, score=0.658 total time=  48.6s
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=modified_huber, penalty=l2;, score=0.660 total time=  25.2s
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=modified_huber, penalty=l1;, score=0.658 total time=  50.5s
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=squared_hinge, penalty=l2;, score=0.660 total time=  28.2s
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=perceptron, penalty=l2;, score=0.580 total time=  15.7s
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=perceptron, penalty=l2;, score=0.564 total time=  16.7s
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=perceptron, penalty=l2;, score=0.563 total time=  15.6s
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=perceptron, penalty=elasticnet;, score=0.658 total time=  38.6s
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=squared_loss, penalty=l1;, score=0.367 total time= 8.1min
[CV 3/3] END activation=tanh, alpha=0.0001, learning_rate=constant, solver=adam;, score=0.546 total time= 5.2min
[CV 3/3] END activation=tanh, alpha=0.05, learning_rate=constant, solver=adam;, score=0.563 total time= 3.0min
[CV 1/3] END activation=tanh, alpha=0.05, learning_rate=adaptive, solver=adam;, score=0.567 total time= 3.5min
[CV 2/3] END activation=tanh, alpha=0.05, learning_rate=adaptive, solver=adam;, score=0.561 total time= 3.4min
[CV 3/3] END activation=tanh, alpha=0.05, learning_rate=adaptive, solver=lbfgs;, score=0.575 total time= 8.2min
[CV 2/3] END activation=relu, alpha=0.0001, learning_rate=adaptive, solver=sgd;, score=0.627 total time=19.0min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=hinge, penalty=l2;, score=0.522 total time=   2.1s
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=log, penalty=elasticnet;, score=0.494 total time=  19.1s
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=squared_hinge, penalty=elasticnet;, score=0.491 total time=  12.4s
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=squared_loss, penalty=l2;, score=0.532 total time=   2.5s
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=squared_loss, penalty=l1;, score=0.452 total time=   7.0s
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=huber, penalty=l2;, score=0.197 total time=   2.5s
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=huber, penalty=l1;, score=0.570 total time=  28.2s
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=log, penalty=elasticnet;, score=0.576 total time=  29.4s
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=squared_hinge, penalty=elasticnet;, score=0.577 total time=  55.3s
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=squared_loss, penalty=elasticnet;, score=0.328 total time=17.7min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_hinge, penalty=elasticnet;, score=0.544 total time=12.2min
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=squared_hinge, penalty=elasticnet;, score=0.658 total time=  34.0s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=perceptron, penalty=elasticnet;, score=0.220 total time=  20.9s
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=squared_loss, penalty=l1;, score=0.307 total time=11.8min
[CV 2/3] END activation=tanh, alpha=0.0001, learning_rate=constant, solver=sgd;, score=0.619 total time=20.5min
[CV 3/3] END activation=relu, alpha=0.0001, learning_rate=constant, solver=adam;, score=0.586 total time= 2.7min
[CV 1/3] END activation=relu, alpha=0.0001, learning_rate=adaptive, solver=sgd;, score=0.637 total time=19.2min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
[CV 1/3] END activation=tanh, alpha=0.0001, learning_rate=adaptive, solver=adam;, score=0.536 total time= 5.3min
[CV 1/3] END activation=tanh, alpha=0.05, learning_rate=constant, solver=lbfgs;, score=0.575 total time= 6.9min
[CV 3/3] END activation=tanh, alpha=0.05, learning_rate=adaptive, solver=adam;, score=0.555 total time= 3.3min
[CV 1/3] END activation=relu, alpha=0.0001, learning_rate=constant, solver=sgd;, score=0.637 total time=20.3min
[CV 1/3] END activation=relu, alpha=0.05, learning_rate=adaptive, solver=adam;, score=0.622 total time= 3.8min
[CV 3/3] END activation=relu, alpha=0.05, learning_rate=adaptive, solver=adam;, score=0.611 total time= 3.1min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
[CV 3/3] END activation=tanh, alpha=0.0001, learning_rate=adaptive, solver=adam;, score=0.552 total time= 4.3min
[CV 3/3] END activation=tanh, alpha=0.05, learning_rate=constant, solver=sgd;, score=0.633 total time=20.5min
[CV 1/3] END activation=relu, alpha=0.0001, learning_rate=adaptive, solver=lbfgs;, score=0.584 total time= 3.7min
[CV 1/3] END activation=relu, alpha=0.05, learning_rate=constant, solver=lbfgs;, score=0.611 total time=15.4min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=log, penalty=l2;, score=0.648 total time=   5.7s
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=modified_huber, penalty=l1;, score=0.579 total time=  27.6s
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=squared_loss, penalty=l2;, score=0.268 total time=   2.5s
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=squared_loss, penalty=l2;, score=0.501 total time=   2.5s
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=squared_loss, penalty=elasticnet;, score=0.243 total time=   7.4s
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=huber, penalty=elasticnet;, score=0.305 total time=  39.0s
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=modified_huber, penalty=l2;, score=0.556 total time=   8.4s
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=modified_huber, penalty=elasticnet;, score=0.554 total time= 1.1min
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=huber, penalty=l2;, score=0.598 total time=  12.5s
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=huber, penalty=elasticnet;, score=0.606 total time=  28.0s
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=hinge, penalty=elasticnet;, score=0.589 total time=  38.1s
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=log, penalty=l1;, score=0.582 total time=  55.1s
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=modified_huber, penalty=elasticnet;, score=0.540 total time= 1.1min
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_hinge, penalty=elasticnet;, score=0.570 total time=  51.4s
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=perceptron, penalty=elasticnet;, score=0.566 total time=  35.7s
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_loss, penalty=l1;, score=0.315 total time=15.1min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_loss, penalty=l2;, score=0.343 total time= 5.8min
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=log, penalty=l1;, score=0.658 total time=   7.6s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=log, penalty=elasticnet;, score=0.658 total time=   4.6s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=modified_huber, penalty=l1;, score=0.658 total time=   4.9s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=squared_hinge, penalty=l2;, score=0.122 total time=   2.9s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=squared_hinge, penalty=l1;, score=0.573 total time=  19.0s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=squared_loss, penalty=l1;, score=0.244 total time=   5.9s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=huber, penalty=l2;, score=0.122 total time=   3.0s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=huber, penalty=l1;, score=0.658 total time=   3.9s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=hinge, penalty=l2;, score=0.658 total time=   2.2s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=hinge, penalty=elasticnet;, score=0.658 total time=   3.5s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=log, penalty=l1;, score=0.658 total time=   4.7s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=modified_huber, penalty=l1;, score=0.657 total time=   5.6s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=squared_hinge, penalty=l2;, score=0.660 total time=   4.6s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=squared_hinge, penalty=elasticnet;, score=0.658 total time=   5.1s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=perceptron, penalty=l1;, score=0.220 total time=   3.3s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=perceptron, penalty=elasticnet;, score=0.657 total time=   3.3s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=squared_loss, penalty=l2;, score=0.657 total time=   3.2s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=squared_loss, penalty=l1;, score=0.653 total time=  16.5s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=huber, penalty=l2;, score=0.658 total time=   2.5s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=huber, penalty=l1;, score=0.657 total time=   3.9s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=huber, penalty=elasticnet;, score=0.657 total time=   3.9s
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=hinge, penalty=l2;, score=0.657 total time=  11.1s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=hinge, penalty=l1;, score=0.658 total time=  19.2s
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=log, penalty=l2;, score=0.657 total time=   9.9s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=log, penalty=l2;, score=0.658 total time=   8.1s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=log, penalty=l1;, score=0.658 total time=   9.6s
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=log, penalty=elasticnet;, score=0.658 total time=  14.8s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=modified_huber, penalty=l1;, score=0.658 total time=  26.3s
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=squared_hinge, penalty=l2;, score=0.609 total time=  17.6s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=squared_hinge, penalty=l1;, score=0.543 total time= 1.2min
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=squared_loss, penalty=l1;, score=0.360 total time=13.4min
[CV 3/3] END activation=tanh, alpha=0.0001, learning_rate=constant, solver=sgd;, score=0.638 total time=20.2min
[CV 2/3] END activation=relu, alpha=0.0001, learning_rate=constant, solver=adam;, score=0.564 total time= 3.5min
[CV 3/3] END activation=relu, alpha=0.0001, learning_rate=adaptive, solver=sgd;, score=0.636 total time=20.5min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
[CV 1/3] END activation=tanh, alpha=0.0001, learning_rate=constant, solver=lbfgs;, score=0.567 total time= 2.9min
[CV 3/3] END activation=tanh, alpha=0.0001, learning_rate=adaptive, solver=lbfgs;, score=0.569 total time= 4.0min
[CV 1/3] END activation=tanh, alpha=0.05, learning_rate=adaptive, solver=sgd;, score=0.628 total time=21.0min
[CV 2/3] END activation=relu, alpha=0.05, learning_rate=constant, solver=adam;, score=0.582 total time= 3.3min
[CV 3/3] END activation=relu, alpha=0.05, learning_rate=constant, solver=lbfgs;, score=0.601 total time=15.1min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=hinge, penalty=l1;, score=0.545 total time=  29.7s
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=perceptron, penalty=l1;, score=0.524 total time=  32.3s
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=log, penalty=l1;, score=0.568 total time=  46.7s
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=perceptron, penalty=l2;, score=0.578 total time=   7.3s
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=perceptron, penalty=l1;, score=0.572 total time=  34.9s
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=squared_loss, penalty=l1;, score=0.319 total time=14.8min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=modified_huber, penalty=l2;, score=0.555 total time=  15.7s
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=modified_huber, penalty=l1;, score=0.548 total time= 2.4min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_hinge, penalty=elasticnet;, score=0.552 total time=12.8min
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=perceptron, penalty=l2;, score=0.611 total time=   9.1s
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=perceptron, penalty=l2;, score=0.615 total time=   9.1s
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=perceptron, penalty=elasticnet;, score=0.657 total time=  20.4s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=squared_loss, penalty=l1;, score=0.341 total time=11.4min
[CV 1/3] END activation=tanh, alpha=0.0001, learning_rate=constant, solver=sgd;, score=0.632 total time=19.8min
[CV 3/3] END activation=relu, alpha=0.0001, learning_rate=constant, solver=sgd;, score=0.639 total time=20.3min
[CV 1/3] END activation=relu, alpha=0.05, learning_rate=adaptive, solver=lbfgs;, score=0.595 total time= 6.2min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
[CV 2/3] END activation=tanh, alpha=0.0001, learning_rate=constant, solver=lbfgs;, score=0.552 total time= 3.6min
[CV 1/3] END activation=tanh, alpha=0.05, learning_rate=constant, solver=sgd;, score=0.634 total time=20.6min
[CV 2/3] END activation=relu, alpha=0.0001, learning_rate=adaptive, solver=adam;, score=0.563 total time= 3.7min
[CV 3/3] END activation=relu, alpha=0.05, learning_rate=constant, solver=sgd;, score=0.642 total time=18.8min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=hinge, penalty=l1;, score=0.597 total time=  31.5s
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=perceptron, penalty=elasticnet;, score=0.600 total time=  17.8s
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=hinge, penalty=l1;, score=0.564 total time=  35.1s
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=modified_huber, penalty=l2;, score=0.553 total time=  11.2s
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=squared_hinge, penalty=l2;, score=0.564 total time=   8.2s
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=squared_hinge, penalty=elasticnet;, score=0.572 total time=  46.6s
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=squared_loss, penalty=l2;, score=0.303 total time= 5.9min
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_loss, penalty=elasticnet;, score=0.298 total time=17.9min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=huber, penalty=l1;, score=0.661 total time= 1.1min
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=hinge, penalty=l2;, score=0.657 total time=   2.6s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=hinge, penalty=l2;, score=0.658 total time=   2.3s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=hinge, penalty=l2;, score=0.122 total time=   2.3s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=hinge, penalty=l1;, score=0.657 total time=   4.4s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=hinge, penalty=l1;, score=0.220 total time=   5.5s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=hinge, penalty=l1;, score=0.658 total time=   3.8s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=hinge, penalty=elasticnet;, score=0.657 total time=   5.0s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=hinge, penalty=elasticnet;, score=0.658 total time=   4.4s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=hinge, penalty=elasticnet;, score=0.658 total time=   4.1s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=log, penalty=l2;, score=0.657 total time=   3.2s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=log, penalty=l2;, score=0.646 total time=   3.5s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=log, penalty=l2;, score=0.658 total time=   5.1s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=log, penalty=l1;, score=0.657 total time=   5.6s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=log, penalty=elasticnet;, score=0.658 total time=   9.3s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=modified_huber, penalty=elasticnet;, score=0.657 total time=   3.5s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=modified_huber, penalty=elasticnet;, score=0.658 total time=   4.7s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=squared_hinge, penalty=elasticnet;, score=0.658 total time=   3.2s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=perceptron, penalty=l2;, score=0.653 total time=   2.1s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=perceptron, penalty=l2;, score=0.658 total time=   2.5s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=perceptron, penalty=l1;, score=0.220 total time=   5.0s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=perceptron, penalty=elasticnet;, score=0.658 total time=   4.0s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=squared_loss, penalty=l1;, score=0.328 total time=   6.9s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=huber, penalty=l2;, score=0.220 total time=   3.0s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=huber, penalty=l1;, score=0.658 total time=   4.0s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=hinge, penalty=l1;, score=0.657 total time=   3.6s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=log, penalty=l2;, score=0.658 total time=   2.9s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=modified_huber, penalty=l2;, score=0.660 total time=   4.2s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=modified_huber, penalty=elasticnet;, score=0.657 total time=   6.0s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=squared_hinge, penalty=l1;, score=0.516 total time= 9.5min
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=perceptron, penalty=elasticnet;, score=0.657 total time=  37.8s
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=squared_loss, penalty=l1;, score=0.363 total time= 8.0min
[CV 2/3] END activation=tanh, alpha=0.0001, learning_rate=constant, solver=adam;, score=0.534 total time= 4.3min
[CV 1/3] END activation=tanh, alpha=0.05, learning_rate=constant, solver=adam;, score=0.564 total time= 3.0min
[CV 2/3] END activation=tanh, alpha=0.05, learning_rate=adaptive, solver=sgd;, score=0.626 total time=20.2min
[CV 1/3] END activation=relu, alpha=0.05, learning_rate=constant, solver=sgd;, score=0.648 total time=19.5min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
[CV 3/3] END activation=tanh, alpha=0.0001, learning_rate=adaptive, solver=sgd;, score=0.634 total time=20.7min
[CV 2/3] END activation=relu, alpha=0.0001, learning_rate=constant, solver=lbfgs;, score=0.563 total time= 6.8min
[CV 2/3] END activation=relu, alpha=0.05, learning_rate=constant, solver=sgd;, score=0.628 total time=19.5min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
[CV 1/3] END activation=tanh, alpha=0.0001, learning_rate=adaptive, solver=lbfgs;, score=0.574 total time= 2.7min
[CV 2/3] END activation=tanh, alpha=0.0001, learning_rate=adaptive, solver=lbfgs;, score=0.544 total time= 3.4min
[CV 3/3] END activation=tanh, alpha=0.05, learning_rate=constant, solver=lbfgs;, score=0.568 total time= 8.0min
[CV 2/3] END activation=tanh, alpha=0.05, learning_rate=adaptive, solver=lbfgs;, score=0.545 total time= 5.8min
[CV 1/3] END activation=relu, alpha=0.0001, learning_rate=constant, solver=adam;, score=0.577 total time= 3.7min
[CV 1/3] END activation=relu, alpha=0.0001, learning_rate=adaptive, solver=adam;, score=0.575 total time= 3.2min
[CV 2/3] END activation=relu, alpha=0.0001, learning_rate=adaptive, solver=lbfgs;, score=0.558 total time= 3.5min
[CV 2/3] END activation=relu, alpha=0.05, learning_rate=constant, solver=lbfgs;, score=0.579 total time=17.6min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)
[CV 3/3] END activation=tanh, alpha=0.0001, learning_rate=constant, solver=lbfgs;, score=0.574 total time= 3.9min
[CV 2/3] END activation=tanh, alpha=0.05, learning_rate=constant, solver=sgd;, score=0.621 total time=20.6min
[CV 3/3] END activation=relu, alpha=0.0001, learning_rate=adaptive, solver=adam;, score=0.581 total time= 3.7min
[CV 3/3] END activation=relu, alpha=0.05, learning_rate=constant, solver=adam;, score=0.615 total time= 3.7min
[CV 1/3] END activation=relu, alpha=0.05, learning_rate=adaptive, solver=sgd;, score=0.637 total time=16.4min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
[CV 2/3] END activation=tanh, alpha=0.0001, learning_rate=adaptive, solver=sgd;, score=0.619 total time=20.8min
[CV 3/3] END activation=relu, alpha=0.0001, learning_rate=constant, solver=lbfgs;, score=0.573 total time=13.4min
[CV 3/3] END activation=relu, alpha=0.05, learning_rate=adaptive, solver=sgd;, score=0.639 total time=15.0min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
[CV 2/3] END activation=tanh, alpha=0.0001, learning_rate=adaptive, solver=adam;, score=0.534 total time= 4.4min
[CV 2/3] END activation=tanh, alpha=0.05, learning_rate=constant, solver=adam;, score=0.561 total time= 2.9min
[CV 3/3] END activation=tanh, alpha=0.05, learning_rate=adaptive, solver=sgd;, score=0.635 total time=20.5min
[CV 1/3] END activation=relu, alpha=0.05, learning_rate=constant, solver=adam;, score=0.627 total time= 4.1min
[CV 2/3] END activation=relu, alpha=0.05, learning_rate=adaptive, solver=sgd;, score=0.634 total time=17.5min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=hinge, penalty=elasticnet;, score=0.495 total time=  10.7s
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=modified_huber, penalty=elasticnet;, score=0.658 total time=  11.9s
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=squared_hinge, penalty=elasticnet;, score=0.587 total time=  10.3s
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=perceptron, penalty=elasticnet;, score=0.563 total time=  12.1s
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=huber, penalty=l1;, score=0.141 total time=  31.1s
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=modified_huber, penalty=l2;, score=0.553 total time=   9.5s
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=modified_huber, penalty=l1;, score=0.557 total time= 1.2min
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=huber, penalty=l2;, score=0.593 total time=  12.3s
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=huber, penalty=l1;, score=0.628 total time=  20.6s
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=hinge, penalty=l2;, score=0.584 total time=   8.1s
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=hinge, penalty=elasticnet;, score=0.577 total time=  42.2s
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=log, penalty=l1;, score=0.587 total time=  47.6s
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=modified_huber, penalty=l1;, score=0.555 total time= 1.0min
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_hinge, penalty=elasticnet;, score=0.543 total time=  43.8s
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=perceptron, penalty=l1;, score=0.545 total time=  43.5s
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_loss, penalty=l2;, score=0.346 total time= 6.0min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=hinge, penalty=l1;, score=0.552 total time= 1.7min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=log, penalty=l1;, score=0.553 total time= 2.6min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=modified_huber, penalty=elasticnet;, score=0.545 total time= 1.7min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_hinge, penalty=l2;, score=0.548 total time= 1.9min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=perceptron, penalty=l1;, score=0.545 total time= 1.8min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_loss, penalty=l1;, score=0.321 total time=14.0min
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=modified_huber, penalty=elasticnet;, score=0.658 total time=  54.4s
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=squared_hinge, penalty=elasticnet;, score=0.658 total time=  53.1s
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=perceptron, penalty=l1;, score=0.220 total time=  36.4s
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=squared_loss, penalty=l1;, score=0.367 total time= 8.1min
[CV 1/3] END activation=tanh, alpha=0.0001, learning_rate=constant, solver=adam;, score=0.536 total time= 5.4min
[CV 2/3] END activation=tanh, alpha=0.05, learning_rate=constant, solver=lbfgs;, score=0.550 total time= 8.3min
[CV 1/3] END activation=tanh, alpha=0.05, learning_rate=adaptive, solver=lbfgs;, score=0.573 total time= 7.0min
[CV 1/3] END activation=relu, alpha=0.0001, learning_rate=constant, solver=lbfgs;, score=0.581 total time= 6.3min
[CV 3/3] END activation=relu, alpha=0.0001, learning_rate=adaptive, solver=lbfgs;, score=0.576 total time=13.6min
[CV 2/3] END activation=relu, alpha=0.05, learning_rate=adaptive, solver=lbfgs;, score=0.588 total time=11.2min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)
[CV 1/3] END activation=tanh, alpha=0.0001, learning_rate=adaptive, solver=sgd;, score=0.634 total time=19.3min
[CV 2/3] END activation=relu, alpha=0.0001, learning_rate=constant, solver=sgd;, score=0.627 total time=18.6min
[CV 2/3] END activation=relu, alpha=0.05, learning_rate=adaptive, solver=adam;, score=0.592 total time= 3.2min
[CV 3/3] END activation=relu, alpha=0.05, learning_rate=adaptive, solver=lbfgs;, score=0.598 total time=11.1min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)
saving: MLP_no_linked_1637242963 as png
saving all
Saving to: no_linked_k-Nearest Neighbour_model_container_454789.7121506714
Saving to: no_linked_Guassian Naive Bayes_model_container_454789.71220010455
Saving to: no_linked_Multinominal Naive Bayes_model_container_454789.7122052181
Saving to: no_linked_Decision Tree_model_container_454789.7122102479
Saving to: no_linked_Support Vector Machine (classifier)_model_container_454789.7122152495
Saving to: no_linked_Stochastic Gradient Descent_model_container_454789.7122638356
Saving to: no_linked_Multi-layer Perceptron_model_container_454789.71226904134
saving: no_linked_comparison_1637242964 as png
Fitting 3 folds for each of 160 candidates, totalling 480 fits
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
[CV 3/3] END algorithm=auto, n_neighbors=1, weights=uniform;, score=0.612 total time=   7.9s
[CV 1/3] END algorithm=auto, n_neighbors=4, weights=uniform;, score=0.659 total time=   8.2s
[CV 2/3] END algorithm=auto, n_neighbors=6, weights=distance;, score=0.617 total time=   8.1s
[CV 1/3] END algorithm=auto, n_neighbors=10, weights=uniform;, score=0.661 total time=   7.9s
[CV 2/3] END algorithm=auto, n_neighbors=12, weights=distance;, score=0.645 total time=   7.9s
[CV 1/3] END algorithm=auto, n_neighbors=15, weights=distance;, score=0.664 total time=   7.6s
[CV 1/3] END algorithm=auto, n_neighbors=18, weights=uniform;, score=0.665 total time=   7.7s
[CV 2/3] END algorithm=auto, n_neighbors=20, weights=distance;, score=0.658 total time=   5.3s
[CV 1/3] END algorithm=ball_tree, n_neighbors=2, weights=distance;, score=0.627 total time= 1.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=5, weights=uniform;, score=0.636 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=7, weights=distance;, score=0.634 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=10, weights=uniform;, score=0.647 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=12, weights=distance;, score=0.653 total time= 1.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=15, weights=distance;, score=0.664 total time= 1.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=18, weights=uniform;, score=0.665 total time= 1.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=20, weights=distance;, score=0.663 total time= 1.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=3, weights=uniform;, score=0.661 total time= 2.2min
[CV 3/3] END algorithm=kd_tree, n_neighbors=5, weights=distance;, score=0.620 total time= 2.3min
[CV 3/3] END algorithm=kd_tree, n_neighbors=8, weights=uniform;, score=0.647 total time= 2.3min
[CV 3/3] END algorithm=kd_tree, n_neighbors=10, weights=distance;, score=0.648 total time= 2.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=13, weights=distance;, score=0.662 total time= 2.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=16, weights=uniform;, score=0.651 total time= 2.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=18, weights=distance;, score=0.663 total time= 2.5min
[CV 3/3] END algorithm=brute, n_neighbors=2, weights=uniform;, score=0.658 total time=   7.7s
[CV 1/3] END algorithm=brute, n_neighbors=3, weights=distance;, score=0.653 total time=   7.6s
[CV 3/3] END algorithm=brute, n_neighbors=4, weights=distance;, score=0.636 total time=   7.7s
[CV 1/3] END algorithm=brute, n_neighbors=6, weights=distance;, score=0.659 total time=   7.5s
[CV 1/3] END algorithm=brute, n_neighbors=8, weights=distance;, score=0.661 total time=   7.6s
[CV 2/3] END algorithm=brute, n_neighbors=10, weights=distance;, score=0.641 total time=   7.6s
[CV 1/3] END algorithm=brute, n_neighbors=13, weights=uniform;, score=0.660 total time=   7.6s
[CV 3/3] END algorithm=brute, n_neighbors=15, weights=uniform;, score=0.655 total time=   7.6s
[CV 3/3] END algorithm=brute, n_neighbors=17, weights=distance;, score=0.668 total time=   7.6s
[CV 3/3] END algorithm=brute, n_neighbors=20, weights=uniform;, score=0.661 total time=   5.4s
[CV 3/3] END class_weight=balanced, gamma=scale, kernel=poly;, score=0.674 total time=20.1min
[CV 3/3] END class_weight=None, gamma=scale, kernel=sigmoid;, score=0.671 total time=12.3min
[CV 1/3] END class_weight=None, gamma=auto, kernel=sigmoid;, score=0.657 total time=10.5min
[CV 1/3] END algorithm=auto, n_neighbors=2, weights=uniform;, score=0.661 total time=   8.1s
[CV 1/3] END algorithm=auto, n_neighbors=4, weights=distance;, score=0.651 total time=   8.2s
[CV 1/3] END algorithm=auto, n_neighbors=7, weights=distance;, score=0.662 total time=   8.0s
[CV 2/3] END algorithm=auto, n_neighbors=10, weights=uniform;, score=0.647 total time=   8.0s
[CV 1/3] END algorithm=auto, n_neighbors=13, weights=uniform;, score=0.660 total time=   7.8s
[CV 3/3] END algorithm=auto, n_neighbors=15, weights=distance;, score=0.664 total time=   7.6s
[CV 3/3] END algorithm=auto, n_neighbors=18, weights=uniform;, score=0.659 total time=   7.8s
[CV 2/3] END algorithm=ball_tree, n_neighbors=1, weights=uniform;, score=0.542 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=4, weights=uniform;, score=0.644 total time= 1.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=7, weights=uniform;, score=0.647 total time= 1.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=9, weights=distance;, score=0.629 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=11, weights=distance;, score=0.649 total time= 1.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=14, weights=distance;, score=0.663 total time= 1.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=17, weights=uniform;, score=0.643 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=19, weights=distance;, score=0.665 total time= 1.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=2, weights=distance;, score=0.627 total time= 2.0min
[CV 2/3] END algorithm=kd_tree, n_neighbors=5, weights=uniform;, score=0.636 total time= 2.3min
[CV 1/3] END algorithm=kd_tree, n_neighbors=8, weights=uniform;, score=0.662 total time= 2.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=10, weights=distance;, score=0.641 total time= 2.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=13, weights=uniform;, score=0.650 total time= 2.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=16, weights=uniform;, score=0.661 total time= 2.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=18, weights=distance;, score=0.655 total time= 2.4min
[CV 3/3] END algorithm=brute, n_neighbors=1, weights=uniform;, score=0.612 total time=   5.9s
[CV 3/3] END algorithm=brute, n_neighbors=1, weights=distance;, score=0.612 total time=   5.6s
[CV 1/3] END algorithm=brute, n_neighbors=2, weights=distance;, score=0.627 total time=   7.6s
[CV 3/3] END algorithm=brute, n_neighbors=3, weights=distance;, score=0.618 total time=   7.7s
[CV 2/3] END algorithm=brute, n_neighbors=5, weights=uniform;, score=0.636 total time=   7.8s
[CV 3/3] END algorithm=brute, n_neighbors=6, weights=distance;, score=0.642 total time=   7.6s
[CV 2/3] END algorithm=brute, n_neighbors=8, weights=distance;, score=0.620 total time=   7.6s
[CV 1/3] END algorithm=brute, n_neighbors=11, weights=uniform;, score=0.661 total time=   7.8s
[CV 3/3] END algorithm=brute, n_neighbors=13, weights=uniform;, score=0.650 total time=   7.7s
[CV 3/3] END algorithm=brute, n_neighbors=15, weights=distance;, score=0.664 total time=   7.5s
[CV 3/3] END algorithm=brute, n_neighbors=18, weights=uniform;, score=0.659 total time=   7.8s
[CV 2/3] END algorithm=brute, n_neighbors=20, weights=distance;, score=0.658 total time=   5.3s
[CV 3/3] END class_weight=balanced, gamma=scale, kernel=rbf;, score=0.612 total time=21.3min
[CV 3/3] END class_weight=None, gamma=scale, kernel=linear;, score=0.624 total time=12.7min
[CV 2/3] END class_weight=None, gamma=auto, kernel=sigmoid;, score=0.658 total time= 9.7min
[CV 3/3] END algorithm=auto, n_neighbors=3, weights=uniform;, score=0.629 total time=   8.0s
[CV 3/3] END algorithm=auto, n_neighbors=5, weights=uniform;, score=0.626 total time=   8.0s
[CV 2/3] END algorithm=auto, n_neighbors=7, weights=distance;, score=0.623 total time=   7.6s
[CV 1/3] END algorithm=auto, n_neighbors=9, weights=distance;, score=0.667 total time=   7.6s
[CV 2/3] END algorithm=auto, n_neighbors=12, weights=uniform;, score=0.650 total time=   7.8s
[CV 3/3] END algorithm=auto, n_neighbors=14, weights=distance;, score=0.659 total time=   7.6s
[CV 1/3] END algorithm=auto, n_neighbors=17, weights=distance;, score=0.664 total time=   7.6s
[CV 1/3] END algorithm=auto, n_neighbors=20, weights=uniform;, score=0.660 total time=   7.7s
[CV 2/3] END algorithm=ball_tree, n_neighbors=3, weights=uniform;, score=0.611 total time= 1.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=5, weights=distance;, score=0.599 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=8, weights=uniform;, score=0.647 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=11, weights=uniform;, score=0.651 total time= 1.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=14, weights=uniform;, score=0.663 total time= 1.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=16, weights=distance;, score=0.664 total time= 1.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=19, weights=uniform;, score=0.655 total time= 1.5min
[CV 3/3] END algorithm=kd_tree, n_neighbors=1, weights=distance;, score=0.612 total time= 1.7min
[CV 1/3] END algorithm=kd_tree, n_neighbors=4, weights=uniform;, score=0.659 total time= 2.3min
[CV 2/3] END algorithm=kd_tree, n_neighbors=6, weights=distance;, score=0.617 total time= 2.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=9, weights=uniform;, score=0.648 total time= 2.3min
[CV 1/3] END algorithm=kd_tree, n_neighbors=12, weights=uniform;, score=0.660 total time= 2.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=14, weights=distance;, score=0.650 total time= 2.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=17, weights=uniform;, score=0.660 total time= 2.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=20, weights=uniform;, score=0.660 total time= 2.4min
[CV 1/3] END algorithm=brute, n_neighbors=8, weights=uniform;, score=0.662 total time=   6.0s
[CV 3/3] END algorithm=brute, n_neighbors=9, weights=distance;, score=0.645 total time=   6.0s
[CV 3/3] END algorithm=brute, n_neighbors=11, weights=uniform;, score=0.651 total time=   6.1s
[CV 2/3] END algorithm=brute, n_neighbors=13, weights=uniform;, score=0.649 total time=   7.8s
[CV 2/3] END algorithm=brute, n_neighbors=15, weights=distance;, score=0.644 total time=   7.5s
[CV 1/3] END algorithm=brute, n_neighbors=18, weights=uniform;, score=0.665 total time=   7.7s
[CV 1/3] END algorithm=brute, n_neighbors=20, weights=distance;, score=0.663 total time=   6.4s
[CV 1/3] END class_weight=balanced, gamma=auto, kernel=sigmoid;, score=0.657 total time=20.8min
[CV 1/3] END class_weight=None, gamma=scale, kernel=linear;, score=0.628 total time=13.4min
[CV 3/3] END class_weight=None, gamma=auto, kernel=sigmoid;, score=0.658 total time= 9.7min
[CV 3/3] END algorithm=auto, n_neighbors=2, weights=distance;, score=0.612 total time=   8.0s
[CV 3/3] END algorithm=auto, n_neighbors=4, weights=distance;, score=0.636 total time=   8.0s
[CV 1/3] END algorithm=auto, n_neighbors=7, weights=uniform;, score=0.660 total time=   7.8s
[CV 2/3] END algorithm=auto, n_neighbors=9, weights=distance;, score=0.629 total time=   7.5s
[CV 3/3] END algorithm=auto, n_neighbors=12, weights=uniform;, score=0.652 total time=   7.8s
[CV 2/3] END algorithm=auto, n_neighbors=15, weights=uniform;, score=0.649 total time=   7.7s
[CV 2/3] END algorithm=auto, n_neighbors=17, weights=distance;, score=0.647 total time=   7.6s
[CV 1/3] END algorithm=auto, n_neighbors=20, weights=distance;, score=0.663 total time=   5.3s
[CV 3/3] END algorithm=ball_tree, n_neighbors=2, weights=uniform;, score=0.658 total time= 1.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=5, weights=uniform;, score=0.664 total time= 1.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=7, weights=distance;, score=0.623 total time= 1.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=10, weights=distance;, score=0.661 total time= 1.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=12, weights=distance;, score=0.645 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=15, weights=uniform;, score=0.655 total time= 1.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=18, weights=uniform;, score=0.657 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=20, weights=distance;, score=0.666 total time= 1.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=3, weights=uniform;, score=0.629 total time= 2.2min
[CV 2/3] END algorithm=kd_tree, n_neighbors=5, weights=distance;, score=0.599 total time= 2.3min
[CV 1/3] END algorithm=kd_tree, n_neighbors=8, weights=distance;, score=0.661 total time= 2.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=11, weights=uniform;, score=0.651 total time= 2.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=13, weights=distance;, score=0.655 total time= 2.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=16, weights=distance;, score=0.664 total time= 2.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=19, weights=uniform;, score=0.655 total time= 2.5min
[CV 2/3] END algorithm=brute, n_neighbors=4, weights=uniform;, score=0.601 total time=   8.0s
[CV 1/3] END algorithm=brute, n_neighbors=5, weights=distance;, score=0.667 total time=   7.8s
[CV 2/3] END algorithm=brute, n_neighbors=7, weights=uniform;, score=0.647 total time=   7.9s
[CV 3/3] END algorithm=brute, n_neighbors=9, weights=uniform;, score=0.648 total time=   7.7s
[CV 2/3] END algorithm=brute, n_neighbors=11, weights=distance;, score=0.642 total time=   7.7s
[CV 2/3] END algorithm=brute, n_neighbors=14, weights=uniform;, score=0.655 total time=   7.8s
[CV 2/3] END algorithm=brute, n_neighbors=16, weights=distance;, score=0.648 total time=   7.6s
[CV 1/3] END algorithm=brute, n_neighbors=19, weights=uniform;, score=0.661 total time=   7.8s
[CV 3/3] END class_weight=balanced, gamma=scale, kernel=sigmoid;, score=0.522 total time=17.1min
[CV 3/3] END class_weight=balanced, gamma=auto, kernel=poly;, score=0.220 total time=20.1min
[CV 1/3] END class_weight=None, gamma=auto, kernel=poly;, score=0.657 total time= 8.7min
[CV 3/3] END algorithm=auto, n_neighbors=2, weights=uniform;, score=0.658 total time=   8.3s
[CV 2/3] END algorithm=auto, n_neighbors=5, weights=distance;, score=0.599 total time=   8.2s
[CV 3/3] END algorithm=auto, n_neighbors=8, weights=distance;, score=0.651 total time=   8.3s
[CV 1/3] END algorithm=auto, n_neighbors=11, weights=distance;, score=0.664 total time=   8.4s
[CV 1/3] END algorithm=auto, n_neighbors=14, weights=uniform;, score=0.663 total time=   8.4s
[CV 2/3] END algorithm=auto, n_neighbors=16, weights=distance;, score=0.648 total time=   8.3s
[CV 3/3] END algorithm=auto, n_neighbors=19, weights=uniform;, score=0.660 total time=   8.3s
[CV 2/3] END algorithm=ball_tree, n_neighbors=2, weights=uniform;, score=0.623 total time= 1.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=4, weights=distance;, score=0.589 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=7, weights=uniform;, score=0.636 total time= 1.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=10, weights=uniform;, score=0.661 total time= 1.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=13, weights=uniform;, score=0.660 total time= 1.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=15, weights=distance;, score=0.644 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=18, weights=uniform;, score=0.659 total time= 1.5min
[CV 1/3] END algorithm=kd_tree, n_neighbors=1, weights=distance;, score=0.627 total time= 1.7min
[CV 2/3] END algorithm=kd_tree, n_neighbors=4, weights=uniform;, score=0.601 total time= 2.3min
[CV 3/3] END algorithm=kd_tree, n_neighbors=6, weights=distance;, score=0.642 total time= 2.3min
[CV 1/3] END algorithm=kd_tree, n_neighbors=9, weights=distance;, score=0.667 total time= 2.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=12, weights=uniform;, score=0.650 total time= 2.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=14, weights=distance;, score=0.659 total time= 2.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=17, weights=distance;, score=0.664 total time= 2.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=20, weights=uniform;, score=0.656 total time= 2.4min
[CV 1/3] END algorithm=brute, n_neighbors=10, weights=uniform;, score=0.661 total time=   7.8s
[CV 2/3] END algorithm=brute, n_neighbors=12, weights=uniform;, score=0.650 total time=   7.8s
[CV 1/3] END algorithm=brute, n_neighbors=14, weights=distance;, score=0.663 total time=   7.6s
[CV 1/3] END algorithm=brute, n_neighbors=17, weights=uniform;, score=0.661 total time=   7.6s
[CV 3/3] END algorithm=brute, n_neighbors=19, weights=uniform;, score=0.660 total time=   7.0s
[CV 2/3] END class_weight=balanced, gamma=scale, kernel=linear;, score=0.569 total time=14.8min
[CV 1/3] END class_weight=balanced, gamma=auto, kernel=poly;, score=0.657 total time=19.9min
[CV 2/3] END class_weight=None, gamma=auto, kernel=linear;, score=0.632 total time=12.1min
[CV 1/3] END algorithm=auto, n_neighbors=1, weights=distance;, score=0.627 total time=   7.6s
[CV 2/3] END algorithm=auto, n_neighbors=3, weights=distance;, score=0.566 total time=   7.5s
[CV 3/3] END algorithm=auto, n_neighbors=6, weights=uniform;, score=0.637 total time=   7.6s
[CV 1/3] END algorithm=auto, n_neighbors=9, weights=uniform;, score=0.662 total time=   7.7s
[CV 2/3] END algorithm=auto, n_neighbors=11, weights=distance;, score=0.642 total time=   7.6s
[CV 3/3] END algorithm=auto, n_neighbors=14, weights=uniform;, score=0.656 total time=   7.7s
[CV 1/3] END algorithm=auto, n_neighbors=17, weights=uniform;, score=0.661 total time=   7.8s
[CV 3/3] END algorithm=auto, n_neighbors=19, weights=distance;, score=0.665 total time=   7.6s
[CV 3/3] END algorithm=ball_tree, n_neighbors=2, weights=distance;, score=0.612 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=5, weights=uniform;, score=0.626 total time= 1.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=8, weights=uniform;, score=0.633 total time= 1.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=11, weights=uniform;, score=0.651 total time= 1.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=13, weights=distance;, score=0.640 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=16, weights=uniform;, score=0.663 total time= 1.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=19, weights=uniform;, score=0.661 total time= 1.5min
[CV 2/3] END algorithm=kd_tree, n_neighbors=1, weights=distance;, score=0.542 total time= 1.9min
[CV 1/3] END algorithm=kd_tree, n_neighbors=4, weights=distance;, score=0.651 total time= 2.3min
[CV 2/3] END algorithm=kd_tree, n_neighbors=7, weights=uniform;, score=0.647 total time= 2.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=9, weights=distance;, score=0.645 total time= 2.3min
[CV 1/3] END algorithm=kd_tree, n_neighbors=12, weights=distance;, score=0.662 total time= 2.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=15, weights=uniform;, score=0.649 total time= 2.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=17, weights=distance;, score=0.668 total time= 2.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=20, weights=distance;, score=0.663 total time= 2.5min
[CV 2/3] END algorithm=brute, n_neighbors=12, weights=distance;, score=0.645 total time=   7.5s
[CV 1/3] END algorithm=brute, n_neighbors=15, weights=uniform;, score=0.658 total time=   7.6s
[CV 3/3] END algorithm=brute, n_neighbors=17, weights=uniform;, score=0.660 total time=   7.7s
[CV 3/3] END algorithm=brute, n_neighbors=19, weights=distance;, score=0.665 total time=   6.7s
[CV 1/3] END class_weight=balanced, gamma=scale, kernel=rbf;, score=0.627 total time=21.4min
[CV 2/3] END class_weight=None, gamma=scale, kernel=poly;, score=0.670 total time=19.0min
[CV 3/3] END class_weight=None, gamma=auto, kernel=poly;, score=0.658 total time= 6.4min
[CV 1/3] END algorithm=auto, n_neighbors=3, weights=uniform;, score=0.661 total time=   8.1s
[CV 2/3] END algorithm=auto, n_neighbors=5, weights=uniform;, score=0.636 total time=   8.0s
[CV 3/3] END algorithm=auto, n_neighbors=7, weights=distance;, score=0.634 total time=   7.7s
[CV 3/3] END algorithm=auto, n_neighbors=9, weights=distance;, score=0.645 total time=   7.6s
[CV 1/3] END algorithm=auto, n_neighbors=12, weights=distance;, score=0.662 total time=   7.7s
[CV 1/3] END algorithm=auto, n_neighbors=15, weights=uniform;, score=0.658 total time=   7.8s
[CV 3/3] END algorithm=auto, n_neighbors=17, weights=distance;, score=0.668 total time=   7.5s
[CV 3/3] END algorithm=auto, n_neighbors=20, weights=uniform;, score=0.661 total time=   7.6s
[CV 3/3] END algorithm=ball_tree, n_neighbors=3, weights=uniform;, score=0.629 total time= 1.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=6, weights=uniform;, score=0.636 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=8, weights=distance;, score=0.651 total time= 1.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=11, weights=distance;, score=0.664 total time= 1.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=14, weights=uniform;, score=0.655 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=16, weights=distance;, score=0.661 total time= 1.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=19, weights=distance;, score=0.664 total time= 1.5min
[CV 2/3] END algorithm=kd_tree, n_neighbors=2, weights=uniform;, score=0.623 total time= 2.2min
[CV 3/3] END algorithm=kd_tree, n_neighbors=4, weights=distance;, score=0.636 total time= 2.2min
[CV 1/3] END algorithm=kd_tree, n_neighbors=7, weights=distance;, score=0.662 total time= 2.3min
[CV 2/3] END algorithm=kd_tree, n_neighbors=10, weights=uniform;, score=0.647 total time= 2.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=12, weights=distance;, score=0.653 total time= 2.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=15, weights=distance;, score=0.664 total time= 2.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=18, weights=uniform;, score=0.657 total time= 2.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=20, weights=distance;, score=0.666 total time= 2.8min
[CV 1/3] END class_weight=balanced, gamma=auto, kernel=linear;, score=0.572 total time=14.1min
[CV 2/3] END class_weight=balanced, gamma=auto, kernel=linear;, score=0.569 total time=13.9min
[CV 3/3] END class_weight=None, gamma=scale, kernel=poly;, score=0.671 total time=19.0min
[CV 3/3] END algorithm=auto, n_neighbors=1, weights=distance;, score=0.612 total time=   8.1s
[CV 3/3] END algorithm=auto, n_neighbors=4, weights=uniform;, score=0.644 total time=   8.0s
[CV 3/3] END algorithm=auto, n_neighbors=6, weights=distance;, score=0.642 total time=   7.6s
[CV 3/3] END algorithm=auto, n_neighbors=9, weights=uniform;, score=0.648 total time=   7.7s
[CV 1/3] END algorithm=auto, n_neighbors=12, weights=uniform;, score=0.660 total time=   7.7s
[CV 2/3] END algorithm=auto, n_neighbors=14, weights=distance;, score=0.650 total time=   7.7s
[CV 3/3] END algorithm=auto, n_neighbors=17, weights=uniform;, score=0.660 total time=   7.7s
[CV 2/3] END algorithm=auto, n_neighbors=20, weights=uniform;, score=0.656 total time=   7.7s
[CV 1/3] END algorithm=ball_tree, n_neighbors=3, weights=uniform;, score=0.661 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=5, weights=distance;, score=0.620 total time= 1.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=8, weights=distance;, score=0.661 total time= 1.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=10, weights=distance;, score=0.641 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=13, weights=uniform;, score=0.650 total time= 1.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=16, weights=uniform;, score=0.651 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=18, weights=distance;, score=0.663 total time= 1.5min
[CV 2/3] END algorithm=kd_tree, n_neighbors=1, weights=uniform;, score=0.542 total time= 1.9min
[CV 3/3] END algorithm=kd_tree, n_neighbors=4, weights=uniform;, score=0.644 total time= 2.2min
[CV 1/3] END algorithm=kd_tree, n_neighbors=7, weights=uniform;, score=0.660 total time= 2.3min
[CV 2/3] END algorithm=kd_tree, n_neighbors=9, weights=distance;, score=0.629 total time= 2.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=12, weights=uniform;, score=0.652 total time= 2.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=15, weights=uniform;, score=0.658 total time= 2.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=17, weights=distance;, score=0.647 total time= 2.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=20, weights=uniform;, score=0.661 total time= 2.6min
[CV 1/3] END algorithm=brute, n_neighbors=14, weights=uniform;, score=0.663 total time=   7.8s
[CV 3/3] END algorithm=brute, n_neighbors=16, weights=uniform;, score=0.663 total time=   7.8s
[CV 3/3] END algorithm=brute, n_neighbors=18, weights=distance;, score=0.663 total time=   7.5s
[CV 2/3] END class_weight=balanced, gamma=scale, kernel=sigmoid;, score=0.520 total time=17.1min
[CV 1/3] END class_weight=balanced, gamma=auto, kernel=rbf;, score=0.657 total time=22.5min
[CV 2/3] END class_weight=None, gamma=auto, kernel=poly;, score=0.658 total time= 7.9min
[CV 2/3] END algorithm=auto, n_neighbors=2, weights=uniform;, score=0.623 total time=   8.4s
[CV 3/3] END algorithm=auto, n_neighbors=5, weights=distance;, score=0.620 total time=   8.0s
[CV 1/3] END algorithm=auto, n_neighbors=8, weights=uniform;, score=0.662 total time=   8.3s
[CV 2/3] END algorithm=auto, n_neighbors=11, weights=uniform;, score=0.651 total time=   8.1s
[CV 3/3] END algorithm=auto, n_neighbors=13, weights=distance;, score=0.655 total time=   7.8s
[CV 1/3] END algorithm=auto, n_neighbors=16, weights=distance;, score=0.664 total time=   7.8s
[CV 2/3] END algorithm=auto, n_neighbors=19, weights=uniform;, score=0.655 total time=   7.9s
[CV 3/3] END algorithm=ball_tree, n_neighbors=1, weights=distance;, score=0.612 total time= 1.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=4, weights=uniform;, score=0.659 total time= 1.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=6, weights=distance;, score=0.617 total time= 1.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=9, weights=uniform;, score=0.653 total time= 1.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=12, weights=uniform;, score=0.650 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=14, weights=distance;, score=0.659 total time= 1.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=17, weights=distance;, score=0.664 total time= 1.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=20, weights=uniform;, score=0.656 total time= 1.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=2, weights=distance;, score=0.612 total time= 2.0min
[CV 3/3] END algorithm=kd_tree, n_neighbors=5, weights=uniform;, score=0.626 total time= 2.3min
[CV 3/3] END algorithm=kd_tree, n_neighbors=7, weights=distance;, score=0.634 total time= 2.3min
[CV 3/3] END algorithm=kd_tree, n_neighbors=10, weights=uniform;, score=0.647 total time= 2.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=13, weights=uniform;, score=0.660 total time= 2.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=15, weights=distance;, score=0.644 total time= 2.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=18, weights=uniform;, score=0.659 total time= 2.4min
[CV 1/3] END algorithm=brute, n_neighbors=1, weights=uniform;, score=0.627 total time=   5.9s
[CV 1/3] END algorithm=brute, n_neighbors=1, weights=distance;, score=0.627 total time=   5.8s
[CV 1/3] END algorithm=brute, n_neighbors=2, weights=uniform;, score=0.661 total time=   5.9s
[CV 3/3] END algorithm=brute, n_neighbors=2, weights=distance;, score=0.612 total time=   5.7s
[CV 1/3] END algorithm=brute, n_neighbors=4, weights=uniform;, score=0.659 total time=   8.0s
[CV 3/3] END algorithm=brute, n_neighbors=5, weights=uniform;, score=0.626 total time=   7.7s
[CV 1/3] END algorithm=brute, n_neighbors=7, weights=uniform;, score=0.660 total time=   7.6s
[CV 1/3] END algorithm=brute, n_neighbors=9, weights=uniform;, score=0.662 total time=   7.6s
[CV 2/3] END algorithm=brute, n_neighbors=11, weights=uniform;, score=0.651 total time=   7.8s
[CV 1/3] END algorithm=brute, n_neighbors=13, weights=distance;, score=0.662 total time=   7.6s
[CV 1/3] END algorithm=brute, n_neighbors=16, weights=uniform;, score=0.661 total time=   7.7s
[CV 1/3] END algorithm=brute, n_neighbors=18, weights=distance;, score=0.666 total time=   7.6s
[CV 3/3] END algorithm=brute, n_neighbors=20, weights=distance;, score=0.666 total time=   5.1s
[CV 2/3] END class_weight=balanced, gamma=auto, kernel=sigmoid;, score=0.220 total time=21.0min
[CV 2/3] END class_weight=None, gamma=scale, kernel=linear;, score=0.632 total time=13.3min
[CV 1/3] END class_weight=None, gamma=auto, kernel=linear;, score=0.628 total time=13.2min
[CV 2/3] END algorithm=auto, n_neighbors=1, weights=distance;, score=0.542 total time=   8.2s
[CV 2/3] END algorithm=auto, n_neighbors=4, weights=distance;, score=0.589 total time=   8.0s
[CV 2/3] END algorithm=auto, n_neighbors=7, weights=uniform;, score=0.647 total time=   8.3s
[CV 3/3] END algorithm=auto, n_neighbors=10, weights=distance;, score=0.648 total time=   7.9s
[CV 3/3] END algorithm=auto, n_neighbors=13, weights=uniform;, score=0.650 total time=   8.1s
[CV 2/3] END algorithm=auto, n_neighbors=16, weights=uniform;, score=0.651 total time=   7.9s
[CV 3/3] END algorithm=auto, n_neighbors=18, weights=distance;, score=0.663 total time=   7.7s
[CV 1/3] END algorithm=ball_tree, n_neighbors=1, weights=distance;, score=0.627 total time= 1.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=4, weights=distance;, score=0.651 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=6, weights=distance;, score=0.642 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=9, weights=uniform;, score=0.648 total time= 1.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=11, weights=distance;, score=0.642 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=14, weights=uniform;, score=0.656 total time= 1.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=17, weights=uniform;, score=0.661 total time= 1.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=19, weights=distance;, score=0.654 total time= 1.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=2, weights=uniform;, score=0.658 total time= 2.0min
[CV 1/3] END algorithm=kd_tree, n_neighbors=5, weights=uniform;, score=0.664 total time= 2.3min
[CV 2/3] END algorithm=kd_tree, n_neighbors=7, weights=distance;, score=0.623 total time= 2.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=10, weights=distance;, score=0.661 total time= 2.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=13, weights=uniform;, score=0.649 total time= 2.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=15, weights=distance;, score=0.664 total time= 2.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=18, weights=distance;, score=0.666 total time= 2.4min
[CV 2/3] END algorithm=brute, n_neighbors=1, weights=uniform;, score=0.542 total time=   5.9s
[CV 2/3] END algorithm=brute, n_neighbors=1, weights=distance;, score=0.542 total time=   5.8s
[CV 2/3] END algorithm=brute, n_neighbors=2, weights=uniform;, score=0.623 total time=   5.9s
[CV 1/3] END algorithm=brute, n_neighbors=3, weights=uniform;, score=0.661 total time=   5.9s
[CV 3/3] END algorithm=brute, n_neighbors=4, weights=uniform;, score=0.644 total time=   8.0s
[CV 2/3] END algorithm=brute, n_neighbors=5, weights=distance;, score=0.599 total time=   7.9s
[CV 3/3] END algorithm=brute, n_neighbors=7, weights=uniform;, score=0.636 total time=   7.9s
[CV 1/3] END algorithm=brute, n_neighbors=9, weights=distance;, score=0.667 total time=   7.8s
[CV 3/3] END algorithm=brute, n_neighbors=11, weights=distance;, score=0.649 total time=   7.8s
[CV 3/3] END algorithm=brute, n_neighbors=14, weights=uniform;, score=0.656 total time=   7.9s
[CV 3/3] END algorithm=brute, n_neighbors=16, weights=distance;, score=0.661 total time=   7.7s
[CV 2/3] END algorithm=brute, n_neighbors=19, weights=uniform;, score=0.655 total time=   7.7s
[CV 3/3] END class_weight=balanced, gamma=scale, kernel=linear;, score=0.572 total time=14.6min
[CV 3/3] END class_weight=balanced, gamma=auto, kernel=linear;, score=0.572 total time=14.5min
[CV 1/3] END class_weight=None, gamma=scale, kernel=rbf;, score=0.675 total time=18.4min
[CV 2/3] END algorithm=auto, n_neighbors=1, weights=uniform;, score=0.542 total time=   7.8s
[CV 3/3] END algorithm=auto, n_neighbors=3, weights=distance;, score=0.618 total time=   7.6s
[CV 1/3] END algorithm=auto, n_neighbors=6, weights=distance;, score=0.659 total time=   7.5s
[CV 2/3] END algorithm=auto, n_neighbors=9, weights=uniform;, score=0.653 total time=   7.7s
[CV 3/3] END algorithm=auto, n_neighbors=11, weights=distance;, score=0.649 total time=   7.6s
[CV 1/3] END algorithm=auto, n_neighbors=14, weights=distance;, score=0.663 total time=   7.6s
[CV 2/3] END algorithm=auto, n_neighbors=17, weights=uniform;, score=0.643 total time=   7.6s
[CV 2/3] END algorithm=auto, n_neighbors=19, weights=distance;, score=0.654 total time=   7.6s
[CV 2/3] END algorithm=ball_tree, n_neighbors=2, weights=distance;, score=0.542 total time= 1.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=5, weights=distance;, score=0.667 total time= 1.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=8, weights=uniform;, score=0.662 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=10, weights=distance;, score=0.648 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=13, weights=distance;, score=0.655 total time= 1.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=16, weights=distance;, score=0.648 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=19, weights=uniform;, score=0.660 total time= 1.5min
[CV 1/3] END algorithm=kd_tree, n_neighbors=2, weights=uniform;, score=0.661 total time= 2.1min
[CV 2/3] END algorithm=kd_tree, n_neighbors=4, weights=distance;, score=0.589 total time= 2.3min
[CV 3/3] END algorithm=kd_tree, n_neighbors=7, weights=uniform;, score=0.636 total time= 2.3min
[CV 1/3] END algorithm=kd_tree, n_neighbors=10, weights=uniform;, score=0.661 total time= 2.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=12, weights=distance;, score=0.645 total time= 2.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=15, weights=uniform;, score=0.655 total time= 2.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=18, weights=uniform;, score=0.665 total time= 2.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=20, weights=distance;, score=0.658 total time= 2.8min
[CV 3/3] END class_weight=balanced, gamma=auto, kernel=sigmoid;, score=0.220 total time=19.8min
[CV 1/3] END class_weight=None, gamma=scale, kernel=sigmoid;, score=0.668 total time=12.0min
[CV 3/3] END class_weight=None, gamma=scale, kernel=rbf;, score=0.674 total time=16.2min
[CV 1/3] END algorithm=auto, n_neighbors=3, weights=distance;, score=0.653 total time=   8.2s
[CV 1/3] END algorithm=auto, n_neighbors=6, weights=uniform;, score=0.658 total time=   8.1s
[CV 2/3] END algorithm=auto, n_neighbors=8, weights=distance;, score=0.620 total time=   7.8s
[CV 1/3] END algorithm=auto, n_neighbors=10, weights=distance;, score=0.661 total time=   7.9s
[CV 2/3] END algorithm=auto, n_neighbors=13, weights=uniform;, score=0.649 total time=   7.8s
[CV 2/3] END algorithm=auto, n_neighbors=15, weights=distance;, score=0.644 total time=   7.7s
[CV 1/3] END algorithm=auto, n_neighbors=18, weights=distance;, score=0.666 total time=   7.6s
[CV 1/3] END algorithm=ball_tree, n_neighbors=1, weights=uniform;, score=0.627 total time= 1.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=3, weights=distance;, score=0.566 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=6, weights=uniform;, score=0.637 total time= 1.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=9, weights=distance;, score=0.667 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=12, weights=uniform;, score=0.652 total time= 1.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=15, weights=uniform;, score=0.658 total time= 1.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=17, weights=distance;, score=0.647 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=20, weights=uniform;, score=0.661 total time= 1.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=3, weights=uniform;, score=0.611 total time= 2.3min
[CV 2/3] END algorithm=kd_tree, n_neighbors=6, weights=uniform;, score=0.636 total time= 2.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=8, weights=distance;, score=0.651 total time= 2.3min
[CV 1/3] END algorithm=kd_tree, n_neighbors=11, weights=distance;, score=0.664 total time= 2.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=14, weights=uniform;, score=0.655 total time= 2.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=16, weights=distance;, score=0.661 total time= 2.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=19, weights=distance;, score=0.664 total time= 2.4min
[CV 2/3] END algorithm=brute, n_neighbors=3, weights=uniform;, score=0.611 total time=   6.0s
[CV 1/3] END algorithm=brute, n_neighbors=4, weights=distance;, score=0.651 total time=   6.0s
[CV 3/3] END algorithm=brute, n_neighbors=5, weights=distance;, score=0.620 total time=   6.0s
[CV 2/3] END algorithm=brute, n_neighbors=6, weights=distance;, score=0.617 total time=   6.0s
[CV 2/3] END algorithm=brute, n_neighbors=8, weights=uniform;, score=0.633 total time=   6.1s
[CV 2/3] END algorithm=brute, n_neighbors=10, weights=uniform;, score=0.647 total time=   6.1s
[CV 1/3] END algorithm=brute, n_neighbors=12, weights=uniform;, score=0.660 total time=   6.1s
[CV 2/3] END algorithm=brute, n_neighbors=13, weights=distance;, score=0.640 total time=   6.0s
[CV 1/3] END algorithm=brute, n_neighbors=15, weights=distance;, score=0.664 total time=   6.0s
[CV 1/3] END algorithm=brute, n_neighbors=17, weights=distance;, score=0.664 total time=   6.0s
[CV 1/3] END algorithm=brute, n_neighbors=19, weights=distance;, score=0.664 total time=   6.0s
[CV 1/3] END class_weight=balanced, gamma=scale, kernel=linear;, score=0.572 total time=15.0min
[CV 2/3] END class_weight=balanced, gamma=auto, kernel=poly;, score=0.220 total time=20.8min
[CV 3/3] END class_weight=None, gamma=auto, kernel=linear;, score=0.624 total time=12.3min
[CV 2/3] END algorithm=auto, n_neighbors=3, weights=uniform;, score=0.611 total time=   8.2s
[CV 2/3] END algorithm=auto, n_neighbors=6, weights=uniform;, score=0.636 total time=   8.0s
[CV 2/3] END algorithm=auto, n_neighbors=8, weights=uniform;, score=0.633 total time=   7.9s
[CV 3/3] END algorithm=auto, n_neighbors=10, weights=uniform;, score=0.647 total time=   7.8s
[CV 3/3] END algorithm=auto, n_neighbors=12, weights=distance;, score=0.653 total time=   7.6s
[CV 3/3] END algorithm=auto, n_neighbors=15, weights=uniform;, score=0.655 total time=   7.8s
[CV 2/3] END algorithm=auto, n_neighbors=18, weights=uniform;, score=0.657 total time=   7.7s
[CV 3/3] END algorithm=auto, n_neighbors=20, weights=distance;, score=0.666 total time=   7.5s
[CV 1/3] END algorithm=ball_tree, n_neighbors=3, weights=distance;, score=0.653 total time= 1.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=6, weights=uniform;, score=0.658 total time= 1.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=8, weights=distance;, score=0.620 total time= 1.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=11, weights=uniform;, score=0.661 total time= 1.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=13, weights=distance;, score=0.662 total time= 1.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=16, weights=uniform;, score=0.661 total time= 1.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=18, weights=distance;, score=0.666 total time= 1.5min
[CV 1/3] END algorithm=kd_tree, n_neighbors=1, weights=uniform;, score=0.627 total time= 1.7min
[CV 3/3] END algorithm=kd_tree, n_neighbors=3, weights=distance;, score=0.618 total time= 2.2min
[CV 3/3] END algorithm=kd_tree, n_neighbors=6, weights=uniform;, score=0.637 total time= 2.3min
[CV 1/3] END algorithm=kd_tree, n_neighbors=9, weights=uniform;, score=0.662 total time= 2.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=11, weights=distance;, score=0.642 total time= 2.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=14, weights=uniform;, score=0.656 total time= 2.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=17, weights=uniform;, score=0.661 total time= 2.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=19, weights=distance;, score=0.654 total time= 2.4min
[CV 2/3] END algorithm=brute, n_neighbors=6, weights=uniform;, score=0.636 total time=   6.0s
[CV 2/3] END algorithm=brute, n_neighbors=7, weights=distance;, score=0.623 total time=   6.0s
[CV 2/3] END algorithm=brute, n_neighbors=9, weights=uniform;, score=0.653 total time=   6.1s
[CV 3/3] END algorithm=brute, n_neighbors=10, weights=distance;, score=0.648 total time=   6.0s
[CV 1/3] END algorithm=brute, n_neighbors=12, weights=distance;, score=0.662 total time=   6.3s
[CV 3/3] END algorithm=brute, n_neighbors=14, weights=distance;, score=0.659 total time=   7.5s
[CV 2/3] END algorithm=brute, n_neighbors=17, weights=uniform;, score=0.643 total time=   7.6s
[CV 2/3] END algorithm=brute, n_neighbors=19, weights=distance;, score=0.654 total time=   6.6s
[CV 1/3] END class_weight=balanced, gamma=scale, kernel=poly;, score=0.673 total time=20.0min
[CV 2/3] END class_weight=None, gamma=scale, kernel=sigmoid;, score=0.660 total time=11.6min
[CV 2/3] END class_weight=None, gamma=scale, kernel=rbf;, score=0.667 total time=17.0min
[CV 2/3] END algorithm=auto, n_neighbors=2, weights=distance;, score=0.542 total time=   8.2s
[CV 1/3] END algorithm=auto, n_neighbors=5, weights=distance;, score=0.667 total time=   8.1s
[CV 1/3] END algorithm=auto, n_neighbors=8, weights=distance;, score=0.661 total time=   8.1s
[CV 1/3] END algorithm=auto, n_neighbors=11, weights=uniform;, score=0.661 total time=   8.1s
[CV 2/3] END algorithm=auto, n_neighbors=13, weights=distance;, score=0.640 total time=   7.8s
[CV 3/3] END algorithm=auto, n_neighbors=16, weights=uniform;, score=0.663 total time=   7.9s
[CV 1/3] END algorithm=auto, n_neighbors=19, weights=uniform;, score=0.661 total time=   7.8s
[CV 2/3] END algorithm=ball_tree, n_neighbors=1, weights=distance;, score=0.542 total time= 1.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=4, weights=uniform;, score=0.601 total time= 1.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=7, weights=uniform;, score=0.660 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=9, weights=distance;, score=0.645 total time= 1.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=12, weights=distance;, score=0.662 total time= 1.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=15, weights=uniform;, score=0.649 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=17, weights=distance;, score=0.668 total time= 1.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=20, weights=distance;, score=0.658 total time= 1.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=3, weights=distance;, score=0.653 total time= 2.2min
[CV 1/3] END algorithm=kd_tree, n_neighbors=6, weights=uniform;, score=0.658 total time= 2.3min
[CV 2/3] END algorithm=kd_tree, n_neighbors=8, weights=distance;, score=0.620 total time= 2.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=11, weights=uniform;, score=0.651 total time= 2.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=14, weights=uniform;, score=0.663 total time= 2.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=16, weights=distance;, score=0.648 total time= 2.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=19, weights=uniform;, score=0.660 total time= 2.4min
[CV 2/3] END algorithm=brute, n_neighbors=2, weights=distance;, score=0.542 total time=   5.9s
[CV 3/3] END algorithm=brute, n_neighbors=3, weights=uniform;, score=0.629 total time=   6.0s
[CV 2/3] END algorithm=brute, n_neighbors=4, weights=distance;, score=0.589 total time=   6.0s
[CV 1/3] END algorithm=brute, n_neighbors=6, weights=uniform;, score=0.658 total time=   6.1s
[CV 1/3] END algorithm=brute, n_neighbors=7, weights=distance;, score=0.662 total time=   6.0s
[CV 3/3] END algorithm=brute, n_neighbors=8, weights=distance;, score=0.651 total time=   6.0s
[CV 3/3] END algorithm=brute, n_neighbors=10, weights=uniform;, score=0.647 total time=   6.1s
[CV 3/3] END algorithm=brute, n_neighbors=12, weights=uniform;, score=0.652 total time=   6.1s
[CV 2/3] END algorithm=brute, n_neighbors=14, weights=distance;, score=0.650 total time=   6.0s
[CV 1/3] END algorithm=brute, n_neighbors=16, weights=distance;, score=0.664 total time=   6.0s
[CV 2/3] END algorithm=brute, n_neighbors=18, weights=uniform;, score=0.657 total time=   6.1s
[CV 1/3] END algorithm=brute, n_neighbors=20, weights=uniform;, score=0.660 total time=   5.4s
[CV 2/3] END class_weight=balanced, gamma=scale, kernel=poly;, score=0.674 total time=19.2min
[CV 3/3] END class_weight=balanced, gamma=auto, kernel=rbf;, score=0.220 total time=22.8min
[CV 3/3] END class_weight=None, gamma=auto, kernel=rbf;, score=0.658 total time= 7.0min
[CV 1/3] END algorithm=auto, n_neighbors=1, weights=uniform;, score=0.627 total time=   8.2s
[CV 1/3] END algorithm=auto, n_neighbors=5, weights=uniform;, score=0.664 total time=   8.3s
[CV 3/3] END algorithm=auto, n_neighbors=8, weights=uniform;, score=0.647 total time=   8.4s
[CV 3/3] END algorithm=auto, n_neighbors=11, weights=uniform;, score=0.651 total time=   8.4s
[CV 2/3] END algorithm=auto, n_neighbors=14, weights=uniform;, score=0.655 total time=   8.4s
[CV 3/3] END algorithm=auto, n_neighbors=16, weights=distance;, score=0.661 total time=   8.3s
[CV 1/3] END algorithm=auto, n_neighbors=19, weights=distance;, score=0.664 total time=   8.3s
[CV 1/3] END algorithm=ball_tree, n_neighbors=2, weights=uniform;, score=0.661 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=4, weights=distance;, score=0.636 total time= 1.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=7, weights=distance;, score=0.662 total time= 1.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=10, weights=uniform;, score=0.647 total time= 1.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=13, weights=uniform;, score=0.649 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=15, weights=distance;, score=0.664 total time= 1.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=18, weights=distance;, score=0.655 total time= 1.5min
[CV 3/3] END algorithm=kd_tree, n_neighbors=1, weights=uniform;, score=0.612 total time= 1.7min
[CV 2/3] END algorithm=kd_tree, n_neighbors=3, weights=distance;, score=0.566 total time= 2.3min
[CV 1/3] END algorithm=kd_tree, n_neighbors=6, weights=distance;, score=0.659 total time= 2.3min
[CV 2/3] END algorithm=kd_tree, n_neighbors=9, weights=uniform;, score=0.653 total time= 2.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=11, weights=distance;, score=0.649 total time= 2.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=14, weights=distance;, score=0.663 total time= 2.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=17, weights=uniform;, score=0.643 total time= 2.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=19, weights=distance;, score=0.665 total time= 2.4min
[CV 3/3] END algorithm=brute, n_neighbors=7, weights=distance;, score=0.634 total time=   6.0s
[CV 2/3] END algorithm=brute, n_neighbors=9, weights=distance;, score=0.629 total time=   7.2s
[CV 1/3] END algorithm=brute, n_neighbors=11, weights=distance;, score=0.664 total time=   7.5s
[CV 3/3] END algorithm=brute, n_neighbors=13, weights=distance;, score=0.655 total time=   7.5s
[CV 2/3] END algorithm=brute, n_neighbors=16, weights=uniform;, score=0.651 total time=   7.7s
[CV 2/3] END algorithm=brute, n_neighbors=18, weights=distance;, score=0.655 total time=   7.5s
[CV 1/3] END class_weight=balanced, gamma=scale, kernel=sigmoid;, score=0.533 total time=17.5min
[CV 2/3] END class_weight=balanced, gamma=auto, kernel=rbf;, score=0.220 total time=23.2min
[CV 1/3] END class_weight=None, gamma=auto, kernel=rbf;, score=0.657 total time= 8.8min
[CV 1/3] END algorithm=auto, n_neighbors=2, weights=distance;, score=0.627 total time=   8.0s
[CV 2/3] END algorithm=auto, n_neighbors=4, weights=uniform;, score=0.601 total time=   8.2s
[CV 3/3] END algorithm=auto, n_neighbors=7, weights=uniform;, score=0.636 total time=   8.2s
[CV 2/3] END algorithm=auto, n_neighbors=10, weights=distance;, score=0.641 total time=   8.0s
[CV 1/3] END algorithm=auto, n_neighbors=13, weights=distance;, score=0.662 total time=   7.6s
[CV 1/3] END algorithm=auto, n_neighbors=16, weights=uniform;, score=0.661 total time=   7.8s
[CV 2/3] END algorithm=auto, n_neighbors=18, weights=distance;, score=0.655 total time=   7.7s
[CV 3/3] END algorithm=ball_tree, n_neighbors=1, weights=uniform;, score=0.612 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=3, weights=distance;, score=0.618 total time= 1.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=6, weights=distance;, score=0.659 total time= 1.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=9, weights=uniform;, score=0.662 total time= 1.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=12, weights=uniform;, score=0.660 total time= 1.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=14, weights=distance;, score=0.650 total time= 1.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=17, weights=uniform;, score=0.660 total time= 1.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=20, weights=uniform;, score=0.660 total time= 1.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=2, weights=distance;, score=0.542 total time= 2.2min
[CV 1/3] END algorithm=kd_tree, n_neighbors=5, weights=distance;, score=0.667 total time= 2.3min
[CV 2/3] END algorithm=kd_tree, n_neighbors=8, weights=uniform;, score=0.633 total time= 2.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=11, weights=uniform;, score=0.661 total time= 2.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=13, weights=distance;, score=0.640 total time= 2.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=16, weights=uniform;, score=0.663 total time= 2.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=19, weights=uniform;, score=0.661 total time= 2.5min
[CV 2/3] END algorithm=brute, n_neighbors=3, weights=distance;, score=0.566 total time=   7.6s
[CV 1/3] END algorithm=brute, n_neighbors=5, weights=uniform;, score=0.664 total time=   7.6s
[CV 3/3] END algorithm=brute, n_neighbors=6, weights=uniform;, score=0.637 total time=   7.6s
[CV 3/3] END algorithm=brute, n_neighbors=8, weights=uniform;, score=0.647 total time=   7.6s
[CV 1/3] END algorithm=brute, n_neighbors=10, weights=distance;, score=0.661 total time=   7.5s
[CV 3/3] END algorithm=brute, n_neighbors=12, weights=distance;, score=0.653 total time=   7.5s
[CV 2/3] END algorithm=brute, n_neighbors=15, weights=uniform;, score=0.649 total time=   7.8s
[CV 2/3] END algorithm=brute, n_neighbors=17, weights=distance;, score=0.647 total time=   7.5s
[CV 2/3] END algorithm=brute, n_neighbors=20, weights=uniform;, score=0.656 total time=   6.0s
[CV 2/3] END class_weight=balanced, gamma=scale, kernel=rbf;, score=0.625 total time=21.4min
[CV 1/3] END class_weight=None, gamma=scale, kernel=poly;, score=0.668 total time=19.5min
[CV 2/3] END class_weight=None, gamma=auto, kernel=rbf;, score=0.658 total time= 8.7min
saving: KNN_summary_1637244800 as png
saving: DT_summary_1637244856 as png
Fitting 3 folds for each of 16 candidates, totalling 48 fits
saving: SVC_summary_1637248815 as png
Fitting 3 folds for each of 168 candidates, totalling 504 fits
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=log, penalty=l1;, score=0.499 total time=  31.7s
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=squared_loss, penalty=l2;, score=0.537 total time=   2.5s
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=squared_loss, penalty=l1;, score=0.291 total time=   7.0s
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=squared_loss, penalty=elasticnet;, score=0.187 total time=   7.4s
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=hinge, penalty=l1;, score=0.570 total time=  37.6s
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=modified_huber, penalty=l2;, score=0.588 total time=   8.8s
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=squared_hinge, penalty=l1;, score=0.570 total time= 1.1min
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=huber, penalty=l2;, score=0.606 total time=  11.6s
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=huber, penalty=elasticnet;, score=0.622 total time=  30.8s
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=hinge, penalty=elasticnet;, score=0.580 total time=  36.9s
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=log, penalty=elasticnet;, score=0.611 total time=  40.4s
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=modified_huber, penalty=l1;, score=0.569 total time= 1.1min
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_hinge, penalty=elasticnet;, score=0.555 total time= 1.1min
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_loss, penalty=l2;, score=0.338 total time= 6.0min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=hinge, penalty=l1;, score=0.557 total time= 1.7min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=log, penalty=elasticnet;, score=0.592 total time= 1.7min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=modified_huber, penalty=l1;, score=0.558 total time= 2.7min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=perceptron, penalty=l2;, score=0.570 total time=  12.9s
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=perceptron, penalty=l2;, score=0.565 total time=  12.8s
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=perceptron, penalty=l2;, score=0.566 total time=  13.0s
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=perceptron, penalty=l1;, score=0.567 total time= 1.7min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=perceptron, penalty=elasticnet;, score=0.572 total time= 1.5min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_loss, penalty=elasticnet;, score=0.324 total time=16.7min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=log, penalty=elasticnet;, score=0.360 total time=  16.9s
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=squared_hinge, penalty=l1;, score=0.597 total time=  30.3s
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=hinge, penalty=l2;, score=0.599 total time=   8.4s
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=log, penalty=l2;, score=0.609 total time=  10.1s
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=log, penalty=l1;, score=0.581 total time=  42.4s
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=perceptron, penalty=l1;, score=0.568 total time=  42.2s
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=squared_loss, penalty=l1;, score=0.346 total time=10.8min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=hinge, penalty=elasticnet;, score=0.586 total time= 1.5min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=log, penalty=elasticnet;, score=0.593 total time= 1.7min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=modified_huber, penalty=elasticnet;, score=0.567 total time= 1.6min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_hinge, penalty=l2;, score=0.550 total time= 1.8min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=perceptron, penalty=l1;, score=0.561 total time= 1.8min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_loss, penalty=l2;, score=0.361 total time= 5.8min
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=hinge, penalty=elasticnet;, score=0.657 total time=   4.5s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=log, penalty=l2;, score=0.657 total time=   3.3s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=log, penalty=l2;, score=0.658 total time=   5.1s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=log, penalty=l1;, score=0.658 total time=   8.1s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=modified_huber, penalty=l2;, score=0.657 total time=   2.2s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=modified_huber, penalty=l2;, score=0.220 total time=   2.5s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=modified_huber, penalty=elasticnet;, score=0.657 total time=   4.3s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=squared_hinge, penalty=l2;, score=0.658 total time=   2.5s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=squared_hinge, penalty=elasticnet;, score=0.657 total time=   3.8s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=perceptron, penalty=l2;, score=0.122 total time=   2.3s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=perceptron, penalty=l1;, score=0.658 total time=   4.8s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=squared_loss, penalty=l2;, score=0.214 total time=   3.2s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=squared_loss, penalty=l1;, score=0.350 total time=   6.9s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=squared_loss, penalty=elasticnet;, score=0.136 total time=   5.1s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=huber, penalty=l1;, score=0.658 total time=   3.9s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=hinge, penalty=l2;, score=0.658 total time=   2.1s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=hinge, penalty=l1;, score=0.658 total time=   3.6s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=log, penalty=l2;, score=0.658 total time=   2.7s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=log, penalty=elasticnet;, score=0.658 total time=   4.1s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=modified_huber, penalty=elasticnet;, score=0.658 total time=   5.0s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=squared_hinge, penalty=elasticnet;, score=0.658 total time=  10.5s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=perceptron, penalty=elasticnet;, score=0.290 total time=   3.3s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=squared_loss, penalty=l1;, score=0.658 total time=   4.5s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=huber, penalty=l2;, score=0.658 total time=   2.4s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=huber, penalty=l1;, score=0.658 total time=   3.9s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=hinge, penalty=l2;, score=0.661 total time=   9.5s
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=hinge, penalty=elasticnet;, score=0.657 total time=  16.4s
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=log, penalty=l2;, score=0.658 total time=   9.1s
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=log, penalty=elasticnet;, score=0.657 total time=  16.4s
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=modified_huber, penalty=l2;, score=0.635 total time=  13.3s
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=modified_huber, penalty=elasticnet;, score=0.555 total time=  33.4s
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=squared_hinge, penalty=l1;, score=0.552 total time=  44.0s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=perceptron, penalty=l1;, score=0.658 total time=  20.0s
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=squared_loss, penalty=l2;, score=0.658 total time=  17.6s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=squared_loss, penalty=elasticnet;, score=0.658 total time=  25.6s
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=huber, penalty=l1;, score=0.658 total time=   4.5s
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=hinge, penalty=l2;, score=0.657 total time=  20.8s
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=hinge, penalty=l1;, score=0.658 total time=  37.7s
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=log, penalty=l2;, score=0.657 total time=  30.6s
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=log, penalty=l1;, score=0.658 total time=  54.1s
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=modified_huber, penalty=l2;, score=0.660 total time=  28.7s
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=modified_huber, penalty=elasticnet;, score=0.658 total time=  48.3s
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=perceptron, penalty=l2;, score=0.576 total time=  14.1s
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=perceptron, penalty=l1;, score=0.220 total time=  40.5s
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=squared_loss, penalty=l2;, score=0.657 total time=  36.2s
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=squared_loss, penalty=elasticnet;, score=0.658 total time=  58.1s
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=huber, penalty=l1;, score=0.658 total time=  42.2s
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=hinge, penalty=l1;, score=0.607 total time=  23.7s
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=perceptron, penalty=l2;, score=0.580 total time=   2.5s
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=perceptron, penalty=l1;, score=0.599 total time=  25.2s
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=hinge, penalty=elasticnet;, score=0.602 total time=  38.8s
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=modified_huber, penalty=elasticnet;, score=0.601 total time=  59.4s
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=squared_loss, penalty=l1;, score=0.333 total time=10.9min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=log, penalty=l2;, score=0.598 total time=  32.5s
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=log, penalty=l2;, score=0.583 total time=  34.4s
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=log, penalty=l1;, score=0.559 total time= 2.4min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=modified_huber, penalty=elasticnet;, score=0.566 total time= 1.6min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_hinge, penalty=l1;, score=0.542 total time= 3.2min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_loss, penalty=l2;, score=0.333 total time= 5.5min
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=hinge, penalty=l2;, score=0.657 total time=   3.6s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=hinge, penalty=l2;, score=0.658 total time=   2.8s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=hinge, penalty=l2;, score=0.655 total time=   3.0s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=hinge, penalty=l1;, score=0.658 total time=   5.5s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=hinge, penalty=elasticnet;, score=0.658 total time=   4.8s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=log, penalty=l2;, score=0.658 total time=   3.7s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=log, penalty=l1;, score=0.658 total time=   4.8s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=log, penalty=elasticnet;, score=0.658 total time=   6.3s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=modified_huber, penalty=l2;, score=0.658 total time=   2.2s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=modified_huber, penalty=l1;, score=0.658 total time=   3.6s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=squared_hinge, penalty=l2;, score=0.657 total time=   2.9s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=squared_hinge, penalty=l1;, score=0.578 total time=  30.1s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=huber, penalty=elasticnet;, score=0.657 total time=   4.8s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=hinge, penalty=elasticnet;, score=0.658 total time=   3.5s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=log, penalty=l1;, score=0.658 total time=   4.6s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=modified_huber, penalty=elasticnet;, score=0.657 total time=   5.7s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=squared_hinge, penalty=elasticnet;, score=0.657 total time=  11.6s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=squared_loss, penalty=l1;, score=0.657 total time=   6.2s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=squared_loss, penalty=elasticnet;, score=0.658 total time=   4.7s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=huber, penalty=elasticnet;, score=0.658 total time=   3.9s
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=hinge, penalty=l1;, score=0.657 total time=  17.9s
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=hinge, penalty=elasticnet;, score=0.658 total time=  19.7s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=log, penalty=elasticnet;, score=0.658 total time=  15.6s
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=modified_huber, penalty=l1;, score=0.657 total time=  34.7s
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=modified_huber, penalty=elasticnet;, score=0.658 total time=  30.8s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=squared_hinge, penalty=elasticnet;, score=0.658 total time=  28.8s
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=perceptron, penalty=l1;, score=0.658 total time=  17.3s
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=squared_loss, penalty=l2;, score=0.656 total time=  17.3s
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=squared_loss, penalty=elasticnet;, score=0.658 total time=  23.0s
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=huber, penalty=elasticnet;, score=0.657 total time=   4.2s
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=hinge, penalty=l2;, score=0.658 total time=  19.4s
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=hinge, penalty=l1;, score=0.658 total time=  38.3s
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=hinge, penalty=elasticnet;, score=0.658 total time=  39.3s
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=log, penalty=l1;, score=0.658 total time=  46.6s
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=modified_huber, penalty=l2;, score=0.660 total time=  24.8s
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=modified_huber, penalty=l1;, score=0.658 total time=  50.9s
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=squared_hinge, penalty=elasticnet;, score=0.658 total time=  56.8s
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=squared_loss, penalty=l2;, score=0.658 total time=  31.7s
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=squared_loss, penalty=elasticnet;, score=0.657 total time= 1.0min
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=huber, penalty=l1;, score=0.658 total time=  43.9s
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=hinge, penalty=elasticnet;, score=0.617 total time=  10.3s
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=modified_huber, penalty=elasticnet;, score=0.639 total time=   9.7s
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=squared_hinge, penalty=elasticnet;, score=0.496 total time=   7.9s
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=perceptron, penalty=elasticnet;, score=0.598 total time=  14.8s
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=huber, penalty=l1;, score=0.610 total time=  26.7s
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=log, penalty=elasticnet;, score=0.583 total time=  33.7s
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=perceptron, penalty=l2;, score=0.549 total time=   6.7s
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=perceptron, penalty=l1;, score=0.576 total time=  35.8s
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=squared_loss, penalty=l2;, score=0.343 total time= 5.5min
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_loss, penalty=elasticnet;, score=0.352 total time=18.6min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=huber, penalty=elasticnet;, score=0.651 total time= 1.5min
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=squared_hinge, penalty=l2;, score=0.220 total time=   2.7s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=squared_hinge, penalty=elasticnet;, score=0.658 total time=   3.8s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=perceptron, penalty=l2;, score=0.220 total time=   2.2s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=perceptron, penalty=elasticnet;, score=0.657 total time=   4.7s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=squared_loss, penalty=l2;, score=0.125 total time=   4.0s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=squared_loss, penalty=l1;, score=0.364 total time=   6.9s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=huber, penalty=l2;, score=0.217 total time=   3.0s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=huber, penalty=l2;, score=0.130 total time=   4.0s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=huber, penalty=elasticnet;, score=0.658 total time=   4.3s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=hinge, penalty=elasticnet;, score=0.658 total time=   3.6s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=log, penalty=elasticnet;, score=0.657 total time=   4.3s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=modified_huber, penalty=l1;, score=0.658 total time=   5.5s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=squared_hinge, penalty=l1;, score=0.529 total time= 6.3min
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=modified_huber, penalty=l2;, score=0.661 total time=  28.3s
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=modified_huber, penalty=elasticnet;, score=0.657 total time=  45.5s
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=squared_hinge, penalty=l1;, score=0.562 total time= 2.8min
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=huber, penalty=elasticnet;, score=0.657 total time=  40.5s
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=log, penalty=l2;, score=0.609 total time=   4.0s
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=modified_huber, penalty=l2;, score=0.642 total time=   1.8s
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=modified_huber, penalty=l1;, score=0.569 total time=  31.2s
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=squared_loss, penalty=elasticnet;, score=0.139 total time=   7.4s
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=hinge, penalty=l2;, score=0.601 total time=   9.4s
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=hinge, penalty=elasticnet;, score=0.591 total time=  38.1s
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=squared_hinge, penalty=l2;, score=0.595 total time=   8.1s
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=squared_hinge, penalty=elasticnet;, score=0.576 total time=  52.6s
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=squared_loss, penalty=elasticnet;, score=0.344 total time=18.5min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=perceptron, penalty=l1;, score=0.560 total time= 1.8min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_loss, penalty=l1;, score=0.311 total time=13.4min
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=squared_hinge, penalty=l2;, score=0.660 total time=  28.9s
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=perceptron, penalty=l1;, score=0.220 total time=  39.2s
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=perceptron, penalty=elasticnet;, score=0.571 total time=  38.9s
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=huber, penalty=l2;, score=0.657 total time=  26.1s
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=huber, penalty=l2;, score=0.658 total time=  26.1s
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=huber, penalty=l2;, score=0.658 total time=  26.1s
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=huber, penalty=elasticnet;, score=0.658 total time=  38.9s
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=hinge, penalty=l1;, score=0.597 total time=  30.8s
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=perceptron, penalty=elasticnet;, score=0.628 total time=  11.4s
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=huber, penalty=l1;, score=0.277 total time=  26.1s
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=log, penalty=elasticnet;, score=0.583 total time=  28.7s
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=squared_hinge, penalty=l1;, score=0.567 total time=  48.9s
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=squared_loss, penalty=l2;, score=0.333 total time= 5.5min
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_loss, penalty=elasticnet;, score=0.321 total time=18.6min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=huber, penalty=elasticnet;, score=0.645 total time= 1.5min
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=modified_huber, penalty=l1;, score=0.602 total time=   5.0s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=squared_hinge, penalty=l1;, score=0.575 total time=  31.1s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=huber, penalty=elasticnet;, score=0.658 total time=   4.4s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=hinge, penalty=elasticnet;, score=0.657 total time=   3.4s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=log, penalty=l1;, score=0.658 total time=   4.6s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=modified_huber, penalty=l1;, score=0.658 total time=   5.9s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=squared_hinge, penalty=l1;, score=0.526 total time= 5.9min
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=log, penalty=elasticnet;, score=0.658 total time=  51.1s
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=modified_huber, penalty=l1;, score=0.658 total time=  46.4s
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=squared_hinge, penalty=l1;, score=0.564 total time= 3.6min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=hinge, penalty=elasticnet;, score=0.606 total time=  11.2s
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=squared_hinge, penalty=l2;, score=0.646 total time=   2.0s
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=squared_hinge, penalty=l2;, score=0.528 total time=   1.9s
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=squared_hinge, penalty=l2;, score=0.519 total time=   2.6s
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=squared_hinge, penalty=l1;, score=0.530 total time=  37.0s
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=log, penalty=l2;, score=0.604 total time=  10.7s
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=log, penalty=l1;, score=0.585 total time=  38.7s
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=perceptron, penalty=l2;, score=0.569 total time=   7.0s
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=perceptron, penalty=elasticnet;, score=0.594 total time=  42.3s
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=squared_loss, penalty=elasticnet;, score=0.370 total time=11.8min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=log, penalty=l2;, score=0.590 total time=  32.3s
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=modified_huber, penalty=l2;, score=0.565 total time=  14.5s
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=modified_huber, penalty=l2;, score=0.562 total time=  16.0s
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=modified_huber, penalty=l2;, score=0.567 total time=  15.1s
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=modified_huber, penalty=l1;, score=0.563 total time= 2.5min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_hinge, penalty=l1;, score=0.566 total time= 5.4min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=huber, penalty=l2;, score=0.606 total time=  31.9s
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=huber, penalty=l2;, score=0.606 total time=  32.5s
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=huber, penalty=l2;, score=0.616 total time=  33.2s
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=huber, penalty=l1;, score=0.666 total time= 1.2min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=huber, penalty=l1;, score=0.654 total time= 1.1min
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=hinge, penalty=l1;, score=0.657 total time=   4.3s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=hinge, penalty=l1;, score=0.658 total time=   4.3s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=hinge, penalty=elasticnet;, score=0.220 total time=   4.4s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=log, penalty=l1;, score=0.220 total time=   5.4s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=log, penalty=elasticnet;, score=0.657 total time=   4.7s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=log, penalty=elasticnet;, score=0.658 total time=   6.6s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=modified_huber, penalty=l1;, score=0.657 total time=   3.5s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=modified_huber, penalty=elasticnet;, score=0.122 total time=   4.5s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=squared_hinge, penalty=elasticnet;, score=0.658 total time=   4.3s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=perceptron, penalty=l1;, score=0.658 total time=   5.1s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=perceptron, penalty=elasticnet;, score=0.658 total time=   5.5s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=squared_loss, penalty=l1;, score=0.216 total time=   6.8s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=huber, penalty=l2;, score=0.122 total time=   3.2s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=huber, penalty=l1;, score=0.657 total time=   4.8s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=hinge, penalty=l2;, score=0.657 total time=   2.1s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=hinge, penalty=l1;, score=0.657 total time=   3.6s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=log, penalty=l2;, score=0.657 total time=   2.9s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=modified_huber, penalty=l2;, score=0.661 total time=   4.1s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=modified_huber, penalty=elasticnet;, score=0.658 total time=   6.2s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=squared_hinge, penalty=elasticnet;, score=0.658 total time=   6.2s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=perceptron, penalty=l1;, score=0.220 total time=   3.4s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=squared_loss, penalty=l2;, score=0.658 total time=   3.4s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=squared_loss, penalty=elasticnet;, score=0.657 total time=   4.5s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=huber, penalty=l2;, score=0.658 total time=   2.4s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=huber, penalty=elasticnet;, score=0.657 total time=   3.8s
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=hinge, penalty=l2;, score=0.658 total time=  10.0s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=hinge, penalty=elasticnet;, score=0.658 total time=  21.0s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=log, penalty=l1;, score=0.658 total time=  13.3s
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=modified_huber, penalty=l2;, score=0.611 total time=  17.2s
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=modified_huber, penalty=l1;, score=0.658 total time=  35.1s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=squared_hinge, penalty=l2;, score=0.623 total time=  19.0s
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=squared_hinge, penalty=elasticnet;, score=0.657 total time=  24.6s
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=perceptron, penalty=l1;, score=0.657 total time=  20.4s
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=perceptron, penalty=elasticnet;, score=0.122 total time=  18.2s
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=squared_loss, penalty=elasticnet;, score=0.657 total time=  21.1s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=huber, penalty=l2;, score=0.658 total time=   2.9s
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=huber, penalty=l1;, score=0.657 total time=   4.5s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=huber, penalty=elasticnet;, score=0.658 total time=   4.5s
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=hinge, penalty=l2;, score=0.658 total time=  18.8s
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=hinge, penalty=elasticnet;, score=0.657 total time=  37.7s
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=log, penalty=l2;, score=0.658 total time=  29.5s
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=log, penalty=l1;, score=0.657 total time=  46.9s
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=log, penalty=elasticnet;, score=0.658 total time=  52.5s
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=squared_hinge, penalty=l2;, score=0.660 total time=  29.6s
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=squared_hinge, penalty=l1;, score=0.551 total time= 3.7min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=hinge, penalty=l1;, score=0.559 total time=  24.9s
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=perceptron, penalty=l2;, score=0.565 total time=   2.2s
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=perceptron, penalty=elasticnet;, score=0.619 total time=  16.2s
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=huber, penalty=l1;, score=0.223 total time=  27.7s
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=modified_huber, penalty=l2;, score=0.556 total time=   9.2s
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=modified_huber, penalty=l2;, score=0.568 total time=   9.1s
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=modified_huber, penalty=l1;, score=0.565 total time= 1.4min
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=huber, penalty=elasticnet;, score=0.608 total time=  31.5s
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=hinge, penalty=elasticnet;, score=0.586 total time=  41.1s
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=log, penalty=elasticnet;, score=0.615 total time=  33.7s
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=modified_huber, penalty=l1;, score=0.560 total time= 1.2min
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_hinge, penalty=elasticnet;, score=0.576 total time=  40.9s
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=perceptron, penalty=l1;, score=0.582 total time=  42.8s
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_loss, penalty=l1;, score=0.372 total time=15.3min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_loss, penalty=l1;, score=0.312 total time=13.9min
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=squared_hinge, penalty=elasticnet;, score=0.658 total time=  55.1s
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=squared_loss, penalty=l2;, score=0.658 total time=  34.3s
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=squared_loss, penalty=elasticnet;, score=0.658 total time=  57.8s
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=huber, penalty=l1;, score=0.657 total time=  42.0s
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=huber, penalty=elasticnet;, score=0.658 total time=  31.2s
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=log, penalty=l1;, score=0.576 total time=  41.6s
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=huber, penalty=l2;, score=0.523 total time=   2.4s
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=huber, penalty=elasticnet;, score=0.458 total time=  47.0s
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=modified_huber, penalty=elasticnet;, score=0.584 total time=  47.3s
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=perceptron, penalty=elasticnet;, score=0.561 total time=  41.7s
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=huber, penalty=elasticnet;, score=0.620 total time=  31.5s
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=log, penalty=l2;, score=0.602 total time=  13.9s
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=log, penalty=l2;, score=0.602 total time=  12.6s
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=log, penalty=l1;, score=0.601 total time=  51.5s
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=modified_huber, penalty=elasticnet;, score=0.574 total time=  54.9s
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_hinge, penalty=l1;, score=0.567 total time=  52.8s
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=perceptron, penalty=elasticnet;, score=0.585 total time=  39.1s
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_loss, penalty=l1;, score=0.356 total time=15.8min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_loss, penalty=elasticnet;, score=0.321 total time=17.8min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=hinge, penalty=l2;, score=0.473 total time=   3.8s
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=modified_huber, penalty=l2;, score=0.659 total time=   2.9s
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=modified_huber, penalty=l1;, score=0.567 total time=  41.7s
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=hinge, penalty=l1;, score=0.576 total time=  45.9s
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=squared_hinge, penalty=l2;, score=0.562 total time=   8.0s
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=squared_hinge, penalty=elasticnet;, score=0.569 total time=  55.5s
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=huber, penalty=l2;, score=0.610 total time=  11.8s
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=huber, penalty=l1;, score=0.640 total time=  21.3s
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=hinge, penalty=l2;, score=0.591 total time=   7.1s
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=hinge, penalty=elasticnet;, score=0.585 total time=  45.8s
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=log, penalty=elasticnet;, score=0.593 total time=  39.9s
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=modified_huber, penalty=elasticnet;, score=0.554 total time=  51.0s
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_hinge, penalty=l1;, score=0.546 total time= 1.1min
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=perceptron, penalty=elasticnet;, score=0.544 total time=  37.9s
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_loss, penalty=l1;, score=0.355 total time=16.1min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_loss, penalty=elasticnet;, score=0.286 total time=17.6min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
saving: SGD_summary_1637251606 as png
Fitting 3 folds for each of 24 candidates, totalling 72 fits
[CV 2/3] END activation=tanh, alpha=0.0001, learning_rate=adaptive, solver=sgd;, score=0.628 total time=21.5min
[CV 3/3] END activation=relu, alpha=0.0001, learning_rate=constant, solver=lbfgs;, score=0.574 total time= 7.5min
[CV 3/3] END activation=relu, alpha=0.05, learning_rate=constant, solver=lbfgs;, score=0.583 total time= 9.8min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=log, penalty=l2;, score=0.558 total time=   4.5s
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=modified_huber, penalty=l1;, score=0.563 total time=  27.5s
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=squared_loss, penalty=l2;, score=0.314 total time=   2.5s
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=squared_loss, penalty=l1;, score=0.571 total time=   6.8s
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=huber, penalty=l2;, score=0.223 total time=   2.4s
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=huber, penalty=elasticnet;, score=0.311 total time=  45.6s
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=modified_huber, penalty=l1;, score=0.558 total time= 1.1min
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=squared_loss, penalty=elasticnet;, score=0.314 total time=18.5min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=perceptron, penalty=elasticnet;, score=0.564 total time= 1.5min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_loss, penalty=l1;, score=0.335 total time=13.4min
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=squared_hinge, penalty=l2;, score=0.661 total time=  25.2s
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=squared_hinge, penalty=elasticnet;, score=0.657 total time=  49.7s
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=perceptron, penalty=elasticnet;, score=0.658 total time=  36.4s
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=squared_loss, penalty=l1;, score=0.337 total time= 6.8min
[CV 2/3] END activation=tanh, alpha=0.0001, learning_rate=constant, solver=sgd;, score=0.626 total time=19.4min
[CV 3/3] END activation=relu, alpha=0.0001, learning_rate=constant, solver=sgd;, score=0.651 total time=20.1min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=log, penalty=l2;, score=0.664 total time=   3.9s
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=modified_huber, penalty=l2;, score=0.623 total time=   2.8s
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=modified_huber, penalty=elasticnet;, score=0.624 total time=   9.2s
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=squared_hinge, penalty=l1;, score=0.602 total time=  28.9s
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=hinge, penalty=l2;, score=0.571 total time=   8.9s
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=hinge, penalty=elasticnet;, score=0.584 total time=  36.3s
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=modified_huber, penalty=l1;, score=0.569 total time= 1.2min
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=huber, penalty=l2;, score=0.590 total time=  11.7s
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=huber, penalty=l1;, score=0.625 total time=  21.6s
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=hinge, penalty=l1;, score=0.574 total time=  43.3s
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=log, penalty=l2;, score=0.601 total time=  11.4s
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=modified_huber, penalty=l2;, score=0.570 total time=   7.8s
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=modified_huber, penalty=l2;, score=0.545 total time=   7.9s
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=modified_huber, penalty=l2;, score=0.574 total time=   7.7s
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=modified_huber, penalty=l1;, score=0.556 total time= 1.6min
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=perceptron, penalty=l2;, score=0.562 total time=   5.4s
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=perceptron, penalty=l1;, score=0.572 total time=  44.6s
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_loss, penalty=l2;, score=0.355 total time= 6.0min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=hinge, penalty=elasticnet;, score=0.583 total time= 1.5min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=log, penalty=elasticnet;, score=0.600 total time= 1.7min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=modified_huber, penalty=l1;, score=0.551 total time= 2.5min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_hinge, penalty=elasticnet;, score=0.563 total time=12.6min
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=squared_hinge, penalty=elasticnet;, score=0.655 total time=  36.4s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=perceptron, penalty=elasticnet;, score=0.220 total time=  19.6s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=squared_loss, penalty=l1;, score=0.366 total time=12.9min
[CV 3/3] END activation=tanh, alpha=0.0001, learning_rate=constant, solver=sgd;, score=0.637 total time=21.2min
[CV 3/3] END activation=relu, alpha=0.0001, learning_rate=constant, solver=adam;, score=0.584 total time= 3.0min
[CV 2/3] END activation=relu, alpha=0.0001, learning_rate=adaptive, solver=adam;, score=0.562 total time= 4.1min
[CV 1/3] END activation=relu, alpha=0.05, learning_rate=constant, solver=lbfgs;, score=0.605 total time=11.8min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
[CV 1/3] END activation=tanh, alpha=0.0001, learning_rate=adaptive, solver=lbfgs;, score=0.584 total time= 2.8min
[CV 1/3] END activation=tanh, alpha=0.05, learning_rate=constant, solver=sgd;, score=0.632 total time=20.8min
[CV 3/3] END activation=relu, alpha=0.0001, learning_rate=adaptive, solver=sgd;, score=0.640 total time=18.9min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
[CV 1/3] END activation=tanh, alpha=0.0001, learning_rate=adaptive, solver=sgd;, score=0.636 total time=21.5min
[CV 2/3] END activation=relu, alpha=0.0001, learning_rate=constant, solver=lbfgs;, score=0.571 total time= 3.8min
[CV 3/3] END activation=relu, alpha=0.0001, learning_rate=adaptive, solver=lbfgs;, score=0.572 total time= 6.4min
[CV 1/3] END activation=relu, alpha=0.05, learning_rate=adaptive, solver=adam;, score=0.619 total time= 3.0min
[CV 2/3] END activation=relu, alpha=0.05, learning_rate=adaptive, solver=adam;, score=0.598 total time= 3.7min
[CV 1/3] END activation=relu, alpha=0.05, learning_rate=adaptive, solver=lbfgs;, score=0.614 total time= 4.4min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=hinge, penalty=elasticnet;, score=0.598 total time=   9.9s
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=modified_huber, penalty=elasticnet;, score=0.305 total time=   9.5s
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=squared_hinge, penalty=elasticnet;, score=0.614 total time=  12.3s
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=squared_loss, penalty=l2;, score=0.222 total time=   2.5s
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=squared_loss, penalty=l1;, score=0.282 total time=   6.9s
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=squared_loss, penalty=elasticnet;, score=0.232 total time=   7.2s
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=hinge, penalty=l1;, score=0.565 total time=  42.9s
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=modified_huber, penalty=elasticnet;, score=0.575 total time= 1.0min
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=squared_loss, penalty=l1;, score=0.318 total time=14.7min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_hinge, penalty=l2;, score=0.555 total time= 1.8min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_hinge, penalty=elasticnet;, score=0.561 total time= 9.6min
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=log, penalty=elasticnet;, score=0.658 total time=   4.1s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=modified_huber, penalty=l1;, score=0.657 total time=   4.8s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=squared_hinge, penalty=l2;, score=0.660 total time=   4.4s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=perceptron, penalty=l2;, score=0.619 total time=   1.4s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=perceptron, penalty=l1;, score=0.657 total time=   3.2s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=perceptron, penalty=elasticnet;, score=0.122 total time=   3.2s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=squared_loss, penalty=l2;, score=0.657 total time=   2.7s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=squared_loss, penalty=l1;, score=0.658 total time=   4.5s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=huber, penalty=l2;, score=0.657 total time=   2.4s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=huber, penalty=l1;, score=0.658 total time=   3.9s
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=hinge, penalty=l2;, score=0.657 total time=   7.6s
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=hinge, penalty=l1;, score=0.658 total time=  16.9s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=log, penalty=l2;, score=0.658 total time=   8.3s
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=log, penalty=l1;, score=0.658 total time=  15.5s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=modified_huber, penalty=l2;, score=0.651 total time=  20.3s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=modified_huber, penalty=elasticnet;, score=0.568 total time=  29.1s
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=squared_hinge, penalty=l2;, score=0.659 total time=  17.9s
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=squared_hinge, penalty=l1;, score=0.565 total time=  51.3s
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=squared_loss, penalty=l1;, score=0.335 total time=13.4min
[CV 1/3] END activation=tanh, alpha=0.0001, learning_rate=constant, solver=adam;, score=0.552 total time= 4.0min
[CV 3/3] END activation=tanh, alpha=0.05, learning_rate=constant, solver=sgd;, score=0.636 total time=19.3min
[CV 1/3] END activation=relu, alpha=0.0001, learning_rate=adaptive, solver=sgd;, score=0.640 total time=20.3min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
[CV 1/3] END activation=tanh, alpha=0.0001, learning_rate=adaptive, solver=adam;, score=0.542 total time= 5.7min
[CV 1/3] END activation=tanh, alpha=0.05, learning_rate=constant, solver=lbfgs;, score=0.600 total time= 6.6min
[CV 3/3] END activation=tanh, alpha=0.05, learning_rate=adaptive, solver=adam;, score=0.589 total time= 2.5min
[CV 3/3] END activation=tanh, alpha=0.05, learning_rate=adaptive, solver=lbfgs;, score=0.570 total time= 8.4min
[CV 2/3] END activation=relu, alpha=0.0001, learning_rate=adaptive, solver=sgd;, score=0.632 total time=20.3min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
[CV 3/3] END activation=tanh, alpha=0.0001, learning_rate=adaptive, solver=adam;, score=0.555 total time= 5.2min
[CV 3/3] END activation=tanh, alpha=0.05, learning_rate=constant, solver=adam;, score=0.576 total time= 3.3min
[CV 1/3] END activation=tanh, alpha=0.05, learning_rate=adaptive, solver=adam;, score=0.576 total time= 4.1min
[CV 1/3] END activation=tanh, alpha=0.05, learning_rate=adaptive, solver=lbfgs;, score=0.587 total time= 6.0min
[CV 2/3] END activation=relu, alpha=0.0001, learning_rate=constant, solver=sgd;, score=0.634 total time=20.2min
[CV 3/3] END activation=relu, alpha=0.05, learning_rate=adaptive, solver=lbfgs;, score=0.583 total time= 5.7min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
[CV 2/3] END activation=tanh, alpha=0.0001, learning_rate=adaptive, solver=adam;, score=0.532 total time= 6.6min
[CV 1/3] END activation=tanh, alpha=0.05, learning_rate=adaptive, solver=sgd;, score=0.634 total time=20.0min
[CV 1/3] END activation=relu, alpha=0.05, learning_rate=constant, solver=sgd;, score=0.644 total time=18.3min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=hinge, penalty=l2;, score=0.462 total time=   2.5s
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=log, penalty=elasticnet;, score=0.571 total time=  20.2s
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=perceptron, penalty=l2;, score=0.648 total time=   2.4s
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=perceptron, penalty=l1;, score=0.553 total time=  29.7s
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=log, penalty=l2;, score=0.596 total time=  11.7s
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=log, penalty=elasticnet;, score=0.594 total time=  28.0s
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=squared_hinge, penalty=l2;, score=0.570 total time=   8.6s
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=perceptron, penalty=l2;, score=0.573 total time=   6.3s
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=perceptron, penalty=l1;, score=0.565 total time=  35.3s
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=perceptron, penalty=elasticnet;, score=0.585 total time=  39.8s
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=hinge, penalty=l2;, score=0.598 total time=   7.8s
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=hinge, penalty=l1;, score=0.593 total time=  46.7s
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=log, penalty=l1;, score=0.586 total time=  48.7s
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=modified_huber, penalty=elasticnet;, score=0.555 total time=  59.0s
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_hinge, penalty=elasticnet;, score=0.564 total time= 1.0min
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=perceptron, penalty=elasticnet;, score=0.566 total time=  32.4s
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_loss, penalty=elasticnet;, score=0.320 total time=18.0min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=huber, penalty=l1;, score=0.660 total time= 1.1min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=huber, penalty=elasticnet;, score=0.657 total time= 1.6min
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=perceptron, penalty=l2;, score=0.653 total time=   2.7s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=perceptron, penalty=l1;, score=0.657 total time=   4.6s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=perceptron, penalty=elasticnet;, score=0.658 total time=   4.1s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=squared_loss, penalty=l2;, score=0.236 total time=   3.8s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=squared_loss, penalty=elasticnet;, score=0.123 total time=   4.5s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=squared_loss, penalty=elasticnet;, score=0.154 total time=   4.3s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=huber, penalty=l1;, score=0.658 total time=   4.3s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=hinge, penalty=l2;, score=0.658 total time=   2.0s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=hinge, penalty=l1;, score=0.658 total time=   3.6s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=log, penalty=l2;, score=0.658 total time=   2.9s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=modified_huber, penalty=l2;, score=0.661 total time=   4.2s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=squared_hinge, penalty=l2;, score=0.661 total time=   4.1s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=squared_hinge, penalty=l1;, score=0.504 total time= 6.8min
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=modified_huber, penalty=elasticnet;, score=0.658 total time=  51.6s
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=perceptron, penalty=l2;, score=0.581 total time=  16.1s
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=perceptron, penalty=elasticnet;, score=0.657 total time=  36.5s
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=squared_loss, penalty=l1;, score=0.311 total time= 8.5min
[CV 2/3] END activation=tanh, alpha=0.0001, learning_rate=constant, solver=adam;, score=0.542 total time= 4.6min
[CV 1/3] END activation=tanh, alpha=0.05, learning_rate=constant, solver=adam;, score=0.577 total time= 3.2min
[CV 3/3] END activation=tanh, alpha=0.05, learning_rate=adaptive, solver=sgd;, score=0.640 total time=20.8min
[CV 2/3] END activation=relu, alpha=0.05, learning_rate=constant, solver=lbfgs;, score=0.589 total time=16.7min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=hinge, penalty=l2;, score=0.521 total time=   2.5s
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=log, penalty=elasticnet;, score=0.597 total time=  16.1s
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=squared_hinge, penalty=elasticnet;, score=0.615 total time=   8.4s
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=perceptron, penalty=l1;, score=0.584 total time=  30.1s
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=log, penalty=l1;, score=0.594 total time=  40.1s
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=squared_hinge, penalty=l1;, score=0.571 total time=  47.9s
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=squared_loss, penalty=l2;, score=0.324 total time= 5.9min
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=huber, penalty=l2;, score=0.617 total time=   7.2s
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=huber, penalty=l2;, score=0.612 total time=   6.4s
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=huber, penalty=l2;, score=0.617 total time=   6.8s
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=huber, penalty=l1;, score=0.653 total time=  16.6s
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=huber, penalty=l1;, score=0.642 total time=  15.5s
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=huber, penalty=l1;, score=0.645 total time=  16.9s
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=huber, penalty=elasticnet;, score=0.626 total time=  19.9s
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=huber, penalty=elasticnet;, score=0.632 total time=  20.6s
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=huber, penalty=elasticnet;, score=0.623 total time=  20.7s
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=hinge, penalty=l2;, score=0.584 total time=  14.0s
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=hinge, penalty=l2;, score=0.575 total time=  13.9s
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=hinge, penalty=l2;, score=0.582 total time=  13.9s
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=hinge, penalty=l1;, score=0.567 total time= 1.8min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=hinge, penalty=elasticnet;, score=0.577 total time= 1.4min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=log, penalty=l1;, score=0.552 total time= 2.3min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=modified_huber, penalty=elasticnet;, score=0.564 total time= 1.8min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_hinge, penalty=l1;, score=0.560 total time= 2.5min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=perceptron, penalty=elasticnet;, score=0.566 total time= 1.4min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_loss, penalty=l2;, score=0.329 total time= 5.5min
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=modified_huber, penalty=elasticnet;, score=0.658 total time=   5.1s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=squared_hinge, penalty=l1;, score=0.550 total time=  36.5s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=log, penalty=l1;, score=0.657 total time=   4.3s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=modified_huber, penalty=l2;, score=0.660 total time=   3.9s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=squared_hinge, penalty=l2;, score=0.662 total time=   5.3s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=perceptron, penalty=l2;, score=0.553 total time=   1.4s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=perceptron, penalty=l2;, score=0.615 total time=   1.4s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=perceptron, penalty=l1;, score=0.658 total time=   3.3s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=perceptron, penalty=elasticnet;, score=0.220 total time=   3.2s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=squared_loss, penalty=l2;, score=0.658 total time=   3.2s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=squared_loss, penalty=elasticnet;, score=0.658 total time=   4.6s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=huber, penalty=l1;, score=0.657 total time=   4.2s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=huber, penalty=elasticnet;, score=0.658 total time=   4.0s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=hinge, penalty=l1;, score=0.658 total time=  19.8s
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=log, penalty=l2;, score=0.657 total time=   9.0s
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=log, penalty=l1;, score=0.657 total time=  13.2s
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=log, penalty=elasticnet;, score=0.658 total time=  14.1s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=modified_huber, penalty=l1;, score=0.122 total time=  32.6s
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=squared_hinge, penalty=l2;, score=0.557 total time=  17.6s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=squared_hinge, penalty=l1;, score=0.546 total time= 1.5min
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=huber, penalty=l2;, score=0.657 total time=   3.3s
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=huber, penalty=l2;, score=0.658 total time=   3.3s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=huber, penalty=l1;, score=0.658 total time=   4.8s
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=huber, penalty=elasticnet;, score=0.658 total time=   4.8s
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=hinge, penalty=l1;, score=0.657 total time=  42.1s
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=hinge, penalty=elasticnet;, score=0.658 total time=  40.3s
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=log, penalty=l2;, score=0.658 total time=  31.1s
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=log, penalty=elasticnet;, score=0.657 total time=  51.3s
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=modified_huber, penalty=l1;, score=0.657 total time=  55.0s
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=perceptron, penalty=l2;, score=0.579 total time=  15.2s
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=perceptron, penalty=l1;, score=0.658 total time=  42.0s
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=squared_loss, penalty=l1;, score=0.266 total time= 8.9min
[CV 3/3] END activation=tanh, alpha=0.0001, learning_rate=constant, solver=adam;, score=0.556 total time= 4.7min
[CV 2/3] END activation=tanh, alpha=0.05, learning_rate=constant, solver=adam;, score=0.571 total time= 3.0min
[CV 2/3] END activation=tanh, alpha=0.05, learning_rate=adaptive, solver=sgd;, score=0.626 total time=19.6min
[CV 3/3] END activation=relu, alpha=0.05, learning_rate=constant, solver=sgd;, score=0.646 total time=18.6min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
[CV 2/3] END activation=tanh, alpha=0.0001, learning_rate=constant, solver=lbfgs;, score=0.552 total time= 3.8min
[CV 2/3] END activation=tanh, alpha=0.05, learning_rate=constant, solver=sgd;, score=0.626 total time=21.0min
[CV 2/3] END activation=relu, alpha=0.0001, learning_rate=adaptive, solver=lbfgs;, score=0.570 total time= 2.1min
[CV 2/3] END activation=relu, alpha=0.05, learning_rate=constant, solver=sgd;, score=0.629 total time=19.1min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
[CV 1/3] END activation=tanh, alpha=0.0001, learning_rate=constant, solver=lbfgs;, score=0.578 total time= 2.7min
[CV 3/3] END activation=tanh, alpha=0.0001, learning_rate=adaptive, solver=lbfgs;, score=0.582 total time= 3.1min
[CV 2/3] END activation=tanh, alpha=0.05, learning_rate=constant, solver=lbfgs;, score=0.562 total time= 6.2min
[CV 2/3] END activation=tanh, alpha=0.05, learning_rate=adaptive, solver=adam;, score=0.572 total time= 3.0min
[CV 1/3] END activation=relu, alpha=0.0001, learning_rate=constant, solver=sgd;, score=0.636 total time=20.0min
[CV 3/3] END activation=relu, alpha=0.05, learning_rate=adaptive, solver=adam;, score=0.619 total time= 3.6min
[CV 2/3] END activation=relu, alpha=0.05, learning_rate=adaptive, solver=lbfgs;, score=0.591 total time= 7.7min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
[CV 3/3] END activation=tanh, alpha=0.0001, learning_rate=constant, solver=lbfgs;, score=0.578 total time= 2.6min
[CV 2/3] END activation=tanh, alpha=0.0001, learning_rate=adaptive, solver=lbfgs;, score=0.554 total time= 3.9min
[CV 3/3] END activation=tanh, alpha=0.05, learning_rate=constant, solver=lbfgs;, score=0.573 total time= 6.9min
[CV 2/3] END activation=tanh, alpha=0.05, learning_rate=adaptive, solver=lbfgs;, score=0.563 total time= 6.7min
[CV 1/3] END activation=relu, alpha=0.0001, learning_rate=constant, solver=adam;, score=0.584 total time= 3.8min
[CV 1/3] END activation=relu, alpha=0.0001, learning_rate=adaptive, solver=adam;, score=0.592 total time= 3.9min
[CV 2/3] END activation=relu, alpha=0.05, learning_rate=constant, solver=adam;, score=0.598 total time= 3.1min
[CV 1/3] END activation=relu, alpha=0.05, learning_rate=adaptive, solver=sgd;, score=0.641 total time=15.6min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
[CV 3/3] END activation=tanh, alpha=0.0001, learning_rate=adaptive, solver=sgd;, score=0.643 total time=21.2min
[CV 1/3] END activation=relu, alpha=0.0001, learning_rate=constant, solver=lbfgs;, score=0.588 total time= 3.3min
[CV 3/3] END activation=relu, alpha=0.0001, learning_rate=adaptive, solver=adam;, score=0.587 total time= 3.1min
[CV 1/3] END activation=relu, alpha=0.05, learning_rate=constant, solver=adam;, score=0.630 total time= 4.0min
[CV 3/3] END activation=relu, alpha=0.05, learning_rate=adaptive, solver=sgd;, score=0.644 total time=15.7min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=log, penalty=l1;, score=0.607 total time=  41.6s
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=huber, penalty=l2;, score=0.263 total time=   2.5s
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=huber, penalty=elasticnet;, score=0.447 total time=  55.8s
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=squared_hinge, penalty=elasticnet;, score=0.549 total time= 1.1min
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=huber, penalty=l1;, score=0.634 total time=  23.6s
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=hinge, penalty=l2;, score=0.583 total time=   7.7s
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=hinge, penalty=l1;, score=0.587 total time=  47.2s
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=log, penalty=l1;, score=0.599 total time=  50.1s
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_hinge, penalty=l2;, score=0.573 total time=  10.2s
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_hinge, penalty=l2;, score=0.542 total time=   9.8s
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_hinge, penalty=l2;, score=0.569 total time=   5.8s
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_hinge, penalty=l1;, score=0.570 total time=  50.6s
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=perceptron, penalty=l2;, score=0.584 total time=   5.8s
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=perceptron, penalty=l2;, score=0.587 total time=   5.6s
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=perceptron, penalty=l1;, score=0.558 total time=  39.1s
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_loss, penalty=l2;, score=0.326 total time= 6.0min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=hinge, penalty=l1;, score=0.559 total time= 1.5min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=log, penalty=l1;, score=0.568 total time= 2.6min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_hinge, penalty=l2;, score=0.563 total time= 1.9min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_hinge, penalty=elasticnet;, score=0.554 total time=12.4min
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=perceptron, penalty=l2;, score=0.655 total time=   8.9s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=perceptron, penalty=l2;, score=0.419 total time=   9.7s
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=perceptron, penalty=l2;, score=0.526 total time=   9.4s
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=perceptron, penalty=elasticnet;, score=0.122 total time=  13.8s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=squared_loss, penalty=l2;, score=0.650 total time=  14.8s
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=squared_loss, penalty=l1;, score=0.318 total time=10.8min
[CV 1/3] END activation=tanh, alpha=0.0001, learning_rate=constant, solver=sgd;, score=0.634 total time=20.7min
[CV 2/3] END activation=relu, alpha=0.0001, learning_rate=constant, solver=adam;, score=0.559 total time= 3.8min
[CV 1/3] END activation=relu, alpha=0.0001, learning_rate=adaptive, solver=lbfgs;, score=0.593 total time= 3.4min
[CV 3/3] END activation=relu, alpha=0.05, learning_rate=constant, solver=adam;, score=0.617 total time= 3.7min
[CV 2/3] END activation=relu, alpha=0.05, learning_rate=adaptive, solver=sgd;, score=0.635 total time=16.5min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
saving: MLP_summary_1637255246 as png
saving all
Saving to: summary_k-Nearest Neighbour_model_container_454793.12404731225
Saving to: summary_Guassian Naive Bayes_model_container_454793.12409723416
Saving to: summary_Multinominal Naive Bayes_model_container_454793.1241023886
Saving to: summary_Decision Tree_model_container_454793.12410746
Saving to: summary_Support Vector Machine (classifier)_model_container_454793.12411249086
Saving to: summary_Stochastic Gradient Descent_model_container_454793.1241613501
Saving to: summary_Multi-layer Perceptron_model_container_454793.1241664928
saving: summary_comparison_1637255247 as png
Fitting 3 folds for each of 160 candidates, totalling 480 fits
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/home/dries/pipeline/src/services/compare_service.py:62: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  dataframe[f"{col}_raw"] = dataframe[col]
/home/dries/pipeline/src/services/compare_service.py:64: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  dataframe[col + "_joined"] = dataframe.apply(lambda row: standardizer.standardize(row[col]), axis=1)
/home/dries/pipeline/src/services/compare_service.py:65: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  dataframe[col] = dataframe.apply(lambda row: row[col + "_joined"][0], axis=1)
/home/dries/pipeline/src/services/compare_service.py:66: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  dataframe[f"{col}_stopword_count"] = dataframe.apply(lambda row: row[col + "_joined"][1], axis=1)
/home/dries/pipeline/dries/lib/python3.7/site-packages/pandas/core/frame.py:4908: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  errors=errors,
[CV 2/3] END algorithm=auto, n_neighbors=2, weights=uniform;, score=0.656 total time=  28.4s
[CV 1/3] END algorithm=auto, n_neighbors=5, weights=uniform;, score=0.669 total time=  28.3s
[CV 3/3] END algorithm=auto, n_neighbors=7, weights=distance;, score=0.644 total time=  28.4s
[CV 3/3] END algorithm=auto, n_neighbors=11, weights=uniform;, score=0.661 total time=  28.2s
[CV 2/3] END algorithm=auto, n_neighbors=13, weights=distance;, score=0.672 total time=  28.4s
[CV 1/3] END algorithm=auto, n_neighbors=16, weights=distance;, score=0.673 total time=  28.4s
[CV 3/3] END algorithm=auto, n_neighbors=19, weights=uniform;, score=0.660 total time=  27.9s
[CV 1/3] END algorithm=ball_tree, n_neighbors=2, weights=uniform;, score=0.652 total time= 4.4min
[CV 2/3] END algorithm=ball_tree, n_neighbors=4, weights=distance;, score=0.647 total time= 4.4min
[CV 1/3] END algorithm=ball_tree, n_neighbors=7, weights=distance;, score=0.668 total time= 4.4min
[CV 3/3] END algorithm=ball_tree, n_neighbors=9, weights=distance;, score=0.661 total time= 4.4min
[CV 1/3] END algorithm=ball_tree, n_neighbors=12, weights=distance;, score=0.669 total time= 4.4min
[CV 3/3] END algorithm=ball_tree, n_neighbors=15, weights=uniform;, score=0.663 total time= 4.4min
[CV 2/3] END algorithm=ball_tree, n_neighbors=18, weights=uniform;, score=0.664 total time= 4.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=1, weights=uniform;, score=0.534 total time= 5.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=3, weights=distance;, score=0.583 total time= 5.5min
[CV 1/3] END algorithm=kd_tree, n_neighbors=6, weights=distance;, score=0.669 total time= 5.9min
[CV 2/3] END algorithm=kd_tree, n_neighbors=9, weights=uniform;, score=0.667 total time= 5.9min
[CV 1/3] END algorithm=kd_tree, n_neighbors=12, weights=uniform;, score=0.668 total time= 5.9min
[CV 2/3] END algorithm=kd_tree, n_neighbors=14, weights=distance;, score=0.670 total time= 5.9min
[CV 1/3] END algorithm=kd_tree, n_neighbors=17, weights=distance;, score=0.673 total time= 5.9min
[CV 2/3] END algorithm=kd_tree, n_neighbors=20, weights=uniform;, score=0.663 total time= 5.9min
[CV 2/3] END algorithm=brute, n_neighbors=8, weights=uniform;, score=0.666 total time=  26.0s
[CV 2/3] END algorithm=brute, n_neighbors=10, weights=distance;, score=0.668 total time=  26.7s
[CV 2/3] END algorithm=brute, n_neighbors=13, weights=uniform;, score=0.665 total time=  27.6s
[CV 2/3] END algorithm=brute, n_neighbors=16, weights=uniform;, score=0.664 total time=  27.1s
[CV 3/3] END algorithm=brute, n_neighbors=18, weights=distance;, score=0.669 total time=  26.5s
[CV 3/3] END class_weight=balanced, gamma=scale, kernel=linear;, score=0.630 total time=53.5min
[CV 2/3] END class_weight=balanced, gamma=auto, kernel=linear;, score=0.601 total time=55.6min
[CV 1/3] END class_weight=None, gamma=auto, kernel=sigmoid;, score=0.661 total time=30.8min
[CV 1/3] END algorithm=auto, n_neighbors=1, weights=distance;, score=0.594 total time=  28.3s
[CV 1/3] END algorithm=auto, n_neighbors=4, weights=distance;, score=0.649 total time=  28.3s
[CV 3/3] END algorithm=auto, n_neighbors=7, weights=uniform;, score=0.645 total time=  28.1s
[CV 1/3] END algorithm=auto, n_neighbors=10, weights=uniform;, score=0.666 total time=  28.2s
[CV 3/3] END algorithm=auto, n_neighbors=12, weights=distance;, score=0.672 total time=  28.1s
[CV 2/3] END algorithm=auto, n_neighbors=15, weights=distance;, score=0.671 total time=  28.1s
[CV 1/3] END algorithm=auto, n_neighbors=18, weights=distance;, score=0.673 total time=  28.1s
[CV 3/3] END algorithm=ball_tree, n_neighbors=1, weights=uniform;, score=0.482 total time= 4.4min
[CV 3/3] END algorithm=ball_tree, n_neighbors=4, weights=distance;, score=0.602 total time= 4.4min
[CV 3/3] END algorithm=ball_tree, n_neighbors=7, weights=uniform;, score=0.645 total time= 4.4min
[CV 2/3] END algorithm=ball_tree, n_neighbors=10, weights=uniform;, score=0.666 total time= 4.4min
[CV 3/3] END algorithm=ball_tree, n_neighbors=12, weights=distance;, score=0.672 total time= 4.4min
[CV 3/3] END algorithm=ball_tree, n_neighbors=15, weights=distance;, score=0.672 total time= 4.4min
[CV 2/3] END algorithm=ball_tree, n_neighbors=18, weights=distance;, score=0.670 total time= 4.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=1, weights=distance;, score=0.594 total time= 5.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=4, weights=uniform;, score=0.629 total time= 5.6min
[CV 2/3] END algorithm=kd_tree, n_neighbors=6, weights=distance;, score=0.658 total time= 5.9min
[CV 3/3] END algorithm=kd_tree, n_neighbors=9, weights=uniform;, score=0.664 total time= 5.7min
[CV 3/3] END algorithm=kd_tree, n_neighbors=11, weights=distance;, score=0.663 total time= 5.7min
[CV 3/3] END algorithm=kd_tree, n_neighbors=14, weights=uniform;, score=0.661 total time= 5.7min
[CV 1/3] END algorithm=kd_tree, n_neighbors=17, weights=uniform;, score=0.669 total time= 5.9min
[CV 2/3] END algorithm=kd_tree, n_neighbors=19, weights=distance;, score=0.671 total time= 5.9min
[CV 1/3] END algorithm=brute, n_neighbors=5, weights=uniform;, score=0.669 total time=  20.1s
[CV 2/3] END algorithm=brute, n_neighbors=6, weights=distance;, score=0.658 total time=  23.4s
[CV 2/3] END algorithm=brute, n_neighbors=8, weights=distance;, score=0.668 total time=  23.3s
[CV 1/3] END algorithm=brute, n_neighbors=11, weights=uniform;, score=0.667 total time=  23.6s
[CV 1/3] END algorithm=brute, n_neighbors=13, weights=distance;, score=0.671 total time=  23.4s
[CV 3/3] END algorithm=brute, n_neighbors=15, weights=distance;, score=0.672 total time=  23.3s
[CV 1/3] END algorithm=brute, n_neighbors=18, weights=uniform;, score=0.666 total time=  23.4s
[CV 2/3] END algorithm=brute, n_neighbors=20, weights=distance;, score=0.669 total time=  14.8s
[CV 1/3] END class_weight=balanced, gamma=auto, kernel=sigmoid;, score=0.213 total time=62.6min
[CV 2/3] END class_weight=None, gamma=scale, kernel=linear;, score=0.628 total time=52.0min
[CV 2/3] END class_weight=None, gamma=auto, kernel=sigmoid;, score=0.661 total time=30.4min
[CV 1/3] END algorithm=auto, n_neighbors=3, weights=distance;, score=0.641 total time=  28.4s
[CV 3/3] END algorithm=auto, n_neighbors=5, weights=distance;, score=0.607 total time=  28.3s
[CV 2/3] END algorithm=auto, n_neighbors=8, weights=uniform;, score=0.666 total time=  27.8s
[CV 2/3] END algorithm=auto, n_neighbors=9, weights=distance;, score=0.671 total time=  27.6s
[CV 3/3] END algorithm=auto, n_neighbors=12, weights=uniform;, score=0.666 total time=  27.7s
[CV 1/3] END algorithm=auto, n_neighbors=15, weights=uniform;, score=0.667 total time=  27.5s
[CV 2/3] END algorithm=auto, n_neighbors=17, weights=distance;, score=0.670 total time=  27.0s
[CV 3/3] END algorithm=auto, n_neighbors=20, weights=uniform;, score=0.660 total time=  26.9s
[CV 2/3] END algorithm=ball_tree, n_neighbors=3, weights=uniform;, score=0.652 total time= 4.4min
[CV 1/3] END algorithm=ball_tree, n_neighbors=6, weights=uniform;, score=0.664 total time= 4.4min
[CV 2/3] END algorithm=ball_tree, n_neighbors=8, weights=distance;, score=0.668 total time= 4.4min
[CV 3/3] END algorithm=ball_tree, n_neighbors=11, weights=uniform;, score=0.661 total time= 4.4min
[CV 1/3] END algorithm=ball_tree, n_neighbors=14, weights=uniform;, score=0.666 total time= 4.4min
[CV 2/3] END algorithm=ball_tree, n_neighbors=16, weights=distance;, score=0.670 total time= 4.4min
[CV 3/3] END algorithm=ball_tree, n_neighbors=19, weights=uniform;, score=0.660 total time= 4.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=2, weights=uniform;, score=0.652 total time= 5.8min
[CV 2/3] END algorithm=kd_tree, n_neighbors=4, weights=distance;, score=0.647 total time= 5.8min
[CV 1/3] END algorithm=kd_tree, n_neighbors=7, weights=distance;, score=0.668 total time= 5.9min
[CV 2/3] END algorithm=kd_tree, n_neighbors=10, weights=uniform;, score=0.666 total time= 5.9min
[CV 3/3] END algorithm=kd_tree, n_neighbors=12, weights=distance;, score=0.672 total time= 5.7min
[CV 1/3] END algorithm=kd_tree, n_neighbors=15, weights=distance;, score=0.672 total time= 5.9min
[CV 2/3] END algorithm=kd_tree, n_neighbors=18, weights=uniform;, score=0.664 total time= 5.9min
[CV 3/3] END algorithm=kd_tree, n_neighbors=20, weights=distance;, score=0.671 total time= 6.2min
[CV 1/3] END algorithm=brute, n_neighbors=15, weights=uniform;, score=0.667 total time=  24.2s
[CV 1/3] END algorithm=brute, n_neighbors=17, weights=distance;, score=0.673 total time=  23.7s
[CV 1/3] END algorithm=brute, n_neighbors=20, weights=uniform;, score=0.666 total time=  19.3s
[CV 3/3] END class_weight=balanced, gamma=scale, kernel=rbf;, score=0.618 total time=63.1min
[CV 3/3] END class_weight=None, gamma=scale, kernel=linear;, score=0.636 total time=55.1min
[CV 1/3] END class_weight=None, gamma=auto, kernel=poly;, score=0.661 total time=27.6min
[CV 2/3] END algorithm=auto, n_neighbors=1, weights=distance;, score=0.534 total time=  27.3s
[CV 2/3] END algorithm=auto, n_neighbors=3, weights=distance;, score=0.635 total time=  27.6s
[CV 3/3] END algorithm=auto, n_neighbors=6, weights=uniform;, score=0.655 total time=  27.5s
[CV 2/3] END algorithm=auto, n_neighbors=9, weights=uniform;, score=0.667 total time=  27.0s
[CV 3/3] END algorithm=auto, n_neighbors=11, weights=distance;, score=0.663 total time=  26.3s
[CV 1/3] END algorithm=auto, n_neighbors=14, weights=distance;, score=0.672 total time=  25.8s
[CV 2/3] END algorithm=auto, n_neighbors=17, weights=uniform;, score=0.664 total time=  25.7s
[CV 3/3] END algorithm=auto, n_neighbors=19, weights=distance;, score=0.670 total time=  25.1s
[CV 1/3] END algorithm=ball_tree, n_neighbors=2, weights=distance;, score=0.594 total time= 4.3min
[CV 2/3] END algorithm=ball_tree, n_neighbors=5, weights=uniform;, score=0.661 total time= 4.3min
[CV 3/3] END algorithm=ball_tree, n_neighbors=7, weights=distance;, score=0.644 total time= 4.3min
[CV 1/3] END algorithm=ball_tree, n_neighbors=10, weights=distance;, score=0.670 total time= 4.3min
[CV 2/3] END algorithm=ball_tree, n_neighbors=13, weights=uniform;, score=0.665 total time= 4.3min
[CV 1/3] END algorithm=ball_tree, n_neighbors=15, weights=distance;, score=0.672 total time= 4.3min
[CV 3/3] END algorithm=ball_tree, n_neighbors=17, weights=distance;, score=0.672 total time= 4.3min
[CV 2/3] END algorithm=ball_tree, n_neighbors=20, weights=uniform;, score=0.663 total time= 4.1min
[CV 1/3] END algorithm=kd_tree, n_neighbors=2, weights=distance;, score=0.594 total time= 5.7min
[CV 1/3] END algorithm=kd_tree, n_neighbors=5, weights=distance;, score=0.654 total time= 5.9min
[CV 3/3] END algorithm=kd_tree, n_neighbors=8, weights=uniform;, score=0.663 total time= 5.6min
[CV 3/3] END algorithm=kd_tree, n_neighbors=10, weights=distance;, score=0.659 total time= 5.7min
[CV 3/3] END algorithm=kd_tree, n_neighbors=13, weights=uniform;, score=0.665 total time= 5.7min
[CV 3/3] END algorithm=kd_tree, n_neighbors=15, weights=distance;, score=0.672 total time= 5.7min
[CV 1/3] END algorithm=kd_tree, n_neighbors=18, weights=distance;, score=0.673 total time= 6.1min
[CV 2/3] END algorithm=brute, n_neighbors=1, weights=uniform;, score=0.534 total time=  26.6s
[CV 2/3] END algorithm=brute, n_neighbors=2, weights=uniform;, score=0.656 total time=  26.4s
[CV 2/3] END algorithm=brute, n_neighbors=3, weights=distance;, score=0.635 total time=  25.7s
[CV 2/3] END algorithm=brute, n_neighbors=5, weights=uniform;, score=0.661 total time=  25.5s
[CV 1/3] END algorithm=brute, n_neighbors=7, weights=uniform;, score=0.669 total time=  27.3s
[CV 1/3] END algorithm=brute, n_neighbors=10, weights=uniform;, score=0.666 total time=  27.0s
[CV 1/3] END algorithm=brute, n_neighbors=12, weights=distance;, score=0.669 total time=  26.9s
[CV 1/3] END algorithm=brute, n_neighbors=15, weights=distance;, score=0.672 total time=  27.4s
[CV 3/3] END algorithm=brute, n_neighbors=18, weights=uniform;, score=0.660 total time=  27.3s
[CV 3/3] END class_weight=balanced, gamma=scale, kernel=sigmoid;, score=0.565 total time=55.7min
[CV 2/3] END class_weight=balanced, gamma=auto, kernel=rbf;, score=0.213 total time=65.7min
[CV 2/3] END class_weight=None, gamma=auto, kernel=poly;, score=0.661 total time=25.1min
[CV 1/3] END algorithm=auto, n_neighbors=2, weights=distance;, score=0.594 total time=  28.4s
[CV 2/3] END algorithm=auto, n_neighbors=5, weights=distance;, score=0.660 total time=  28.3s
[CV 1/3] END algorithm=auto, n_neighbors=8, weights=uniform;, score=0.668 total time=  28.1s
[CV 3/3] END algorithm=auto, n_neighbors=10, weights=uniform;, score=0.664 total time=  28.1s
[CV 2/3] END algorithm=auto, n_neighbors=13, weights=uniform;, score=0.665 total time=  28.1s
[CV 3/3] END algorithm=auto, n_neighbors=15, weights=distance;, score=0.672 total time=  28.0s
[CV 3/3] END algorithm=auto, n_neighbors=18, weights=distance;, score=0.669 total time=  28.0s
[CV 2/3] END algorithm=ball_tree, n_neighbors=1, weights=distance;, score=0.534 total time= 4.4min
[CV 3/3] END algorithm=ball_tree, n_neighbors=4, weights=uniform;, score=0.629 total time= 4.4min
[CV 2/3] END algorithm=ball_tree, n_neighbors=7, weights=uniform;, score=0.663 total time= 4.4min
[CV 1/3] END algorithm=ball_tree, n_neighbors=10, weights=uniform;, score=0.666 total time= 4.4min
[CV 2/3] END algorithm=ball_tree, n_neighbors=12, weights=distance;, score=0.669 total time= 4.4min
[CV 2/3] END algorithm=ball_tree, n_neighbors=15, weights=distance;, score=0.671 total time= 4.4min
[CV 1/3] END algorithm=ball_tree, n_neighbors=18, weights=distance;, score=0.673 total time= 4.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=1, weights=uniform;, score=0.482 total time= 5.0min
[CV 2/3] END algorithm=kd_tree, n_neighbors=3, weights=distance;, score=0.635 total time= 5.8min
[CV 3/3] END algorithm=kd_tree, n_neighbors=6, weights=uniform;, score=0.655 total time= 5.6min
[CV 1/3] END algorithm=kd_tree, n_neighbors=9, weights=uniform;, score=0.667 total time= 5.9min
[CV 2/3] END algorithm=kd_tree, n_neighbors=11, weights=distance;, score=0.670 total time= 5.9min
[CV 1/3] END algorithm=kd_tree, n_neighbors=14, weights=distance;, score=0.672 total time= 5.9min
[CV 2/3] END algorithm=kd_tree, n_neighbors=17, weights=uniform;, score=0.664 total time= 5.9min
[CV 3/3] END algorithm=kd_tree, n_neighbors=19, weights=distance;, score=0.670 total time= 5.8min
[CV 2/3] END algorithm=brute, n_neighbors=5, weights=distance;, score=0.660 total time=  24.0s
[CV 2/3] END algorithm=brute, n_neighbors=7, weights=distance;, score=0.665 total time=  23.6s
[CV 2/3] END algorithm=brute, n_neighbors=9, weights=distance;, score=0.671 total time=  23.6s
[CV 2/3] END algorithm=brute, n_neighbors=12, weights=uniform;, score=0.664 total time=  23.6s
[CV 1/3] END algorithm=brute, n_neighbors=14, weights=distance;, score=0.672 total time=  23.7s
[CV 2/3] END algorithm=brute, n_neighbors=17, weights=uniform;, score=0.664 total time=  23.8s
[CV 2/3] END algorithm=brute, n_neighbors=19, weights=distance;, score=0.671 total time=  18.9s
[CV 1/3] END class_weight=balanced, gamma=scale, kernel=linear;, score=0.621 total time=54.3min
[CV 1/3] END class_weight=balanced, gamma=auto, kernel=poly;, score=0.213 total time=62.1min
[CV 3/3] END class_weight=None, gamma=auto, kernel=sigmoid;, score=0.661 total time=30.6min
[CV 3/3] END algorithm=auto, n_neighbors=1, weights=uniform;, score=0.482 total time=  28.4s
[CV 1/3] END algorithm=auto, n_neighbors=5, weights=distance;, score=0.654 total time=  28.4s
[CV 1/3] END algorithm=auto, n_neighbors=8, weights=distance;, score=0.672 total time=  28.1s
[CV 1/3] END algorithm=auto, n_neighbors=11, weights=uniform;, score=0.667 total time=  28.1s
[CV 3/3] END algorithm=auto, n_neighbors=13, weights=uniform;, score=0.665 total time=  28.1s
[CV 1/3] END algorithm=auto, n_neighbors=16, weights=uniform;, score=0.666 total time=  27.2s
[CV 3/3] END algorithm=auto, n_neighbors=18, weights=uniform;, score=0.660 total time=  26.7s
[CV 2/3] END algorithm=auto, n_neighbors=20, weights=distance;, score=0.669 total time=  25.5s
[CV 1/3] END algorithm=ball_tree, n_neighbors=3, weights=uniform;, score=0.658 total time= 4.4min
[CV 2/3] END algorithm=ball_tree, n_neighbors=5, weights=distance;, score=0.660 total time= 4.3min
[CV 3/3] END algorithm=ball_tree, n_neighbors=8, weights=uniform;, score=0.663 total time= 4.4min
[CV 1/3] END algorithm=ball_tree, n_neighbors=11, weights=uniform;, score=0.667 total time= 4.4min
[CV 2/3] END algorithm=ball_tree, n_neighbors=13, weights=distance;, score=0.672 total time= 4.4min
[CV 3/3] END algorithm=ball_tree, n_neighbors=16, weights=uniform;, score=0.661 total time= 4.4min
[CV 1/3] END algorithm=ball_tree, n_neighbors=19, weights=uniform;, score=0.668 total time= 4.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=1, weights=distance;, score=0.534 total time= 5.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=4, weights=distance;, score=0.649 total time= 5.8min
[CV 2/3] END algorithm=kd_tree, n_neighbors=7, weights=uniform;, score=0.663 total time= 5.9min
[CV 1/3] END algorithm=kd_tree, n_neighbors=10, weights=uniform;, score=0.666 total time= 5.9min
[CV 2/3] END algorithm=kd_tree, n_neighbors=12, weights=distance;, score=0.669 total time= 5.9min
[CV 3/3] END algorithm=kd_tree, n_neighbors=15, weights=uniform;, score=0.663 total time= 5.7min
[CV 1/3] END algorithm=kd_tree, n_neighbors=18, weights=uniform;, score=0.666 total time= 5.9min
[CV 2/3] END algorithm=kd_tree, n_neighbors=20, weights=distance;, score=0.669 total time= 7.4min
[CV 3/3] END algorithm=brute, n_neighbors=20, weights=uniform;, score=0.660 total time=  16.4s
[CV 1/3] END class_weight=balanced, gamma=scale, kernel=rbf;, score=0.622 total time=63.2min
[CV 1/3] END class_weight=None, gamma=scale, kernel=poly;, score=0.661 total time=59.9min
[CV 3/3] END class_weight=None, gamma=auto, kernel=poly;, score=0.661 total time=25.0min
[CV 1/3] END algorithm=auto, n_neighbors=2, weights=uniform;, score=0.652 total time=  28.4s
[CV 3/3] END algorithm=auto, n_neighbors=4, weights=distance;, score=0.602 total time=  28.1s
[CV 2/3] END algorithm=auto, n_neighbors=6, weights=distance;, score=0.658 total time=  27.9s
[CV 3/3] END algorithm=auto, n_neighbors=9, weights=uniform;, score=0.664 total time=  27.3s
[CV 1/3] END algorithm=auto, n_neighbors=12, weights=uniform;, score=0.668 total time=  26.9s
[CV 2/3] END algorithm=auto, n_neighbors=14, weights=distance;, score=0.670 total time=  26.0s
[CV 3/3] END algorithm=auto, n_neighbors=17, weights=uniform;, score=0.660 total time=  25.7s
[CV 1/3] END algorithm=auto, n_neighbors=20, weights=uniform;, score=0.666 total time=  25.1s
[CV 2/3] END algorithm=ball_tree, n_neighbors=2, weights=distance;, score=0.534 total time= 4.3min
[CV 3/3] END algorithm=ball_tree, n_neighbors=5, weights=uniform;, score=0.640 total time= 4.3min
[CV 1/3] END algorithm=ball_tree, n_neighbors=8, weights=uniform;, score=0.668 total time= 4.3min
[CV 2/3] END algorithm=ball_tree, n_neighbors=10, weights=distance;, score=0.668 total time= 4.3min
[CV 3/3] END algorithm=ball_tree, n_neighbors=13, weights=uniform;, score=0.665 total time= 4.3min
[CV 1/3] END algorithm=ball_tree, n_neighbors=16, weights=uniform;, score=0.666 total time= 4.3min
[CV 3/3] END algorithm=ball_tree, n_neighbors=18, weights=uniform;, score=0.660 total time= 4.3min
[CV 2/3] END algorithm=ball_tree, n_neighbors=20, weights=distance;, score=0.669 total time= 4.1min
[CV 3/3] END algorithm=kd_tree, n_neighbors=3, weights=uniform;, score=0.625 total time= 5.5min
[CV 3/3] END algorithm=kd_tree, n_neighbors=5, weights=uniform;, score=0.640 total time= 5.6min
[CV 2/3] END algorithm=kd_tree, n_neighbors=7, weights=distance;, score=0.665 total time= 5.9min
[CV 1/3] END algorithm=kd_tree, n_neighbors=10, weights=distance;, score=0.670 total time= 5.9min
[CV 2/3] END algorithm=kd_tree, n_neighbors=13, weights=uniform;, score=0.665 total time= 5.9min
[CV 1/3] END algorithm=kd_tree, n_neighbors=16, weights=uniform;, score=0.666 total time= 5.9min
[CV 3/3] END algorithm=kd_tree, n_neighbors=18, weights=distance;, score=0.669 total time= 5.7min
[CV 1/3] END algorithm=brute, n_neighbors=1, weights=distance;, score=0.594 total time=  19.2s
[CV 1/3] END algorithm=brute, n_neighbors=2, weights=uniform;, score=0.652 total time=  23.5s
[CV 2/3] END algorithm=brute, n_neighbors=3, weights=uniform;, score=0.652 total time=  23.6s
[CV 3/3] END algorithm=brute, n_neighbors=4, weights=distance;, score=0.602 total time=  23.3s
[CV 1/3] END algorithm=brute, n_neighbors=6, weights=distance;, score=0.669 total time=  23.3s
[CV 1/3] END algorithm=brute, n_neighbors=8, weights=distance;, score=0.672 total time=  23.4s
[CV 1/3] END algorithm=brute, n_neighbors=10, weights=distance;, score=0.670 total time=  23.3s
[CV 3/3] END algorithm=brute, n_neighbors=12, weights=distance;, score=0.672 total time=  23.4s
[CV 2/3] END algorithm=brute, n_neighbors=15, weights=uniform;, score=0.665 total time=  23.4s
[CV 2/3] END algorithm=brute, n_neighbors=17, weights=distance;, score=0.670 total time=  23.4s
[CV 2/3] END algorithm=brute, n_neighbors=20, weights=uniform;, score=0.663 total time=  20.0s
[CV 2/3] END class_weight=balanced, gamma=auto, kernel=sigmoid;, score=0.213 total time=61.6min
[CV 2/3] END class_weight=None, gamma=scale, kernel=sigmoid;, score=0.665 total time=38.8min
[CV 3/3] END class_weight=None, gamma=scale, kernel=poly;, score=0.661 total time=50.2min
[CV 3/3] END algorithm=auto, n_neighbors=1, weights=distance;, score=0.482 total time=  28.4s
[CV 3/3] END algorithm=auto, n_neighbors=5, weights=uniform;, score=0.640 total time=  28.5s
[CV 2/3] END algorithm=auto, n_neighbors=8, weights=distance;, score=0.668 total time=  28.1s
[CV 2/3] END algorithm=auto, n_neighbors=11, weights=uniform;, score=0.664 total time=  28.1s
[CV 1/3] END algorithm=auto, n_neighbors=13, weights=distance;, score=0.671 total time=  28.0s
[CV 2/3] END algorithm=auto, n_neighbors=16, weights=uniform;, score=0.664 total time=  27.7s
[CV 2/3] END algorithm=auto, n_neighbors=18, weights=distance;, score=0.670 total time=  26.9s
[CV 3/3] END algorithm=auto, n_neighbors=20, weights=distance;, score=0.671 total time=  26.2s
[CV 3/3] END algorithm=ball_tree, n_neighbors=3, weights=uniform;, score=0.625 total time= 4.4min
[CV 3/3] END algorithm=ball_tree, n_neighbors=5, weights=distance;, score=0.607 total time= 4.4min
[CV 1/3] END algorithm=ball_tree, n_neighbors=8, weights=distance;, score=0.672 total time= 4.3min
[CV 2/3] END algorithm=ball_tree, n_neighbors=11, weights=uniform;, score=0.664 total time= 4.4min
[CV 3/3] END algorithm=ball_tree, n_neighbors=13, weights=distance;, score=0.672 total time= 4.4min
[CV 1/3] END algorithm=ball_tree, n_neighbors=16, weights=distance;, score=0.673 total time= 4.4min
[CV 2/3] END algorithm=ball_tree, n_neighbors=19, weights=uniform;, score=0.664 total time= 4.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=1, weights=distance;, score=0.482 total time= 5.1min
[CV 1/3] END algorithm=kd_tree, n_neighbors=4, weights=uniform;, score=0.662 total time= 5.8min
[CV 3/3] END algorithm=kd_tree, n_neighbors=6, weights=distance;, score=0.627 total time= 5.6min
[CV 1/3] END algorithm=kd_tree, n_neighbors=9, weights=distance;, score=0.669 total time= 5.9min
[CV 2/3] END algorithm=kd_tree, n_neighbors=12, weights=uniform;, score=0.664 total time= 5.9min
[CV 3/3] END algorithm=kd_tree, n_neighbors=14, weights=distance;, score=0.671 total time= 5.7min
[CV 3/3] END algorithm=kd_tree, n_neighbors=17, weights=uniform;, score=0.660 total time= 5.7min
[CV 1/3] END algorithm=kd_tree, n_neighbors=20, weights=uniform;, score=0.666 total time= 6.5min
[CV 3/3] END algorithm=brute, n_neighbors=9, weights=uniform;, score=0.664 total time=  23.6s
[CV 2/3] END algorithm=brute, n_neighbors=11, weights=distance;, score=0.670 total time=  23.3s
[CV 1/3] END algorithm=brute, n_neighbors=14, weights=uniform;, score=0.666 total time=  23.5s
[CV 1/3] END algorithm=brute, n_neighbors=16, weights=distance;, score=0.673 total time=  23.7s
[CV 2/3] END algorithm=brute, n_neighbors=19, weights=uniform;, score=0.664 total time=  23.5s
[CV 1/3] END class_weight=balanced, gamma=scale, kernel=poly;, score=0.661 total time=62.3min
[CV 3/3] END class_weight=None, gamma=scale, kernel=sigmoid;, score=0.657 total time=41.5min
[CV 2/3] END class_weight=None, gamma=scale, kernel=rbf;, score=0.666 total time=50.1min
[CV 2/3] END algorithm=auto, n_neighbors=1, weights=uniform;, score=0.534 total time=  28.3s
[CV 1/3] END algorithm=auto, n_neighbors=4, weights=uniform;, score=0.662 total time=  28.3s
[CV 1/3] END algorithm=auto, n_neighbors=7, weights=distance;, score=0.668 total time=  28.0s
[CV 3/3] END algorithm=auto, n_neighbors=9, weights=distance;, score=0.661 total time=  28.0s
[CV 2/3] END algorithm=auto, n_neighbors=12, weights=distance;, score=0.669 total time=  27.7s
[CV 3/3] END algorithm=auto, n_neighbors=15, weights=uniform;, score=0.663 total time=  27.6s
[CV 1/3] END algorithm=auto, n_neighbors=18, weights=uniform;, score=0.666 total time=  28.0s
[CV 1/3] END algorithm=ball_tree, n_neighbors=1, weights=uniform;, score=0.594 total time= 4.4min
[CV 2/3] END algorithm=ball_tree, n_neighbors=3, weights=distance;, score=0.635 total time= 4.4min
[CV 1/3] END algorithm=ball_tree, n_neighbors=6, weights=distance;, score=0.669 total time= 4.4min
[CV 1/3] END algorithm=ball_tree, n_neighbors=9, weights=uniform;, score=0.667 total time= 4.4min
[CV 2/3] END algorithm=ball_tree, n_neighbors=11, weights=distance;, score=0.670 total time= 4.4min
[CV 3/3] END algorithm=ball_tree, n_neighbors=14, weights=uniform;, score=0.661 total time= 4.4min
[CV 1/3] END algorithm=ball_tree, n_neighbors=17, weights=uniform;, score=0.669 total time= 4.4min
[CV 3/3] END algorithm=ball_tree, n_neighbors=19, weights=distance;, score=0.670 total time= 4.1min
[CV 2/3] END algorithm=kd_tree, n_neighbors=2, weights=distance;, score=0.534 total time= 5.7min
[CV 2/3] END algorithm=kd_tree, n_neighbors=5, weights=distance;, score=0.660 total time= 5.8min
[CV 1/3] END algorithm=kd_tree, n_neighbors=8, weights=distance;, score=0.672 total time= 5.9min
[CV 2/3] END algorithm=kd_tree, n_neighbors=11, weights=uniform;, score=0.664 total time= 5.9min
[CV 1/3] END algorithm=kd_tree, n_neighbors=14, weights=uniform;, score=0.666 total time= 5.9min
[CV 2/3] END algorithm=kd_tree, n_neighbors=16, weights=distance;, score=0.670 total time= 5.9min
[CV 3/3] END algorithm=kd_tree, n_neighbors=19, weights=uniform;, score=0.660 total time= 5.9min
[CV 1/3] END algorithm=brute, n_neighbors=3, weights=uniform;, score=0.658 total time=  23.6s
[CV 3/3] END algorithm=brute, n_neighbors=4, weights=uniform;, score=0.629 total time=  23.5s
[CV 2/3] END algorithm=brute, n_neighbors=6, weights=uniform;, score=0.662 total time=  23.9s
[CV 1/3] END algorithm=brute, n_neighbors=8, weights=uniform;, score=0.668 total time=  23.6s
[CV 3/3] END algorithm=brute, n_neighbors=10, weights=uniform;, score=0.664 total time=  23.5s
[CV 3/3] END algorithm=brute, n_neighbors=12, weights=uniform;, score=0.666 total time=  23.4s
[CV 2/3] END algorithm=brute, n_neighbors=14, weights=distance;, score=0.670 total time=  23.6s
[CV 3/3] END algorithm=brute, n_neighbors=17, weights=uniform;, score=0.660 total time=  23.6s
[CV 3/3] END algorithm=brute, n_neighbors=19, weights=distance;, score=0.670 total time=  22.9s
[CV 2/3] END class_weight=balanced, gamma=scale, kernel=rbf;, score=0.589 total time=65.9min
[CV 2/3] END class_weight=None, gamma=scale, kernel=poly;, score=0.661 total time=57.5min
[CV 1/3] END class_weight=None, gamma=auto, kernel=rbf;, score=0.661 total time=31.3min
[CV 3/3] END algorithm=auto, n_neighbors=2, weights=uniform;, score=0.632 total time=  28.4s
[CV 2/3] END algorithm=auto, n_neighbors=5, weights=uniform;, score=0.661 total time=  28.1s
[CV 2/3] END algorithm=auto, n_neighbors=7, weights=uniform;, score=0.663 total time=  28.4s
[CV 3/3] END algorithm=auto, n_neighbors=10, weights=distance;, score=0.659 total time=  28.5s
[CV 2/3] END algorithm=auto, n_neighbors=14, weights=uniform;, score=0.661 total time=  28.3s
[CV 3/3] END algorithm=auto, n_neighbors=16, weights=distance;, score=0.673 total time=  28.0s
[CV 2/3] END algorithm=auto, n_neighbors=19, weights=uniform;, score=0.664 total time=  27.7s
[CV 3/3] END algorithm=ball_tree, n_neighbors=1, weights=distance;, score=0.482 total time= 4.4min
[CV 2/3] END algorithm=ball_tree, n_neighbors=4, weights=uniform;, score=0.655 total time= 4.4min
[CV 3/3] END algorithm=ball_tree, n_neighbors=6, weights=distance;, score=0.627 total time= 4.4min
[CV 1/3] END algorithm=ball_tree, n_neighbors=9, weights=distance;, score=0.669 total time= 4.4min
[CV 1/3] END algorithm=ball_tree, n_neighbors=12, weights=uniform;, score=0.668 total time= 4.4min
[CV 2/3] END algorithm=ball_tree, n_neighbors=14, weights=distance;, score=0.670 total time= 4.4min
[CV 3/3] END algorithm=ball_tree, n_neighbors=17, weights=uniform;, score=0.660 total time= 4.4min
[CV 3/3] END algorithm=ball_tree, n_neighbors=20, weights=uniform;, score=0.660 total time= 4.1min
[CV 1/3] END algorithm=kd_tree, n_neighbors=3, weights=uniform;, score=0.658 total time= 5.9min
[CV 1/3] END algorithm=kd_tree, n_neighbors=6, weights=uniform;, score=0.664 total time= 5.9min
[CV 3/3] END algorithm=kd_tree, n_neighbors=8, weights=distance;, score=0.641 total time= 5.7min
[CV 3/3] END algorithm=kd_tree, n_neighbors=11, weights=uniform;, score=0.661 total time= 5.7min
[CV 2/3] END algorithm=kd_tree, n_neighbors=13, weights=distance;, score=0.672 total time= 5.9min
[CV 1/3] END algorithm=kd_tree, n_neighbors=16, weights=distance;, score=0.673 total time= 5.9min
[CV 2/3] END algorithm=kd_tree, n_neighbors=19, weights=uniform;, score=0.664 total time= 5.9min
[CV 1/3] END algorithm=brute, n_neighbors=2, weights=distance;, score=0.594 total time=  18.9s
[CV 1/3] END algorithm=brute, n_neighbors=3, weights=distance;, score=0.641 total time=  19.0s
[CV 2/3] END algorithm=brute, n_neighbors=4, weights=distance;, score=0.647 total time=  19.0s
[CV 3/3] END algorithm=brute, n_neighbors=6, weights=uniform;, score=0.655 total time=  19.1s
[CV 2/3] END algorithm=brute, n_neighbors=7, weights=uniform;, score=0.663 total time=  19.2s
[CV 1/3] END algorithm=brute, n_neighbors=9, weights=uniform;, score=0.667 total time=  19.2s
[CV 2/3] END algorithm=brute, n_neighbors=11, weights=uniform;, score=0.664 total time=  19.1s
[CV 1/3] END algorithm=brute, n_neighbors=13, weights=uniform;, score=0.666 total time=  19.0s
[CV 3/3] END algorithm=brute, n_neighbors=14, weights=distance;, score=0.671 total time=  19.0s
[CV 3/3] END algorithm=brute, n_neighbors=16, weights=distance;, score=0.673 total time=  19.1s
[CV 1/3] END algorithm=brute, n_neighbors=19, weights=uniform;, score=0.668 total time=  19.1s
[CV 1/3] END class_weight=balanced, gamma=scale, kernel=sigmoid;, score=0.575 total time=55.6min
[CV 1/3] END class_weight=balanced, gamma=auto, kernel=rbf;, score=0.213 total time=69.3min
[CV 3/3] END class_weight=None, gamma=auto, kernel=rbf;, score=0.661 total time=29.7min
[CV 2/3] END algorithm=auto, n_neighbors=2, weights=distance;, score=0.534 total time=  28.3s
[CV 2/3] END algorithm=auto, n_neighbors=4, weights=uniform;, score=0.655 total time=  28.2s
[CV 3/3] END algorithm=auto, n_neighbors=6, weights=distance;, score=0.627 total time=  28.0s
[CV 1/3] END algorithm=auto, n_neighbors=9, weights=distance;, score=0.669 total time=  27.5s
[CV 2/3] END algorithm=auto, n_neighbors=12, weights=uniform;, score=0.664 total time=  27.2s
[CV 3/3] END algorithm=auto, n_neighbors=14, weights=distance;, score=0.671 total time=  26.4s
[CV 1/3] END algorithm=auto, n_neighbors=17, weights=distance;, score=0.673 total time=  25.7s
[CV 2/3] END algorithm=auto, n_neighbors=20, weights=uniform;, score=0.663 total time=  25.5s
[CV 3/3] END algorithm=ball_tree, n_neighbors=2, weights=distance;, score=0.482 total time= 4.3min
[CV 1/3] END algorithm=ball_tree, n_neighbors=5, weights=distance;, score=0.654 total time= 4.3min
[CV 2/3] END algorithm=ball_tree, n_neighbors=8, weights=uniform;, score=0.666 total time= 4.3min
[CV 3/3] END algorithm=ball_tree, n_neighbors=10, weights=distance;, score=0.659 total time= 4.3min
[CV 1/3] END algorithm=ball_tree, n_neighbors=13, weights=distance;, score=0.671 total time= 4.3min
[CV 2/3] END algorithm=ball_tree, n_neighbors=16, weights=uniform;, score=0.664 total time= 4.3min
[CV 3/3] END algorithm=ball_tree, n_neighbors=18, weights=distance;, score=0.669 total time= 4.3min
[CV 3/3] END algorithm=ball_tree, n_neighbors=20, weights=distance;, score=0.671 total time= 4.1min
[CV 1/3] END algorithm=kd_tree, n_neighbors=3, weights=distance;, score=0.641 total time= 5.8min
[CV 3/3] END algorithm=kd_tree, n_neighbors=5, weights=distance;, score=0.607 total time= 5.6min
[CV 2/3] END algorithm=kd_tree, n_neighbors=8, weights=uniform;, score=0.666 total time= 5.9min
[CV 1/3] END algorithm=kd_tree, n_neighbors=11, weights=uniform;, score=0.667 total time= 5.9min
[CV 3/3] END algorithm=kd_tree, n_neighbors=13, weights=distance;, score=0.672 total time= 5.7min
[CV 3/3] END algorithm=kd_tree, n_neighbors=16, weights=uniform;, score=0.661 total time= 5.7min
[CV 2/3] END algorithm=kd_tree, n_neighbors=18, weights=distance;, score=0.670 total time= 6.0min
[CV 2/3] END algorithm=brute, n_neighbors=1, weights=distance;, score=0.534 total time=  23.5s
[CV 3/3] END algorithm=brute, n_neighbors=2, weights=distance;, score=0.482 total time=  23.6s
[CV 2/3] END algorithm=brute, n_neighbors=4, weights=uniform;, score=0.655 total time=  23.6s
[CV 3/3] END algorithm=brute, n_neighbors=5, weights=distance;, score=0.607 total time=  24.0s
[CV 3/3] END algorithm=brute, n_neighbors=7, weights=distance;, score=0.644 total time=  23.6s
[CV 3/3] END algorithm=brute, n_neighbors=9, weights=distance;, score=0.661 total time=  23.5s
[CV 1/3] END algorithm=brute, n_neighbors=12, weights=uniform;, score=0.668 total time=  23.6s
[CV 3/3] END algorithm=brute, n_neighbors=14, weights=uniform;, score=0.661 total time=  23.7s
[CV 1/3] END algorithm=brute, n_neighbors=17, weights=uniform;, score=0.669 total time=  23.7s
[CV 1/3] END algorithm=brute, n_neighbors=19, weights=distance;, score=0.675 total time=  21.5s
[CV 3/3] END class_weight=balanced, gamma=scale, kernel=poly;, score=0.661 total time=61.0min
[CV 1/3] END class_weight=None, gamma=scale, kernel=sigmoid;, score=0.667 total time=39.6min
[CV 1/3] END class_weight=None, gamma=scale, kernel=rbf;, score=0.664 total time=54.4min
[CV 3/3] END algorithm=auto, n_neighbors=3, weights=uniform;, score=0.625 total time=  28.5s
[CV 2/3] END algorithm=auto, n_neighbors=6, weights=uniform;, score=0.662 total time=  28.4s
[CV 3/3] END algorithm=auto, n_neighbors=8, weights=distance;, score=0.641 total time=  27.9s
[CV 1/3] END algorithm=auto, n_neighbors=10, weights=distance;, score=0.670 total time=  27.7s
[CV 1/3] END algorithm=auto, n_neighbors=12, weights=distance;, score=0.669 total time=  27.5s
[CV 2/3] END algorithm=auto, n_neighbors=15, weights=uniform;, score=0.665 total time=  27.7s
[CV 3/3] END algorithm=auto, n_neighbors=17, weights=distance;, score=0.672 total time=  27.3s
[CV 1/3] END algorithm=auto, n_neighbors=20, weights=distance;, score=0.674 total time=  27.0s
[CV 1/3] END algorithm=ball_tree, n_neighbors=3, weights=distance;, score=0.641 total time= 4.4min
[CV 2/3] END algorithm=ball_tree, n_neighbors=6, weights=uniform;, score=0.662 total time= 4.4min
[CV 3/3] END algorithm=ball_tree, n_neighbors=8, weights=distance;, score=0.641 total time= 4.4min
[CV 1/3] END algorithm=ball_tree, n_neighbors=11, weights=distance;, score=0.671 total time= 4.4min
[CV 2/3] END algorithm=ball_tree, n_neighbors=14, weights=uniform;, score=0.661 total time= 4.4min
[CV 3/3] END algorithm=ball_tree, n_neighbors=16, weights=distance;, score=0.673 total time= 4.4min
[CV 1/3] END algorithm=ball_tree, n_neighbors=19, weights=distance;, score=0.675 total time= 4.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=2, weights=uniform;, score=0.656 total time= 5.8min
[CV 3/3] END algorithm=kd_tree, n_neighbors=4, weights=distance;, score=0.602 total time= 5.6min
[CV 3/3] END algorithm=kd_tree, n_neighbors=7, weights=uniform;, score=0.645 total time= 5.6min
[CV 3/3] END algorithm=kd_tree, n_neighbors=9, weights=distance;, score=0.661 total time= 5.7min
[CV 1/3] END algorithm=kd_tree, n_neighbors=12, weights=distance;, score=0.669 total time= 5.9min
[CV 2/3] END algorithm=kd_tree, n_neighbors=15, weights=uniform;, score=0.665 total time= 5.9min
[CV 3/3] END algorithm=kd_tree, n_neighbors=17, weights=distance;, score=0.672 total time= 5.7min
[CV 1/3] END algorithm=kd_tree, n_neighbors=20, weights=distance;, score=0.674 total time= 5.9min
[CV 2/3] END algorithm=brute, n_neighbors=9, weights=uniform;, score=0.667 total time=  19.1s
[CV 1/3] END algorithm=brute, n_neighbors=11, weights=distance;, score=0.671 total time=  19.1s
[CV 2/3] END algorithm=brute, n_neighbors=13, weights=distance;, score=0.672 total time=  18.5s
[CV 3/3] END algorithm=brute, n_neighbors=15, weights=uniform;, score=0.663 total time=  24.2s
[CV 3/3] END algorithm=brute, n_neighbors=17, weights=distance;, score=0.672 total time=  23.9s
[CV 1/3] END algorithm=brute, n_neighbors=20, weights=distance;, score=0.674 total time=  18.5s
[CV 3/3] END class_weight=balanced, gamma=auto, kernel=sigmoid;, score=0.213 total time=62.3min
[CV 1/3] END class_weight=None, gamma=scale, kernel=linear;, score=0.634 total time=55.7min
[CV 3/3] END class_weight=None, gamma=auto, kernel=linear;, score=0.636 total time=38.5min
[CV 1/3] END algorithm=auto, n_neighbors=1, weights=uniform;, score=0.594 total time=  28.4s
[CV 2/3] END algorithm=auto, n_neighbors=4, weights=distance;, score=0.647 total time=  28.2s
[CV 1/3] END algorithm=auto, n_neighbors=7, weights=uniform;, score=0.669 total time=  28.5s
[CV 2/3] END algorithm=auto, n_neighbors=10, weights=distance;, score=0.668 total time=  28.5s
[CV 1/3] END algorithm=auto, n_neighbors=14, weights=uniform;, score=0.666 total time=  28.2s
[CV 3/3] END algorithm=auto, n_neighbors=16, weights=uniform;, score=0.661 total time=  28.0s
[CV 1/3] END algorithm=auto, n_neighbors=19, weights=uniform;, score=0.668 total time=  27.5s
[CV 1/3] END algorithm=ball_tree, n_neighbors=1, weights=distance;, score=0.594 total time= 4.3min
[CV 1/3] END algorithm=ball_tree, n_neighbors=4, weights=uniform;, score=0.662 total time= 4.4min
[CV 3/3] END algorithm=ball_tree, n_neighbors=6, weights=uniform;, score=0.655 total time= 4.4min
[CV 2/3] END algorithm=ball_tree, n_neighbors=9, weights=uniform;, score=0.667 total time= 4.4min
[CV 3/3] END algorithm=ball_tree, n_neighbors=11, weights=distance;, score=0.663 total time= 4.4min
[CV 3/3] END algorithm=ball_tree, n_neighbors=14, weights=distance;, score=0.671 total time= 4.4min
[CV 2/3] END algorithm=ball_tree, n_neighbors=17, weights=distance;, score=0.670 total time= 4.4min
[CV 1/3] END algorithm=ball_tree, n_neighbors=20, weights=distance;, score=0.674 total time= 4.1min
[CV 2/3] END algorithm=kd_tree, n_neighbors=3, weights=uniform;, score=0.652 total time= 5.9min
[CV 2/3] END algorithm=kd_tree, n_neighbors=6, weights=uniform;, score=0.662 total time= 5.9min
[CV 2/3] END algorithm=kd_tree, n_neighbors=8, weights=distance;, score=0.668 total time= 5.9min
[CV 1/3] END algorithm=kd_tree, n_neighbors=11, weights=distance;, score=0.671 total time= 5.9min
[CV 2/3] END algorithm=kd_tree, n_neighbors=14, weights=uniform;, score=0.661 total time= 5.9min
[CV 3/3] END algorithm=kd_tree, n_neighbors=16, weights=distance;, score=0.673 total time= 5.7min
[CV 1/3] END algorithm=kd_tree, n_neighbors=19, weights=distance;, score=0.675 total time= 5.9min
[CV 3/3] END algorithm=brute, n_neighbors=3, weights=uniform;, score=0.625 total time=  19.1s
[CV 1/3] END algorithm=brute, n_neighbors=4, weights=distance;, score=0.649 total time=  19.1s
[CV 1/3] END algorithm=brute, n_neighbors=6, weights=uniform;, score=0.664 total time=  19.2s
[CV 3/3] END algorithm=brute, n_neighbors=6, weights=distance;, score=0.627 total time=  19.2s
[CV 3/3] END algorithm=brute, n_neighbors=8, weights=distance;, score=0.641 total time=  21.2s
[CV 3/3] END algorithm=brute, n_neighbors=11, weights=uniform;, score=0.661 total time=  23.4s
[CV 3/3] END algorithm=brute, n_neighbors=13, weights=distance;, score=0.672 total time=  23.4s
[CV 1/3] END algorithm=brute, n_neighbors=16, weights=uniform;, score=0.666 total time=  23.3s
[CV 1/3] END algorithm=brute, n_neighbors=18, weights=distance;, score=0.673 total time=  23.3s
[CV 3/3] END algorithm=brute, n_neighbors=20, weights=distance;, score=0.671 total time=  15.6s
[CV 1/3] END class_weight=balanced, gamma=auto, kernel=linear;, score=0.621 total time=54.3min
[CV 3/3] END class_weight=balanced, gamma=auto, kernel=linear;, score=0.630 total time=53.2min
[CV 3/3] END class_weight=None, gamma=scale, kernel=rbf;, score=0.665 total time=49.3min
[CV 1/3] END algorithm=auto, n_neighbors=3, weights=uniform;, score=0.658 total time=  28.3s
[CV 3/3] END algorithm=auto, n_neighbors=4, weights=uniform;, score=0.629 total time=  28.4s
[CV 2/3] END algorithm=auto, n_neighbors=7, weights=distance;, score=0.665 total time=  28.1s
[CV 2/3] END algorithm=auto, n_neighbors=10, weights=uniform;, score=0.666 total time=  28.1s
[CV 1/3] END algorithm=auto, n_neighbors=13, weights=uniform;, score=0.666 total time=  27.8s
[CV 1/3] END algorithm=auto, n_neighbors=15, weights=distance;, score=0.672 total time=  27.4s
[CV 2/3] END algorithm=auto, n_neighbors=18, weights=uniform;, score=0.664 total time=  27.8s
[CV 2/3] END algorithm=ball_tree, n_neighbors=1, weights=uniform;, score=0.534 total time= 4.4min
[CV 3/3] END algorithm=ball_tree, n_neighbors=3, weights=distance;, score=0.583 total time= 4.4min
[CV 2/3] END algorithm=ball_tree, n_neighbors=6, weights=distance;, score=0.658 total time= 4.4min
[CV 3/3] END algorithm=ball_tree, n_neighbors=9, weights=uniform;, score=0.664 total time= 4.4min
[CV 2/3] END algorithm=ball_tree, n_neighbors=12, weights=uniform;, score=0.664 total time= 4.4min
[CV 1/3] END algorithm=ball_tree, n_neighbors=14, weights=distance;, score=0.672 total time= 4.4min
[CV 2/3] END algorithm=ball_tree, n_neighbors=17, weights=uniform;, score=0.664 total time= 4.4min
[CV 1/3] END algorithm=ball_tree, n_neighbors=20, weights=uniform;, score=0.666 total time= 4.1min
[CV 3/3] END algorithm=kd_tree, n_neighbors=2, weights=distance;, score=0.482 total time= 5.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=5, weights=uniform;, score=0.661 total time= 5.9min
[CV 1/3] END algorithm=kd_tree, n_neighbors=8, weights=uniform;, score=0.668 total time= 5.9min
[CV 2/3] END algorithm=kd_tree, n_neighbors=10, weights=distance;, score=0.668 total time= 5.9min
[CV 1/3] END algorithm=kd_tree, n_neighbors=13, weights=distance;, score=0.671 total time= 5.9min
[CV 2/3] END algorithm=kd_tree, n_neighbors=16, weights=uniform;, score=0.664 total time= 5.9min
[CV 1/3] END algorithm=kd_tree, n_neighbors=19, weights=uniform;, score=0.668 total time= 5.9min
[CV 3/3] END algorithm=brute, n_neighbors=1, weights=distance;, score=0.482 total time=  18.9s
[CV 2/3] END algorithm=brute, n_neighbors=2, weights=distance;, score=0.534 total time=  22.5s
[CV 1/3] END algorithm=brute, n_neighbors=4, weights=uniform;, score=0.662 total time=  23.6s
[CV 1/3] END algorithm=brute, n_neighbors=5, weights=distance;, score=0.654 total time=  23.4s
[CV 1/3] END algorithm=brute, n_neighbors=7, weights=distance;, score=0.668 total time=  23.5s
[CV 1/3] END algorithm=brute, n_neighbors=9, weights=distance;, score=0.669 total time=  23.6s
[CV 3/3] END algorithm=brute, n_neighbors=11, weights=distance;, score=0.663 total time=  23.4s
[CV 2/3] END algorithm=brute, n_neighbors=14, weights=uniform;, score=0.661 total time=  23.4s
[CV 2/3] END algorithm=brute, n_neighbors=16, weights=distance;, score=0.670 total time=  23.8s
[CV 3/3] END algorithm=brute, n_neighbors=19, weights=uniform;, score=0.660 total time=  23.4s
[CV 2/3] END class_weight=balanced, gamma=scale, kernel=poly;, score=0.662 total time=59.4min
[CV 3/3] END class_weight=balanced, gamma=auto, kernel=rbf;, score=0.213 total time=65.5min
[CV 2/3] END class_weight=None, gamma=auto, kernel=rbf;, score=0.661 total time=32.4min
[CV 3/3] END algorithm=auto, n_neighbors=2, weights=distance;, score=0.482 total time=  27.5s
[CV 3/3] END algorithm=auto, n_neighbors=3, weights=distance;, score=0.583 total time=  27.5s
[CV 1/3] END algorithm=auto, n_neighbors=6, weights=distance;, score=0.669 total time=  27.3s
[CV 1/3] END algorithm=auto, n_neighbors=9, weights=uniform;, score=0.667 total time=  26.7s
[CV 2/3] END algorithm=auto, n_neighbors=11, weights=distance;, score=0.670 total time=  26.2s
[CV 3/3] END algorithm=auto, n_neighbors=14, weights=uniform;, score=0.661 total time=  25.6s
[CV 1/3] END algorithm=auto, n_neighbors=17, weights=uniform;, score=0.669 total time=  25.3s
[CV 2/3] END algorithm=auto, n_neighbors=19, weights=distance;, score=0.671 total time=  24.8s
[CV 3/3] END algorithm=ball_tree, n_neighbors=2, weights=uniform;, score=0.632 total time= 4.3min
[CV 1/3] END algorithm=ball_tree, n_neighbors=5, weights=uniform;, score=0.669 total time= 4.3min
[CV 2/3] END algorithm=ball_tree, n_neighbors=7, weights=distance;, score=0.665 total time= 4.3min
[CV 3/3] END algorithm=ball_tree, n_neighbors=10, weights=uniform;, score=0.664 total time= 4.3min
[CV 1/3] END algorithm=ball_tree, n_neighbors=13, weights=uniform;, score=0.666 total time= 4.3min
[CV 1/3] END algorithm=ball_tree, n_neighbors=15, weights=uniform;, score=0.667 total time= 4.3min
[CV 1/3] END algorithm=ball_tree, n_neighbors=17, weights=distance;, score=0.673 total time= 4.3min
[CV 2/3] END algorithm=ball_tree, n_neighbors=19, weights=distance;, score=0.671 total time= 4.1min
[CV 3/3] END algorithm=kd_tree, n_neighbors=2, weights=uniform;, score=0.632 total time= 5.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=5, weights=uniform;, score=0.669 total time= 5.9min
[CV 3/3] END algorithm=kd_tree, n_neighbors=7, weights=distance;, score=0.644 total time= 5.6min
[CV 3/3] END algorithm=kd_tree, n_neighbors=10, weights=uniform;, score=0.664 total time= 5.7min
[CV 1/3] END algorithm=kd_tree, n_neighbors=13, weights=uniform;, score=0.666 total time= 5.9min
[CV 2/3] END algorithm=kd_tree, n_neighbors=15, weights=distance;, score=0.671 total time= 5.9min
[CV 3/3] END algorithm=kd_tree, n_neighbors=18, weights=uniform;, score=0.660 total time= 5.8min
[CV 1/3] END algorithm=brute, n_neighbors=1, weights=uniform;, score=0.594 total time=  18.6s
[CV 3/3] END algorithm=brute, n_neighbors=1, weights=uniform;, score=0.482 total time=  26.6s
[CV 3/3] END algorithm=brute, n_neighbors=2, weights=uniform;, score=0.632 total time=  26.4s
[CV 3/3] END algorithm=brute, n_neighbors=3, weights=distance;, score=0.583 total time=  25.9s
[CV 3/3] END algorithm=brute, n_neighbors=5, weights=uniform;, score=0.640 total time=  25.6s
[CV 3/3] END algorithm=brute, n_neighbors=7, weights=uniform;, score=0.645 total time=  27.0s
[CV 2/3] END algorithm=brute, n_neighbors=10, weights=uniform;, score=0.666 total time=  26.9s
[CV 2/3] END algorithm=brute, n_neighbors=12, weights=distance;, score=0.669 total time=  26.7s
[CV 2/3] END algorithm=brute, n_neighbors=15, weights=distance;, score=0.671 total time=  27.2s
[CV 2/3] END algorithm=brute, n_neighbors=18, weights=uniform;, score=0.664 total time=  27.0s
[CV 2/3] END class_weight=balanced, gamma=scale, kernel=sigmoid;, score=0.547 total time=55.0min
[CV 2/3] END class_weight=balanced, gamma=auto, kernel=poly;, score=0.213 total time=62.1min
[CV 2/3] END class_weight=None, gamma=auto, kernel=linear;, score=0.628 total time=40.6min
[CV 2/3] END algorithm=auto, n_neighbors=3, weights=uniform;, score=0.652 total time=  28.5s
[CV 1/3] END algorithm=auto, n_neighbors=6, weights=uniform;, score=0.664 total time=  28.3s
[CV 3/3] END algorithm=auto, n_neighbors=8, weights=uniform;, score=0.663 total time=  28.4s
[CV 1/3] END algorithm=auto, n_neighbors=11, weights=distance;, score=0.671 total time=  28.2s
[CV 3/3] END algorithm=auto, n_neighbors=13, weights=distance;, score=0.672 total time=  28.4s
[CV 2/3] END algorithm=auto, n_neighbors=16, weights=distance;, score=0.670 total time=  28.4s
[CV 1/3] END algorithm=auto, n_neighbors=19, weights=distance;, score=0.675 total time=  28.0s
[CV 2/3] END algorithm=ball_tree, n_neighbors=2, weights=uniform;, score=0.656 total time= 4.4min
[CV 1/3] END algorithm=ball_tree, n_neighbors=4, weights=distance;, score=0.649 total time= 4.4min
[CV 1/3] END algorithm=ball_tree, n_neighbors=7, weights=uniform;, score=0.669 total time= 4.4min
[CV 2/3] END algorithm=ball_tree, n_neighbors=9, weights=distance;, score=0.671 total time= 4.4min
[CV 3/3] END algorithm=ball_tree, n_neighbors=12, weights=uniform;, score=0.666 total time= 4.4min
[CV 2/3] END algorithm=ball_tree, n_neighbors=15, weights=uniform;, score=0.665 total time= 4.4min
[CV 1/3] END algorithm=ball_tree, n_neighbors=18, weights=uniform;, score=0.666 total time= 4.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=1, weights=uniform;, score=0.594 total time= 5.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=4, weights=uniform;, score=0.655 total time= 5.9min
[CV 1/3] END algorithm=kd_tree, n_neighbors=7, weights=uniform;, score=0.669 total time= 5.9min
[CV 2/3] END algorithm=kd_tree, n_neighbors=9, weights=distance;, score=0.671 total time= 5.9min
[CV 3/3] END algorithm=kd_tree, n_neighbors=12, weights=uniform;, score=0.666 total time= 5.7min
[CV 1/3] END algorithm=kd_tree, n_neighbors=15, weights=uniform;, score=0.667 total time= 5.9min
[CV 2/3] END algorithm=kd_tree, n_neighbors=17, weights=distance;, score=0.670 total time= 5.9min
[CV 3/3] END algorithm=kd_tree, n_neighbors=20, weights=uniform;, score=0.660 total time= 5.8min
[CV 3/3] END algorithm=brute, n_neighbors=8, weights=uniform;, score=0.663 total time=  25.9s
[CV 3/3] END algorithm=brute, n_neighbors=10, weights=distance;, score=0.659 total time=  26.2s
[CV 3/3] END algorithm=brute, n_neighbors=13, weights=uniform;, score=0.665 total time=  27.5s
[CV 3/3] END algorithm=brute, n_neighbors=16, weights=uniform;, score=0.661 total time=  26.8s
[CV 2/3] END algorithm=brute, n_neighbors=18, weights=distance;, score=0.670 total time=  26.2s
[CV 2/3] END class_weight=balanced, gamma=scale, kernel=linear;, score=0.601 total time=55.1min
[CV 3/3] END class_weight=balanced, gamma=auto, kernel=poly;, score=0.213 total time=61.9min
[CV 1/3] END class_weight=None, gamma=auto, kernel=linear;, score=0.634 total time=42.7min
saving: KNN_description_1637260229 as png
saving: DT_description_1637260365 as png
Fitting 3 folds for each of 16 candidates, totalling 48 fits
saving: SVC_description_1637275111 as png
Fitting 3 folds for each of 168 candidates, totalling 504 fits
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=hinge, penalty=elasticnet;, score=0.431 total time=  45.3s
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=modified_huber, penalty=elasticnet;, score=0.658 total time=  34.6s
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=perceptron, penalty=l2;, score=0.663 total time=   8.2s
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=perceptron, penalty=l1;, score=0.626 total time= 1.2min
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=log, penalty=l1;, score=0.586 total time= 1.9min
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=perceptron, penalty=l1;, score=0.572 total time= 1.6min
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=huber, penalty=l2;, score=0.601 total time= 1.0min
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=huber, penalty=elasticnet;, score=0.620 total time= 2.1min
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=log, penalty=elasticnet;, score=0.605 total time= 2.0min
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=perceptron, penalty=l2;, score=0.566 total time=  13.7s
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=perceptron, penalty=l2;, score=0.591 total time=  12.8s
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=perceptron, penalty=l1;, score=0.584 total time= 1.7min
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_loss, penalty=l1;, score=0.310 total time= 2.2min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=log, penalty=l1;, score=0.572 total time= 6.2min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_hinge, penalty=elasticnet;, score=0.570 total time=50.7min
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=squared_loss, penalty=elasticnet;, score=0.661 total time= 3.1min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=hinge, penalty=elasticnet;, score=0.633 total time=  42.4s
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=modified_huber, penalty=elasticnet;, score=0.585 total time=  29.5s
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=squared_hinge, penalty=elasticnet;, score=0.563 total time=  34.2s
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=squared_loss, penalty=l1;, score=0.481 total time=  23.1s
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=huber, penalty=elasticnet;, score=0.231 total time=  26.9s
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=log, penalty=l2;, score=0.634 total time=  26.9s
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=modified_huber, penalty=l2;, score=0.594 total time=  15.3s
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=modified_huber, penalty=l2;, score=0.593 total time=  17.0s
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=modified_huber, penalty=l1;, score=0.575 total time= 2.3min
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=squared_loss, penalty=l2;, score=0.232 total time= 1.1min
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=huber, penalty=l1;, score=0.630 total time= 1.2min
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=log, penalty=l2;, score=0.620 total time=  37.6s
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=log, penalty=l1;, score=0.618 total time= 2.0min
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_hinge, penalty=l1;, score=0.561 total time= 3.1min
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=huber, penalty=l1;, score=0.641 total time= 1.2min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=log, penalty=l1;, score=0.578 total time= 6.3min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_hinge, penalty=l1;, score=0.585 total time= 5.7min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_loss, penalty=l1;, score=0.338 total time=29.6min
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=squared_loss, penalty=l2;, score=0.338 total time=  54.3s
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=squared_loss, penalty=elasticnet;, score=0.661 total time= 1.4min
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=hinge, penalty=l1;, score=0.661 total time= 2.0min
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=log, penalty=l1;, score=0.661 total time= 2.7min
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=modified_huber, penalty=l1;, score=0.661 total time= 2.8min
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=squared_hinge, penalty=l1;, score=0.579 total time= 5.7min
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=squared_loss, penalty=elasticnet;, score=0.661 total time= 3.2min
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=log, penalty=l1;, score=0.583 total time= 1.4min
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=perceptron, penalty=l1;, score=0.556 total time= 1.1min
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=hinge, penalty=elasticnet;, score=0.618 total time= 1.9min
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=squared_hinge, penalty=elasticnet;, score=0.627 total time= 1.7min
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=squared_loss, penalty=l1;, score=0.341 total time= 4.2min
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=modified_huber, penalty=elasticnet;, score=0.567 total time= 2.4min
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=perceptron, penalty=elasticnet;, score=0.582 total time= 1.6min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=hinge, penalty=l2;, score=0.594 total time=  38.4s
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=hinge, penalty=elasticnet;, score=0.577 total time= 4.6min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_hinge, penalty=l2;, score=0.573 total time= 6.1min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_loss, penalty=l2;, score=0.363 total time=19.2min
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=log, penalty=elasticnet;, score=0.661 total time=  16.1s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=modified_huber, penalty=l2;, score=0.660 total time=  14.1s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=modified_huber, penalty=elasticnet;, score=0.661 total time=  20.9s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=squared_hinge, penalty=l1;, score=0.536 total time=22.8min
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=perceptron, penalty=l1;, score=0.661 total time= 2.2min
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=squared_loss, penalty=l2;, score=0.660 total time= 1.9min
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=squared_loss, penalty=elasticnet;, score=0.661 total time= 3.6min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=log, penalty=l1;, score=0.514 total time= 1.6min
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=perceptron, penalty=elasticnet;, score=0.510 total time=  33.0s
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=huber, penalty=l1;, score=0.134 total time= 1.8min
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=modified_huber, penalty=elasticnet;, score=0.615 total time= 1.8min
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=perceptron, penalty=elasticnet;, score=0.618 total time= 1.3min
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=huber, penalty=l1;, score=0.632 total time= 1.2min
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=log, penalty=l2;, score=0.617 total time=  34.8s
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=log, penalty=l1;, score=0.598 total time= 2.0min
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_hinge, penalty=l2;, score=0.573 total time=  13.4s
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_hinge, penalty=elasticnet;, score=0.564 total time= 2.7min
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_loss, penalty=elasticnet;, score=0.228 total time=  26.6s
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=huber, penalty=elasticnet;, score=0.619 total time= 1.8min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=log, penalty=elasticnet;, score=0.617 total time= 5.6min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_hinge, penalty=l1;, score=0.583 total time= 6.3min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_loss, penalty=l1;, score=0.335 total time=22.6min
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=modified_huber, penalty=l2;, score=0.658 total time=  48.6s
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=modified_huber, penalty=elasticnet;, score=0.661 total time= 1.6min
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=squared_hinge, penalty=l2;, score=0.651 total time=  48.1s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=squared_hinge, penalty=elasticnet;, score=0.611 total time= 2.1min
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=perceptron, penalty=l1;, score=0.213 total time= 1.1min
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=squared_loss, penalty=l2;, score=0.621 total time=  55.9s
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=huber, penalty=l2;, score=0.661 total time=  11.9s
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=huber, penalty=l1;, score=0.661 total time=  16.8s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=huber, penalty=elasticnet;, score=0.661 total time=  16.8s
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=hinge, penalty=l2;, score=0.661 total time= 1.2min
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=log, penalty=l2;, score=0.661 total time= 1.8min
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=log, penalty=elasticnet;, score=0.661 total time= 3.0min
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=modified_huber, penalty=elasticnet;, score=0.661 total time= 3.0min
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=squared_hinge, penalty=elasticnet;, score=0.661 total time= 3.1min
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=squared_loss, penalty=l2;, score=0.661 total time= 2.1min
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=huber, penalty=l2;, score=0.661 total time= 1.4min
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=huber, penalty=l1;, score=0.661 total time= 2.1min
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=hinge, penalty=l1;, score=0.601 total time= 1.1min
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=squared_hinge, penalty=l1;, score=0.602 total time= 1.7min
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=log, penalty=l1;, score=0.596 total time= 1.6min
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=perceptron, penalty=l2;, score=0.575 total time=  14.6s
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=perceptron, penalty=l1;, score=0.591 total time= 1.7min
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=huber, penalty=l2;, score=0.601 total time= 1.0min
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=hinge, penalty=l2;, score=0.608 total time=  15.5s
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=hinge, penalty=l2;, score=0.563 total time=  23.2s
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=hinge, penalty=elasticnet;, score=0.577 total time= 1.6min
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=modified_huber, penalty=l2;, score=0.573 total time=  23.9s
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=modified_huber, penalty=l2;, score=0.591 total time=  17.1s
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=modified_huber, penalty=elasticnet;, score=0.587 total time= 2.0min
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=perceptron, penalty=l1;, score=0.575 total time= 1.6min
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=huber, penalty=l2;, score=0.607 total time=  33.7s
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=hinge, penalty=l2;, score=0.608 total time=  38.6s
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=log, penalty=l2;, score=0.622 total time= 1.8min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=modified_huber, penalty=l2;, score=0.587 total time=  45.7s
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=modified_huber, penalty=l1;, score=0.585 total time= 7.0min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=perceptron, penalty=elasticnet;, score=0.576 total time= 4.5min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=huber, penalty=l2;, score=0.603 total time= 1.9min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=huber, penalty=l1;, score=0.657 total time= 3.7min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=huber, penalty=elasticnet;, score=0.640 total time= 5.0min
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=hinge, penalty=elasticnet;, score=0.661 total time=  14.2s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=log, penalty=l2;, score=0.639 total time=  14.3s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=log, penalty=elasticnet;, score=0.661 total time=  35.5s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=modified_huber, penalty=l1;, score=0.661 total time=  16.6s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=modified_huber, penalty=elasticnet;, score=0.661 total time=  17.9s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=squared_hinge, penalty=l1;, score=0.640 total time=  56.0s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=perceptron, penalty=l2;, score=0.661 total time=  10.7s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=perceptron, penalty=l1;, score=0.661 total time=  20.6s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=squared_loss, penalty=l2;, score=0.160 total time=  19.1s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=squared_loss, penalty=elasticnet;, score=0.187 total time=  18.2s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=huber, penalty=l2;, score=0.126 total time=   9.5s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=huber, penalty=l2;, score=0.425 total time=  10.0s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=huber, penalty=l1;, score=0.661 total time=  14.9s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=hinge, penalty=l2;, score=0.661 total time=   8.0s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=hinge, penalty=l2;, score=0.661 total time=   8.0s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=hinge, penalty=elasticnet;, score=0.661 total time=  12.9s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=log, penalty=l2;, score=0.661 total time=  10.8s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=log, penalty=l1;, score=0.661 total time=  15.7s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=modified_huber, penalty=l2;, score=0.661 total time=  18.9s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=modified_huber, penalty=elasticnet;, score=0.661 total time=  19.8s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=squared_hinge, penalty=l1;, score=0.539 total time=30.8min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=hinge, penalty=elasticnet;, score=0.655 total time=  48.2s
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=squared_hinge, penalty=l2;, score=0.674 total time=   5.9s
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=squared_hinge, penalty=l2;, score=0.647 total time=   8.0s
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=squared_hinge, penalty=l2;, score=0.654 total time=   6.6s
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=squared_hinge, penalty=elasticnet;, score=0.545 total time=  38.7s
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=squared_loss, penalty=elasticnet;, score=0.236 total time=  26.6s
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=hinge, penalty=l2;, score=0.617 total time=  17.4s
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=log, penalty=l2;, score=0.608 total time=  27.1s
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=log, penalty=elasticnet;, score=0.598 total time= 1.4min
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=squared_hinge, penalty=elasticnet;, score=0.596 total time= 1.8min
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=squared_loss, penalty=elasticnet;, score=0.589 total time= 6.8min
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=perceptron, penalty=elasticnet;, score=0.600 total time= 1.4min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=hinge, penalty=l2;, score=0.592 total time=  40.1s
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=hinge, penalty=elasticnet;, score=0.605 total time= 4.6min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_hinge, penalty=l2;, score=0.579 total time= 6.1min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_loss, penalty=l1;, score=0.308 total time=20.0min
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=squared_hinge, penalty=elasticnet;, score=0.661 total time=  20.5s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=perceptron, penalty=l1;, score=0.661 total time=  12.2s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=squared_loss, penalty=l2;, score=0.660 total time=  12.4s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=squared_loss, penalty=elasticnet;, score=0.661 total time=  16.3s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=squared_loss, penalty=elasticnet;, score=0.661 total time=  16.3s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=huber, penalty=l1;, score=0.661 total time=  14.4s
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=hinge, penalty=l2;, score=0.660 total time=  45.5s
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=hinge, penalty=elasticnet;, score=0.661 total time=  58.2s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=log, penalty=l2;, score=0.660 total time=  31.2s
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=log, penalty=l1;, score=0.661 total time=  42.0s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=log, penalty=elasticnet;, score=0.661 total time=  47.0s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=modified_huber, penalty=l1;, score=0.488 total time= 2.2min
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=squared_hinge, penalty=l1;, score=0.553 total time= 2.5min
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=perceptron, penalty=l2;, score=0.661 total time=  32.0s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=perceptron, penalty=elasticnet;, score=0.661 total time= 1.2min
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=squared_loss, penalty=l1;, score=0.253 total time=  26.7s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=huber, penalty=l2;, score=0.661 total time=  11.6s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=huber, penalty=l1;, score=0.661 total time=  17.1s
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=hinge, penalty=l2;, score=0.661 total time= 1.2min
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=hinge, penalty=elasticnet;, score=0.661 total time= 2.5min
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=modified_huber, penalty=l2;, score=0.661 total time= 1.7min
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=modified_huber, penalty=l2;, score=0.660 total time= 1.8min
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=squared_hinge, penalty=l2;, score=0.661 total time= 1.7min
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=squared_hinge, penalty=elasticnet;, score=0.661 total time= 3.2min
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=perceptron, penalty=elasticnet;, score=0.579 total time= 2.3min
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=huber, penalty=l2;, score=0.661 total time= 1.6min
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=huber, penalty=l1;, score=0.661 total time= 2.5min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=hinge, penalty=l2;, score=0.322 total time=  12.0s
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=log, penalty=elasticnet;, score=0.625 total time= 1.1min
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=perceptron, penalty=l2;, score=0.638 total time=   7.6s
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=perceptron, penalty=l2;, score=0.618 total time=   8.3s
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=perceptron, penalty=elasticnet;, score=0.626 total time=  28.0s
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=huber, penalty=l2;, score=0.382 total time=   9.1s
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=huber, penalty=elasticnet;, score=0.219 total time=  26.9s
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=log, penalty=l2;, score=0.610 total time=  27.0s
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=log, penalty=elasticnet;, score=0.626 total time= 1.3min
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=squared_hinge, penalty=l1;, score=0.575 total time= 2.5min
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=huber, penalty=l1;, score=0.643 total time= 1.2min
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=log, penalty=l2;, score=0.623 total time=  34.0s
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=log, penalty=l1;, score=0.603 total time= 2.3min
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_hinge, penalty=l1;, score=0.556 total time= 2.6min
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_loss, penalty=l1;, score=0.342 total time=  25.4s
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=huber, penalty=l1;, score=0.644 total time= 1.2min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=log, penalty=l2;, score=0.614 total time= 1.8min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=modified_huber, penalty=l2;, score=0.590 total time=  48.2s
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=modified_huber, penalty=l1;, score=0.594 total time= 6.3min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=perceptron, penalty=elasticnet;, score=0.576 total time= 4.6min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=huber, penalty=l2;, score=0.607 total time= 2.0min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=huber, penalty=l1;, score=0.660 total time= 3.9min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=huber, penalty=elasticnet;, score=0.639 total time= 5.3min
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=log, penalty=l1;, score=0.661 total time=  26.1s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=modified_huber, penalty=l2;, score=0.127 total time=   7.5s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=modified_huber, penalty=l2;, score=0.661 total time=  10.8s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=modified_huber, penalty=elasticnet;, score=0.661 total time=  18.1s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=squared_hinge, penalty=l2;, score=0.661 total time=   6.8s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=squared_hinge, penalty=l2;, score=0.661 total time=   9.4s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=squared_hinge, penalty=elasticnet;, score=0.661 total time=  14.7s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=squared_hinge, penalty=elasticnet;, score=0.213 total time=  15.6s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=squared_hinge, penalty=elasticnet;, score=0.661 total time=  14.2s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=perceptron, penalty=l2;, score=0.661 total time=  11.8s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=perceptron, penalty=l1;, score=0.661 total time=  17.1s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=perceptron, penalty=elasticnet;, score=0.661 total time=  15.1s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=squared_loss, penalty=l1;, score=0.454 total time=  24.1s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=squared_loss, penalty=elasticnet;, score=0.126 total time=  24.7s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=huber, penalty=l1;, score=0.661 total time=  17.0s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=huber, penalty=elasticnet;, score=0.661 total time=  16.1s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=hinge, penalty=l1;, score=0.661 total time=  13.0s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=log, penalty=l2;, score=0.661 total time=  10.8s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=log, penalty=l1;, score=0.661 total time=  16.3s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=log, penalty=elasticnet;, score=0.661 total time=  16.4s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=modified_huber, penalty=l1;, score=0.661 total time=  23.3s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=squared_hinge, penalty=l2;, score=0.660 total time=  14.2s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=perceptron, penalty=l2;, score=0.606 total time=   4.9s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=perceptron, penalty=l2;, score=0.576 total time=   4.9s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=perceptron, penalty=l2;, score=0.604 total time=   4.9s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=perceptron, penalty=l1;, score=0.661 total time=  12.2s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=squared_loss, penalty=l2;, score=0.661 total time=  12.3s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=squared_loss, penalty=l1;, score=0.661 total time= 3.2min
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=log, penalty=l1;, score=0.661 total time=  59.4s
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=modified_huber, penalty=l2;, score=0.654 total time=  52.2s
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=modified_huber, penalty=elasticnet;, score=0.213 total time= 1.6min
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=squared_hinge, penalty=l1;, score=0.554 total time= 4.4min
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=squared_loss, penalty=elasticnet;, score=0.661 total time= 1.7min
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=hinge, penalty=elasticnet;, score=0.661 total time= 2.3min
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=log, penalty=elasticnet;, score=0.661 total time= 2.9min
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=modified_huber, penalty=elasticnet;, score=0.661 total time= 3.1min
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=perceptron, penalty=l2;, score=0.577 total time=  49.3s
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=perceptron, penalty=l1;, score=0.661 total time= 2.1min
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=perceptron, penalty=elasticnet;, score=0.661 total time= 2.3min
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=huber, penalty=l2;, score=0.661 total time= 1.6min
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=huber, penalty=elasticnet;, score=0.661 total time= 2.5min
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=log, penalty=l1;, score=0.628 total time= 1.7min
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=squared_loss, penalty=l2;, score=0.279 total time=   9.4s
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=huber, penalty=l2;, score=0.287 total time=   9.1s
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=huber, penalty=l2;, score=0.487 total time=   9.4s
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=huber, penalty=elasticnet;, score=0.202 total time=  26.9s
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=log, penalty=l1;, score=0.583 total time= 1.9min
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=perceptron, penalty=l2;, score=0.627 total time=  12.8s
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=perceptron, penalty=elasticnet;, score=0.588 total time= 1.5min
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=squared_loss, penalty=elasticnet;, score=0.348 total time= 1.6min
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=hinge, penalty=l1;, score=0.563 total time= 2.3min
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=modified_huber, penalty=l1;, score=0.569 total time= 2.7min
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=perceptron, penalty=elasticnet;, score=0.574 total time= 1.7min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=hinge, penalty=l1;, score=0.589 total time= 5.1min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_hinge, penalty=l1;, score=0.591 total time=18.5min
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=hinge, penalty=l2;, score=0.660 total time=   6.6s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=hinge, penalty=l2;, score=0.661 total time=  10.5s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=hinge, penalty=l2;, score=0.661 total time=  11.8s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=hinge, penalty=l1;, score=0.661 total time=  16.8s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=hinge, penalty=l1;, score=0.661 total time=  13.6s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=hinge, penalty=l1;, score=0.661 total time=  16.0s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=hinge, penalty=elasticnet;, score=0.661 total time=  17.7s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=log, penalty=l2;, score=0.126 total time=  12.2s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=log, penalty=l1;, score=0.213 total time=  26.1s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=log, penalty=elasticnet;, score=0.661 total time=  19.0s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=modified_huber, penalty=l1;, score=0.213 total time=  16.5s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=modified_huber, penalty=elasticnet;, score=0.661 total time=  18.3s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=squared_hinge, penalty=l1;, score=0.622 total time= 1.2min
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=perceptron, penalty=elasticnet;, score=0.661 total time=  20.0s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=squared_loss, penalty=l2;, score=0.143 total time=  10.9s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=squared_loss, penalty=l1;, score=0.227 total time=  23.9s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=squared_loss, penalty=elasticnet;, score=0.661 total time=  23.4s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=huber, penalty=elasticnet;, score=0.661 total time=  16.9s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=hinge, penalty=l2;, score=0.661 total time=   8.3s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=hinge, penalty=l1;, score=0.661 total time=  13.0s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=hinge, penalty=elasticnet;, score=0.661 total time=  13.0s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=log, penalty=l1;, score=0.661 total time=  16.4s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=modified_huber, penalty=l2;, score=0.661 total time=  15.3s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=modified_huber, penalty=l1;, score=0.661 total time=  19.2s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=squared_hinge, penalty=l2;, score=0.660 total time=  13.7s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=squared_hinge, penalty=elasticnet;, score=0.661 total time=  28.1s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=perceptron, penalty=elasticnet;, score=0.410 total time=  12.2s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=squared_loss, penalty=l2;, score=0.660 total time=  12.4s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=squared_loss, penalty=elasticnet;, score=0.661 total time=  16.3s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=huber, penalty=l2;, score=0.661 total time=   9.2s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=huber, penalty=elasticnet;, score=0.661 total time=  14.4s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=hinge, penalty=l2;, score=0.661 total time=  34.7s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=hinge, penalty=l1;, score=0.661 total time= 1.1min
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=hinge, penalty=elasticnet;, score=0.661 total time= 1.3min
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=log, penalty=elasticnet;, score=0.661 total time=  47.7s
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=modified_huber, penalty=l1;, score=0.661 total time= 2.2min
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=squared_hinge, penalty=l1;, score=0.579 total time= 1.8min
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=perceptron, penalty=l2;, score=0.216 total time=  29.9s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=perceptron, penalty=l2;, score=0.213 total time=  32.9s
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=perceptron, penalty=elasticnet;, score=0.661 total time=  58.1s
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=squared_loss, penalty=l1;, score=0.364 total time=  25.4s
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=squared_loss, penalty=l1;, score=0.263 total time=  25.4s
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=huber, penalty=l2;, score=0.661 total time=  10.4s
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=huber, penalty=elasticnet;, score=0.661 total time=  16.6s
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=hinge, penalty=l2;, score=0.661 total time= 1.0min
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=hinge, penalty=elasticnet;, score=0.661 total time= 2.1min
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=log, penalty=l1;, score=0.661 total time= 2.8min
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=modified_huber, penalty=l1;, score=0.661 total time= 2.7min
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=squared_hinge, penalty=l1;, score=0.592 total time= 8.3min
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=huber, penalty=elasticnet;, score=0.661 total time= 1.5min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=hinge, penalty=l2;, score=0.525 total time=  11.9s
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=log, penalty=elasticnet;, score=0.592 total time= 1.4min
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=perceptron, penalty=elasticnet;, score=0.593 total time=  42.1s
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=hinge, penalty=l1;, score=0.576 total time= 1.7min
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=modified_huber, penalty=elasticnet;, score=0.601 total time= 1.8min
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=squared_loss, penalty=l2;, score=0.458 total time=  54.6s
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=huber, penalty=l2;, score=0.613 total time=  59.6s
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=hinge, penalty=l2;, score=0.603 total time=  14.9s
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=hinge, penalty=elasticnet;, score=0.567 total time= 1.8min
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=modified_huber, penalty=l2;, score=0.569 total time=  18.3s
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=modified_huber, penalty=l1;, score=0.558 total time= 3.3min
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_loss, penalty=l2;, score=0.508 total time= 1.3min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=hinge, penalty=elasticnet;, score=0.600 total time= 4.8min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_hinge, penalty=l2;, score=0.563 total time= 6.1min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_loss, penalty=l2;, score=0.335 total time=20.4min
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=perceptron, penalty=l1;, score=0.126 total time=  12.2s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=perceptron, penalty=elasticnet;, score=0.652 total time=  12.2s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=squared_loss, penalty=l1;, score=0.656 total time=  27.5s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=huber, penalty=l2;, score=0.661 total time=   9.2s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=huber, penalty=l1;, score=0.661 total time=  14.4s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=huber, penalty=elasticnet;, score=0.661 total time=  14.4s
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=hinge, penalty=l1;, score=0.661 total time= 1.2min
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=hinge, penalty=elasticnet;, score=0.661 total time= 1.3min
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=log, penalty=elasticnet;, score=0.661 total time=  49.1s
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=modified_huber, penalty=l1;, score=0.661 total time= 2.1min
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=squared_hinge, penalty=l2;, score=0.648 total time=  53.6s
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=squared_hinge, penalty=elasticnet;, score=0.661 total time= 2.1min
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=perceptron, penalty=l1;, score=0.213 total time= 1.1min
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=squared_loss, penalty=l2;, score=0.660 total time=  42.2s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=squared_loss, penalty=elasticnet;, score=0.661 total time= 1.4min
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=hinge, penalty=l1;, score=0.661 total time= 2.3min
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=log, penalty=l1;, score=0.661 total time= 3.0min
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=modified_huber, penalty=elasticnet;, score=0.661 total time= 3.2min
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=squared_hinge, penalty=elasticnet;, score=0.661 total time= 3.2min
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=squared_loss, penalty=l2;, score=0.660 total time= 2.2min
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=huber, penalty=l1;, score=0.661 total time= 2.5min
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=huber, penalty=elasticnet;, score=0.661 total time= 2.1min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=hinge, penalty=l1;, score=0.527 total time= 1.5min
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=perceptron, penalty=l1;, score=0.619 total time= 1.4min
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=log, penalty=elasticnet;, score=0.598 total time= 1.3min
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=squared_hinge, penalty=l2;, score=0.598 total time=  13.0s
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=squared_hinge, penalty=elasticnet;, score=0.614 total time= 1.7min
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=squared_loss, penalty=l1;, score=0.276 total time=13.2min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=modified_huber, penalty=elasticnet;, score=0.588 total time= 5.6min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=perceptron, penalty=elasticnet;, score=0.601 total time= 4.8min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=huber, penalty=l2;, score=0.618 total time= 1.8min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=huber, penalty=l1;, score=0.655 total time= 3.7min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=huber, penalty=elasticnet;, score=0.639 total time= 4.5min
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=hinge, penalty=elasticnet;, score=0.661 total time=  15.4s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=log, penalty=l2;, score=0.213 total time=  12.1s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=log, penalty=l1;, score=0.661 total time=  16.0s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=log, penalty=elasticnet;, score=0.661 total time=  21.3s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=modified_huber, penalty=l2;, score=0.661 total time=   6.9s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=modified_huber, penalty=l1;, score=0.661 total time=  20.9s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=squared_hinge, penalty=l2;, score=0.661 total time=   8.9s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=squared_hinge, penalty=l1;, score=0.593 total time=  52.6s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=perceptron, penalty=l2;, score=0.661 total time=   8.0s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=perceptron, penalty=l1;, score=0.661 total time=  17.6s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=perceptron, penalty=elasticnet;, score=0.661 total time=  17.3s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=squared_loss, penalty=l2;, score=0.220 total time=  11.3s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=squared_loss, penalty=l1;, score=0.206 total time=  22.9s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=huber, penalty=l2;, score=0.215 total time=  11.6s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=huber, penalty=l1;, score=0.661 total time=  15.3s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=huber, penalty=elasticnet;, score=0.126 total time=  18.6s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=hinge, penalty=l1;, score=0.661 total time=  12.3s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=hinge, penalty=elasticnet;, score=0.661 total time=  12.2s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=log, penalty=l2;, score=0.661 total time=  10.3s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=log, penalty=elasticnet;, score=0.661 total time=  17.7s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=modified_huber, penalty=l1;, score=0.661 total time=  17.1s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=squared_hinge, penalty=l2;, score=0.663 total time=  17.9s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=squared_hinge, penalty=elasticnet;, score=0.661 total time=  34.2s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=perceptron, penalty=elasticnet;, score=0.661 total time=  11.5s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=squared_loss, penalty=l1;, score=0.660 total time=  27.0s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=huber, penalty=l2;, score=0.661 total time=   8.4s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=huber, penalty=l1;, score=0.661 total time=  13.1s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=huber, penalty=elasticnet;, score=0.661 total time=  13.1s
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=hinge, penalty=l2;, score=0.661 total time=  32.3s
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=hinge, penalty=l1;, score=0.661 total time=  59.7s
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=log, penalty=l2;, score=0.660 total time=  20.6s
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=log, penalty=l2;, score=0.659 total time=  27.1s
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=log, penalty=l1;, score=0.661 total time=  42.3s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=modified_huber, penalty=l2;, score=0.296 total time=  47.2s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=modified_huber, penalty=elasticnet;, score=0.661 total time= 1.4min
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=squared_hinge, penalty=l2;, score=0.223 total time=  53.4s
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=squared_hinge, penalty=elasticnet;, score=0.657 total time= 2.2min
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=perceptron, penalty=l1;, score=0.126 total time= 1.0min
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=perceptron, penalty=elasticnet;, score=0.629 total time= 1.3min
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=huber, penalty=l1;, score=0.661 total time=  15.7s
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=huber, penalty=elasticnet;, score=0.661 total time=  15.7s
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=hinge, penalty=l1;, score=0.661 total time= 2.2min
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=log, penalty=l2;, score=0.661 total time= 1.7min
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=modified_huber, penalty=l2;, score=0.661 total time= 1.4min
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=modified_huber, penalty=l1;, score=0.661 total time= 2.9min
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=squared_hinge, penalty=l1;, score=0.580 total time=16.4min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=log, penalty=l2;, score=0.599 total time=  18.5s
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=modified_huber, penalty=l2;, score=0.522 total time=   9.0s
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=modified_huber, penalty=elasticnet;, score=0.643 total time=  41.1s
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=squared_hinge, penalty=elasticnet;, score=0.611 total time=  33.8s
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=squared_loss, penalty=l2;, score=0.437 total time=   9.2s
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=squared_loss, penalty=elasticnet;, score=0.150 total time=  26.2s
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=hinge, penalty=l1;, score=0.587 total time= 1.5min
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=modified_huber, penalty=elasticnet;, score=0.597 total time= 2.0min
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=squared_loss, penalty=l2;, score=0.343 total time= 2.0min
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=hinge, penalty=l1;, score=0.594 total time= 2.3min
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=modified_huber, penalty=l1;, score=0.563 total time= 3.5min
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_loss, penalty=elasticnet;, score=0.472 total time=  26.2s
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=huber, penalty=elasticnet;, score=0.625 total time= 1.6min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=log, penalty=l1;, score=0.596 total time= 6.3min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_hinge, penalty=elasticnet;, score=0.584 total time=38.0min
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=log, penalty=l2;, score=0.661 total time= 1.7min
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=log, penalty=elasticnet;, score=0.661 total time= 2.8min
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=squared_hinge, penalty=l2;, score=0.661 total time= 1.5min
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=squared_hinge, penalty=l2;, score=0.660 total time= 1.5min
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=perceptron, penalty=l2;, score=0.575 total time=  50.1s
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=perceptron, penalty=l2;, score=0.596 total time=  49.8s
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=perceptron, penalty=l1;, score=0.213 total time= 2.0min
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=squared_loss, penalty=l1;, score=0.346 total time=15.9min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=log, penalty=l2;, score=0.625 total time=  20.6s
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=modified_huber, penalty=l1;, score=0.601 total time= 1.5min
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=squared_loss, penalty=elasticnet;, score=0.470 total time=  26.5s
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=hinge, penalty=l1;, score=0.594 total time= 2.0min
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=squared_hinge, penalty=l1;, score=0.579 total time= 2.9min
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=huber, penalty=elasticnet;, score=0.614 total time= 2.1min
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=log, penalty=elasticnet;, score=0.620 total time= 2.1min
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=perceptron, penalty=l2;, score=0.580 total time=  14.2s
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=perceptron, penalty=l1;, score=0.570 total time= 1.6min
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_loss, penalty=l2;, score=0.243 total time=  57.6s
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=huber, penalty=elasticnet;, score=0.630 total time= 1.6min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=log, penalty=elasticnet;, score=0.631 total time= 5.9min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_hinge, penalty=elasticnet;, score=0.574 total time=50.3min
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=squared_loss, penalty=l1;, score=0.339 total time=15.0min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=log, penalty=l2;, score=0.649 total time=  18.1s
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=modified_huber, penalty=l2;, score=0.641 total time=   9.2s
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=modified_huber, penalty=l1;, score=0.636 total time= 1.3min
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=squared_loss, penalty=l1;, score=0.307 total time=  23.8s
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=huber, penalty=l1;, score=0.623 total time= 1.6min
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=modified_huber, penalty=l1;, score=0.597 total time= 2.0min
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=perceptron, penalty=elasticnet;, score=0.610 total time= 1.5min
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=huber, penalty=elasticnet;, score=0.623 total time= 1.9min
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=log, penalty=elasticnet;, score=0.608 total time= 2.0min
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_hinge, penalty=elasticnet;, score=0.568 total time= 2.4min
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_loss, penalty=l1;, score=0.408 total time=  25.6s
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=huber, penalty=l2;, score=0.621 total time=  32.4s
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=hinge, penalty=l1;, score=0.578 total time= 4.6min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=modified_huber, penalty=elasticnet;, score=0.581 total time= 5.0min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=perceptron, penalty=l1;, score=0.589 total time= 4.2min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_loss, penalty=elasticnet;, score=0.337 total time=61.5min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=log, penalty=elasticnet;, score=0.658 total time= 1.1min
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=squared_hinge, penalty=l1;, score=0.608 total time=  56.1s
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=huber, penalty=l1;, score=0.629 total time= 1.3min
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=modified_huber, penalty=l2;, score=0.623 total time=  18.1s
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=modified_huber, penalty=l1;, score=0.572 total time= 2.5min
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=squared_loss, penalty=l1;, score=0.242 total time= 1.8min
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=hinge, penalty=elasticnet;, score=0.580 total time= 2.4min
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_hinge, penalty=l2;, score=0.550 total time=  16.3s
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_hinge, penalty=l2;, score=0.560 total time=  19.5s
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_hinge, penalty=l1;, score=0.574 total time= 2.7min
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_loss, penalty=elasticnet;, score=0.278 total time= 3.0min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=log, penalty=elasticnet;, score=0.619 total time= 5.4min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=perceptron, penalty=l2;, score=0.577 total time=  38.5s
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=perceptron, penalty=l2;, score=0.582 total time=  39.5s
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=perceptron, penalty=l2;, score=0.601 total time=  41.2s
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=perceptron, penalty=l1;, score=0.572 total time= 4.4min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_loss, penalty=elasticnet;, score=0.327 total time=61.6min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=hinge, penalty=l1;, score=0.578 total time= 1.1min
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=squared_hinge, penalty=l1;, score=0.578 total time= 1.1min
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=hinge, penalty=l2;, score=0.620 total time=  13.7s
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=hinge, penalty=elasticnet;, score=0.605 total time= 1.7min
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=squared_hinge, penalty=l2;, score=0.601 total time=  16.8s
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=squared_hinge, penalty=l1;, score=0.578 total time= 3.4min
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=hinge, penalty=l1;, score=0.594 total time= 2.4min
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=modified_huber, penalty=elasticnet;, score=0.554 total time= 3.3min
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_loss, penalty=l2;, score=0.330 total time=  34.2s
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=huber, penalty=l1;, score=0.645 total time= 1.1min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=log, penalty=l2;, score=0.611 total time= 1.9min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=modified_huber, penalty=l2;, score=0.579 total time=  45.7s
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=modified_huber, penalty=l1;, score=0.597 total time= 6.0min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=perceptron, penalty=l1;, score=0.591 total time= 4.5min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_loss, penalty=elasticnet;, score=0.332 total time=62.2min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
saving: SGD_description_1637280987 as png
Fitting 3 folds for each of 24 candidates, totalling 72 fits
[CV 1/3] END activation=tanh, alpha=0.0001, learning_rate=adaptive, solver=lbfgs;, score=0.591 total time= 9.4min
[CV 2/3] END activation=tanh, alpha=0.0001, learning_rate=adaptive, solver=lbfgs;, score=0.594 total time=10.6min
[CV 1/3] END activation=tanh, alpha=0.05, learning_rate=adaptive, solver=adam;, score=0.605 total time= 7.3min
[CV 3/3] END activation=tanh, alpha=0.05, learning_rate=adaptive, solver=adam;, score=0.616 total time= 7.3min
[CV 3/3] END activation=tanh, alpha=0.05, learning_rate=adaptive, solver=lbfgs;, score=0.589 total time=18.9min
[CV 1/3] END activation=relu, alpha=0.0001, learning_rate=constant, solver=adam;, score=0.596 total time=12.7min
[CV 2/3] END activation=relu, alpha=0.0001, learning_rate=constant, solver=adam;, score=0.580 total time=10.2min
[CV 1/3] END activation=relu, alpha=0.0001, learning_rate=adaptive, solver=adam;, score=0.601 total time=11.8min
[CV 1/3] END activation=relu, alpha=0.05, learning_rate=constant, solver=adam;, score=0.607 total time=10.1min
[CV 3/3] END activation=relu, alpha=0.05, learning_rate=constant, solver=lbfgs;, score=0.585 total time=21.8min
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=hinge, penalty=l2;, score=0.283 total time=  14.2s
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=modified_huber, penalty=l2;, score=0.659 total time=  10.7s
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=modified_huber, penalty=l1;, score=0.617 total time= 1.2min
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=squared_loss, penalty=l2;, score=0.265 total time=   9.1s
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=squared_loss, penalty=l1;, score=0.432 total time=  24.1s
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=hinge, penalty=l2;, score=0.608 total time=  18.2s
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=hinge, penalty=elasticnet;, score=0.605 total time= 1.6min
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=squared_hinge, penalty=l2;, score=0.611 total time=  18.9s
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=perceptron, penalty=l2;, score=0.585 total time=  14.2s
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=perceptron, penalty=l1;, score=0.604 total time= 1.5min
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=squared_loss, penalty=elasticnet;, score=0.250 total time= 5.1min
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_hinge, penalty=elasticnet;, score=0.563 total time= 2.6min
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=huber, penalty=l2;, score=0.615 total time=  36.8s
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=hinge, penalty=l1;, score=0.585 total time= 4.7min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=modified_huber, penalty=elasticnet;, score=0.573 total time= 5.7min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_loss, penalty=l2;, score=0.319 total time=20.4min
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=modified_huber, penalty=elasticnet;, score=0.661 total time=  18.4s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=squared_hinge, penalty=l1;, score=0.511 total time=24.5min
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=perceptron, penalty=elasticnet;, score=0.661 total time= 2.0min
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=squared_loss, penalty=l1;, score=0.295 total time=25.6min
[CV 1/3] END activation=tanh, alpha=0.0001, learning_rate=constant, solver=sgd;, score=0.651 total time=69.3min
[CV 1/3] END activation=relu, alpha=0.0001, learning_rate=constant, solver=lbfgs;, score=0.608 total time=13.0min
[CV 2/3] END activation=relu, alpha=0.0001, learning_rate=adaptive, solver=lbfgs;, score=0.580 total time=11.4min
[CV 1/3] END activation=relu, alpha=0.05, learning_rate=constant, solver=lbfgs;, score=0.581 total time=21.1min
[CV 3/3] END activation=relu, alpha=0.05, learning_rate=adaptive, solver=adam;, score=0.619 total time= 5.5min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
[CV 3/3] END activation=tanh, alpha=0.0001, learning_rate=adaptive, solver=adam;, score=0.586 total time=13.5min
[CV 2/3] END activation=tanh, alpha=0.05, learning_rate=constant, solver=lbfgs;, score=0.564 total time=17.7min
[CV 1/3] END activation=tanh, alpha=0.05, learning_rate=adaptive, solver=lbfgs;, score=0.574 total time=14.5min
[CV 2/3] END activation=relu, alpha=0.0001, learning_rate=constant, solver=sgd;, score=0.659 total time=68.9min
[CV 2/3] END activation=relu, alpha=0.05, learning_rate=adaptive, solver=adam;, score=0.610 total time= 6.4min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
[CV 2/3] END activation=tanh, alpha=0.0001, learning_rate=adaptive, solver=adam;, score=0.589 total time= 9.7min
[CV 1/3] END activation=tanh, alpha=0.05, learning_rate=constant, solver=sgd;, score=0.652 total time=70.5min
[CV 3/3] END activation=relu, alpha=0.0001, learning_rate=adaptive, solver=adam;, score=0.585 total time=12.5min
[CV 3/3] END activation=relu, alpha=0.05, learning_rate=constant, solver=adam;, score=0.616 total time= 5.5min
[CV 2/3] END activation=relu, alpha=0.05, learning_rate=constant, solver=lbfgs;, score=0.569 total time=28.5min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
[CV 3/3] END activation=tanh, alpha=0.0001, learning_rate=constant, solver=adam;, score=0.596 total time=11.5min
[CV 1/3] END activation=tanh, alpha=0.05, learning_rate=constant, solver=adam;, score=0.606 total time= 5.7min
[CV 3/3] END activation=tanh, alpha=0.05, learning_rate=constant, solver=lbfgs;, score=0.592 total time=15.2min
[CV 2/3] END activation=tanh, alpha=0.05, learning_rate=adaptive, solver=lbfgs;, score=0.569 total time=14.3min
[CV 3/3] END activation=relu, alpha=0.0001, learning_rate=constant, solver=sgd;, score=0.664 total time=69.0min
[CV 1/3] END activation=relu, alpha=0.05, learning_rate=adaptive, solver=lbfgs;, score=0.576 total time=13.5min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
[CV 2/3] END activation=tanh, alpha=0.0001, learning_rate=constant, solver=lbfgs;, score=0.586 total time=10.8min
[CV 3/3] END activation=tanh, alpha=0.05, learning_rate=constant, solver=sgd;, score=0.660 total time=65.2min
[CV 3/3] END activation=relu, alpha=0.0001, learning_rate=adaptive, solver=sgd;, score=0.662 total time=57.4min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
[CV 2/3] END activation=tanh, alpha=0.0001, learning_rate=constant, solver=adam;, score=0.585 total time=10.8min
[CV 2/3] END activation=tanh, alpha=0.05, learning_rate=constant, solver=sgd;, score=0.659 total time=70.5min
[CV 1/3] END activation=relu, alpha=0.0001, learning_rate=adaptive, solver=lbfgs;, score=0.589 total time=30.4min
[CV 1/3] END activation=relu, alpha=0.05, learning_rate=adaptive, solver=adam;, score=0.607 total time= 8.4min
[CV 3/3] END activation=relu, alpha=0.05, learning_rate=adaptive, solver=lbfgs;, score=0.594 total time=14.3min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
[CV 3/3] END activation=tanh, alpha=0.0001, learning_rate=adaptive, solver=sgd;, score=0.663 total time=70.2min
[CV 2/3] END activation=relu, alpha=0.0001, learning_rate=adaptive, solver=sgd;, score=0.658 total time=65.0min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
[CV 2/3] END activation=tanh, alpha=0.0001, learning_rate=constant, solver=sgd;, score=0.659 total time=69.9min
[CV 1/3] END activation=relu, alpha=0.0001, learning_rate=adaptive, solver=sgd;, score=0.653 total time=67.2min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
[CV 3/3] END activation=tanh, alpha=0.0001, learning_rate=constant, solver=lbfgs;, score=0.611 total time= 9.6min
[CV 3/3] END activation=tanh, alpha=0.0001, learning_rate=adaptive, solver=lbfgs;, score=0.611 total time= 9.1min
[CV 2/3] END activation=tanh, alpha=0.05, learning_rate=adaptive, solver=sgd;, score=0.662 total time=66.2min
[CV 3/3] END activation=relu, alpha=0.0001, learning_rate=adaptive, solver=lbfgs;, score=0.606 total time=34.6min
[CV 2/3] END activation=relu, alpha=0.05, learning_rate=adaptive, solver=lbfgs;, score=0.568 total time=18.1min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
[CV 1/3] END activation=tanh, alpha=0.0001, learning_rate=adaptive, solver=adam;, score=0.603 total time=11.6min
[CV 2/3] END activation=tanh, alpha=0.05, learning_rate=constant, solver=adam;, score=0.592 total time= 7.2min
[CV 3/3] END activation=tanh, alpha=0.05, learning_rate=adaptive, solver=sgd;, score=0.664 total time=69.3min
[CV 3/3] END activation=relu, alpha=0.05, learning_rate=constant, solver=sgd;, score=0.663 total time=52.9min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
[CV 3/3] END activation=tanh, alpha=0.0001, learning_rate=constant, solver=sgd;, score=0.660 total time=69.3min
[CV 2/3] END activation=relu, alpha=0.0001, learning_rate=constant, solver=lbfgs;, score=0.589 total time=17.8min
[CV 1/3] END activation=relu, alpha=0.05, learning_rate=constant, solver=sgd;, score=0.657 total time=55.4min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
[CV 1/3] END activation=tanh, alpha=0.0001, learning_rate=constant, solver=lbfgs;, score=0.595 total time=11.6min
[CV 3/3] END activation=tanh, alpha=0.05, learning_rate=constant, solver=adam;, score=0.608 total time= 6.8min
[CV 1/3] END activation=tanh, alpha=0.05, learning_rate=adaptive, solver=sgd;, score=0.650 total time=69.6min
[CV 2/3] END activation=relu, alpha=0.05, learning_rate=constant, solver=sgd;, score=0.658 total time=55.7min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
[CV 1/3] END activation=tanh, alpha=0.0001, learning_rate=adaptive, solver=sgd;, score=0.654 total time=68.3min
[CV 3/3] END activation=relu, alpha=0.0001, learning_rate=constant, solver=adam;, score=0.598 total time=10.6min
[CV 2/3] END activation=relu, alpha=0.0001, learning_rate=adaptive, solver=adam;, score=0.580 total time=11.6min
[CV 2/3] END activation=relu, alpha=0.05, learning_rate=constant, solver=adam;, score=0.592 total time= 8.9min
[CV 1/3] END activation=relu, alpha=0.05, learning_rate=adaptive, solver=sgd;, score=0.657 total time=49.5min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
[CV 1/3] END activation=tanh, alpha=0.0001, learning_rate=constant, solver=adam;, score=0.600 total time=12.2min
[CV 1/3] END activation=tanh, alpha=0.05, learning_rate=constant, solver=lbfgs;, score=0.581 total time=13.3min
[CV 2/3] END activation=tanh, alpha=0.05, learning_rate=adaptive, solver=adam;, score=0.609 total time= 9.2min
[CV 1/3] END activation=relu, alpha=0.0001, learning_rate=constant, solver=sgd;, score=0.656 total time=68.9min
[CV 2/3] END activation=relu, alpha=0.05, learning_rate=adaptive, solver=sgd;, score=0.666 total time=49.1min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
[CV 2/3] END activation=tanh, alpha=0.0001, learning_rate=adaptive, solver=sgd;, score=0.656 total time=69.5min
[CV 3/3] END activation=relu, alpha=0.0001, learning_rate=constant, solver=lbfgs;, score=0.592 total time=39.0min
[CV 3/3] END activation=relu, alpha=0.05, learning_rate=adaptive, solver=sgd;, score=0.664 total time=45.7min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
saving: MLP_description_1637292767 as png
saving all
Saving to: description_k-Nearest Neighbour_model_container_454803.54637480516
Saving to: description_Guassian Naive Bayes_model_container_454803.5465503672
Saving to: description_Multinominal Naive Bayes_model_container_454803.54655772285
Saving to: description_Decision Tree_model_container_454803.54656500445
Saving to: description_Support Vector Machine (classifier)_model_container_454803.5465721556
Saving to: description_Stochastic Gradient Descent_model_container_454803.5467176034
Saving to: description_Multi-layer Perceptron_model_container_454803.5467249914
saving: description_comparison_1637292768 as png
Fitting 3 folds for each of 160 candidates, totalling 480 fits
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
[CV 1/3] END algorithm=auto, n_neighbors=1, weights=uniform;, score=0.503 total time=  35.4s
[CV 3/3] END algorithm=auto, n_neighbors=3, weights=distance;, score=0.654 total time=  35.4s
[CV 2/3] END algorithm=auto, n_neighbors=7, weights=uniform;, score=0.661 total time=  35.4s
[CV 2/3] END algorithm=auto, n_neighbors=10, weights=uniform;, score=0.660 total time=  35.1s
[CV 2/3] END algorithm=auto, n_neighbors=12, weights=distance;, score=0.666 total time=  34.9s
[CV 1/3] END algorithm=auto, n_neighbors=15, weights=distance;, score=0.664 total time=  34.9s
[CV 1/3] END algorithm=auto, n_neighbors=18, weights=uniform;, score=0.661 total time=  35.1s
[CV 3/3] END algorithm=auto, n_neighbors=20, weights=distance;, score=0.665 total time=  34.6s
[CV 1/3] END algorithm=ball_tree, n_neighbors=3, weights=distance;, score=0.615 total time= 5.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=6, weights=uniform;, score=0.661 total time= 5.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=8, weights=distance;, score=0.658 total time= 5.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=11, weights=uniform;, score=0.664 total time= 5.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=13, weights=distance;, score=0.668 total time= 5.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=16, weights=distance;, score=0.664 total time= 5.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=19, weights=uniform;, score=0.665 total time= 5.5min
[CV 3/3] END algorithm=kd_tree, n_neighbors=1, weights=distance;, score=0.596 total time= 7.1min
[CV 3/3] END algorithm=kd_tree, n_neighbors=4, weights=uniform;, score=0.664 total time= 7.3min
[CV 2/3] END algorithm=kd_tree, n_neighbors=6, weights=distance;, score=0.656 total time= 7.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=9, weights=uniform;, score=0.664 total time= 7.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=11, weights=distance;, score=0.664 total time= 7.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=14, weights=uniform;, score=0.661 total time= 7.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=17, weights=uniform;, score=0.661 total time= 7.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=19, weights=distance;, score=0.668 total time= 7.4min
[CV 1/3] END algorithm=brute, n_neighbors=8, weights=distance;, score=0.658 total time=  26.7s
[CV 3/3] END algorithm=brute, n_neighbors=10, weights=distance;, score=0.667 total time=  29.6s
[CV 1/3] END algorithm=brute, n_neighbors=13, weights=distance;, score=0.663 total time=  29.7s
[CV 2/3] END algorithm=brute, n_neighbors=16, weights=uniform;, score=0.665 total time=  29.6s
[CV 3/3] END algorithm=brute, n_neighbors=18, weights=distance;, score=0.665 total time=  29.6s
[CV 1/3] END class_weight=balanced, gamma=scale, kernel=linear;, score=0.593 total time=66.1min
[CV 3/3] END class_weight=balanced, gamma=auto, kernel=linear;, score=0.642 total time=66.0min
[CV 1/3] END class_weight=None, gamma=auto, kernel=sigmoid;, score=0.661 total time=38.5min
[CV 2/3] END algorithm=auto, n_neighbors=1, weights=distance;, score=0.619 total time=  35.4s
[CV 2/3] END algorithm=auto, n_neighbors=4, weights=distance;, score=0.641 total time=  35.5s
[CV 3/3] END algorithm=auto, n_neighbors=7, weights=uniform;, score=0.666 total time=  35.1s
[CV 3/3] END algorithm=auto, n_neighbors=9, weights=uniform;, score=0.664 total time=  35.0s
[CV 2/3] END algorithm=auto, n_neighbors=12, weights=uniform;, score=0.662 total time=  34.9s
[CV 3/3] END algorithm=auto, n_neighbors=14, weights=distance;, score=0.667 total time=  34.9s
[CV 3/3] END algorithm=auto, n_neighbors=17, weights=distance;, score=0.666 total time=  35.0s
[CV 1/3] END algorithm=auto, n_neighbors=20, weights=distance;, score=0.663 total time=  34.5s
[CV 3/3] END algorithm=ball_tree, n_neighbors=3, weights=uniform;, score=0.661 total time= 5.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=5, weights=distance;, score=0.660 total time= 5.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=8, weights=uniform;, score=0.662 total time= 5.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=10, weights=distance;, score=0.667 total time= 5.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=13, weights=distance;, score=0.665 total time= 5.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=16, weights=uniform;, score=0.661 total time= 5.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=19, weights=uniform;, score=0.661 total time= 5.5min
[CV 2/3] END algorithm=kd_tree, n_neighbors=1, weights=distance;, score=0.619 total time= 7.2min
[CV 1/3] END algorithm=kd_tree, n_neighbors=4, weights=distance;, score=0.630 total time= 7.3min
[CV 1/3] END algorithm=kd_tree, n_neighbors=7, weights=uniform;, score=0.662 total time= 7.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=9, weights=distance;, score=0.664 total time= 7.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=12, weights=uniform;, score=0.661 total time= 7.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=14, weights=distance;, score=0.664 total time= 7.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=17, weights=uniform;, score=0.666 total time= 7.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=19, weights=distance;, score=0.665 total time= 7.4min
[CV 3/3] END algorithm=brute, n_neighbors=8, weights=distance;, score=0.667 total time=  29.8s
[CV 1/3] END algorithm=brute, n_neighbors=11, weights=distance;, score=0.664 total time=  29.5s
[CV 2/3] END algorithm=brute, n_neighbors=14, weights=uniform;, score=0.665 total time=  29.5s
[CV 3/3] END algorithm=brute, n_neighbors=16, weights=distance;, score=0.666 total time=  29.5s
[CV 1/3] END algorithm=brute, n_neighbors=19, weights=distance;, score=0.663 total time=  26.4s
[CV 3/3] END class_weight=balanced, gamma=scale, kernel=poly;, score=0.664 total time=77.4min
[CV 1/3] END class_weight=None, gamma=scale, kernel=linear;, score=0.604 total time=65.5min
[CV 3/3] END class_weight=None, gamma=auto, kernel=sigmoid;, score=0.661 total time=33.6min
[CV 2/3] END algorithm=auto, n_neighbors=2, weights=distance;, score=0.619 total time=  35.4s
[CV 3/3] END algorithm=auto, n_neighbors=4, weights=uniform;, score=0.664 total time=  35.6s
[CV 2/3] END algorithm=auto, n_neighbors=7, weights=distance;, score=0.662 total time=  35.3s
[CV 1/3] END algorithm=auto, n_neighbors=10, weights=distance;, score=0.663 total time=  35.3s
[CV 3/3] END algorithm=auto, n_neighbors=13, weights=uniform;, score=0.662 total time=  35.6s
[CV 2/3] END algorithm=auto, n_neighbors=16, weights=uniform;, score=0.665 total time=  35.4s
[CV 1/3] END algorithm=auto, n_neighbors=19, weights=uniform;, score=0.661 total time=  35.4s
[CV 3/3] END algorithm=ball_tree, n_neighbors=1, weights=distance;, score=0.596 total time= 5.4min
[CV 2/3] END algorithm=ball_tree, n_neighbors=4, weights=uniform;, score=0.660 total time= 5.4min
[CV 3/3] END algorithm=ball_tree, n_neighbors=6, weights=distance;, score=0.665 total time= 5.4min
[CV 1/3] END algorithm=ball_tree, n_neighbors=9, weights=distance;, score=0.661 total time= 5.4min
[CV 1/3] END algorithm=ball_tree, n_neighbors=12, weights=uniform;, score=0.659 total time= 5.4min
[CV 2/3] END algorithm=ball_tree, n_neighbors=14, weights=distance;, score=0.668 total time= 5.4min
[CV 3/3] END algorithm=ball_tree, n_neighbors=17, weights=uniform;, score=0.661 total time= 5.4min
[CV 1/3] END algorithm=ball_tree, n_neighbors=20, weights=uniform;, score=0.661 total time= 5.2min
[CV 2/3] END algorithm=kd_tree, n_neighbors=2, weights=distance;, score=0.619 total time= 7.3min
[CV 1/3] END algorithm=kd_tree, n_neighbors=5, weights=distance;, score=0.651 total time= 7.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=8, weights=uniform;, score=0.662 total time= 7.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=10, weights=distance;, score=0.667 total time= 7.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=13, weights=distance;, score=0.663 total time= 7.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=16, weights=uniform;, score=0.665 total time= 7.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=18, weights=distance;, score=0.668 total time= 7.4min
[CV 3/3] END algorithm=brute, n_neighbors=1, weights=uniform;, score=0.596 total time=  30.5s
[CV 3/3] END algorithm=brute, n_neighbors=2, weights=distance;, score=0.596 total time=  29.9s
[CV 1/3] END algorithm=brute, n_neighbors=4, weights=uniform;, score=0.649 total time=  29.9s
[CV 3/3] END algorithm=brute, n_neighbors=5, weights=uniform;, score=0.660 total time=  29.7s
[CV 2/3] END algorithm=brute, n_neighbors=6, weights=distance;, score=0.656 total time=  29.6s
[CV 1/3] END algorithm=brute, n_neighbors=8, weights=uniform;, score=0.662 total time=  29.8s
[CV 3/3] END algorithm=brute, n_neighbors=10, weights=uniform;, score=0.661 total time=  29.6s
[CV 1/3] END algorithm=brute, n_neighbors=13, weights=uniform;, score=0.662 total time=  29.6s
[CV 2/3] END algorithm=brute, n_neighbors=15, weights=distance;, score=0.668 total time=  29.5s
[CV 3/3] END algorithm=brute, n_neighbors=18, weights=uniform;, score=0.661 total time=  29.7s
[CV 1/3] END class_weight=balanced, gamma=scale, kernel=sigmoid;, score=0.547 total time=67.2min
[CV 3/3] END class_weight=balanced, gamma=auto, kernel=poly;, score=0.213 total time=74.5min
[CV 2/3] END class_weight=None, gamma=auto, kernel=sigmoid;, score=0.661 total time=38.2min
[CV 2/3] END algorithm=auto, n_neighbors=1, weights=uniform;, score=0.619 total time=  35.4s
[CV 1/3] END algorithm=auto, n_neighbors=4, weights=uniform;, score=0.649 total time=  35.4s
[CV 2/3] END algorithm=auto, n_neighbors=6, weights=distance;, score=0.656 total time=  35.3s
[CV 1/3] END algorithm=auto, n_neighbors=9, weights=distance;, score=0.661 total time=  35.0s
[CV 3/3] END algorithm=auto, n_neighbors=12, weights=uniform;, score=0.661 total time=  34.9s
[CV 1/3] END algorithm=auto, n_neighbors=15, weights=uniform;, score=0.661 total time=  34.9s
[CV 2/3] END algorithm=auto, n_neighbors=17, weights=distance;, score=0.668 total time=  34.5s
[CV 3/3] END algorithm=auto, n_neighbors=20, weights=uniform;, score=0.661 total time=  34.2s
[CV 1/3] END algorithm=ball_tree, n_neighbors=3, weights=uniform;, score=0.634 total time= 5.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=5, weights=uniform;, score=0.660 total time= 5.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=8, weights=uniform;, score=0.662 total time= 5.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=10, weights=distance;, score=0.666 total time= 5.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=13, weights=uniform;, score=0.662 total time= 5.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=16, weights=uniform;, score=0.661 total time= 5.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=18, weights=distance;, score=0.668 total time= 5.5min
[CV 3/3] END algorithm=kd_tree, n_neighbors=1, weights=uniform;, score=0.596 total time= 7.1min
[CV 1/3] END algorithm=kd_tree, n_neighbors=4, weights=uniform;, score=0.649 total time= 7.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=6, weights=distance;, score=0.665 total time= 7.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=9, weights=distance;, score=0.661 total time= 7.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=12, weights=uniform;, score=0.662 total time= 7.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=14, weights=distance;, score=0.668 total time= 7.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=17, weights=uniform;, score=0.661 total time= 7.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=20, weights=uniform;, score=0.661 total time= 7.4min
[CV 1/3] END algorithm=brute, n_neighbors=9, weights=uniform;, score=0.662 total time=  29.8s
[CV 3/3] END algorithm=brute, n_neighbors=11, weights=distance;, score=0.666 total time=  30.8s
[CV 1/3] END algorithm=brute, n_neighbors=14, weights=distance;, score=0.664 total time=  30.2s
[CV 2/3] END algorithm=brute, n_neighbors=17, weights=uniform;, score=0.666 total time=  30.1s
[CV 3/3] END algorithm=brute, n_neighbors=19, weights=distance;, score=0.665 total time=  25.3s
[CV 3/3] END class_weight=balanced, gamma=scale, kernel=rbf;, score=0.669 total time=84.1min
[CV 3/3] END class_weight=None, gamma=scale, kernel=linear;, score=0.646 total time=65.5min
[CV 1/3] END class_weight=None, gamma=auto, kernel=poly;, score=0.661 total time=32.3min
[CV 3/3] END algorithm=auto, n_neighbors=1, weights=uniform;, score=0.596 total time=  35.4s
[CV 2/3] END algorithm=auto, n_neighbors=4, weights=uniform;, score=0.660 total time=  35.5s
[CV 1/3] END algorithm=auto, n_neighbors=7, weights=distance;, score=0.663 total time=  35.3s
[CV 3/3] END algorithm=auto, n_neighbors=9, weights=distance;, score=0.668 total time=  35.3s
[CV 1/3] END algorithm=auto, n_neighbors=13, weights=uniform;, score=0.662 total time=  35.2s
[CV 2/3] END algorithm=auto, n_neighbors=15, weights=distance;, score=0.668 total time=  34.9s
[CV 3/3] END algorithm=auto, n_neighbors=18, weights=uniform;, score=0.661 total time=  34.9s
[CV 1/3] END algorithm=ball_tree, n_neighbors=1, weights=uniform;, score=0.503 total time= 5.4min
[CV 2/3] END algorithm=ball_tree, n_neighbors=3, weights=distance;, score=0.630 total time= 5.4min
[CV 3/3] END algorithm=ball_tree, n_neighbors=6, weights=uniform;, score=0.665 total time= 5.4min
[CV 1/3] END algorithm=ball_tree, n_neighbors=9, weights=uniform;, score=0.662 total time= 5.4min
[CV 2/3] END algorithm=ball_tree, n_neighbors=11, weights=distance;, score=0.664 total time= 5.4min
[CV 3/3] END algorithm=ball_tree, n_neighbors=14, weights=uniform;, score=0.661 total time= 5.4min
[CV 1/3] END algorithm=ball_tree, n_neighbors=17, weights=uniform;, score=0.661 total time= 5.4min
[CV 2/3] END algorithm=ball_tree, n_neighbors=19, weights=distance;, score=0.668 total time= 5.2min
[CV 3/3] END algorithm=kd_tree, n_neighbors=2, weights=uniform;, score=0.661 total time= 7.3min
[CV 1/3] END algorithm=kd_tree, n_neighbors=5, weights=uniform;, score=0.659 total time= 7.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=7, weights=distance;, score=0.662 total time= 7.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=10, weights=uniform;, score=0.661 total time= 7.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=13, weights=uniform;, score=0.662 total time= 7.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=15, weights=distance;, score=0.668 total time= 7.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=18, weights=distance;, score=0.663 total time= 7.4min
[CV 2/3] END algorithm=brute, n_neighbors=1, weights=uniform;, score=0.619 total time=  30.3s
[CV 2/3] END algorithm=brute, n_neighbors=2, weights=distance;, score=0.619 total time=  31.2s
[CV 2/3] END algorithm=brute, n_neighbors=4, weights=uniform;, score=0.660 total time=  30.6s
[CV 1/3] END algorithm=brute, n_neighbors=5, weights=distance;, score=0.651 total time=  30.3s
[CV 3/3] END algorithm=brute, n_neighbors=6, weights=distance;, score=0.665 total time=  30.4s
[CV 2/3] END algorithm=brute, n_neighbors=8, weights=uniform;, score=0.662 total time=  30.1s
[CV 1/3] END algorithm=brute, n_neighbors=10, weights=distance;, score=0.663 total time=  30.6s
[CV 3/3] END algorithm=brute, n_neighbors=13, weights=uniform;, score=0.662 total time=  29.9s
[CV 1/3] END algorithm=brute, n_neighbors=16, weights=uniform;, score=0.661 total time=  29.8s
[CV 2/3] END algorithm=brute, n_neighbors=18, weights=distance;, score=0.668 total time=  29.3s
[CV 3/3] END class_weight=balanced, gamma=scale, kernel=sigmoid;, score=0.616 total time=67.9min
[CV 1/3] END class_weight=balanced, gamma=auto, kernel=rbf;, score=0.213 total time=85.4min
[CV 2/3] END class_weight=None, gamma=auto, kernel=poly;, score=0.661 total time=33.8min
[CV 2/3] END algorithm=auto, n_neighbors=3, weights=uniform;, score=0.636 total time=  35.6s
[CV 1/3] END algorithm=auto, n_neighbors=6, weights=uniform;, score=0.661 total time=  35.5s
[CV 3/3] END algorithm=auto, n_neighbors=8, weights=distance;, score=0.667 total time=  35.1s
[CV 3/3] END algorithm=auto, n_neighbors=10, weights=distance;, score=0.667 total time=  35.0s
[CV 3/3] END algorithm=auto, n_neighbors=12, weights=distance;, score=0.666 total time=  34.6s
[CV 2/3] END algorithm=auto, n_neighbors=15, weights=uniform;, score=0.666 total time=  34.8s
[CV 1/3] END algorithm=auto, n_neighbors=17, weights=distance;, score=0.664 total time=  34.2s
[CV 2/3] END algorithm=auto, n_neighbors=20, weights=uniform;, score=0.664 total time=  34.4s
[CV 3/3] END algorithm=ball_tree, n_neighbors=2, weights=distance;, score=0.596 total time= 5.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=6, weights=uniform;, score=0.664 total time= 5.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=8, weights=distance;, score=0.667 total time= 5.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=11, weights=distance;, score=0.664 total time= 5.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=14, weights=uniform;, score=0.665 total time= 5.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=16, weights=distance;, score=0.666 total time= 5.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=19, weights=distance;, score=0.663 total time= 5.5min
[CV 1/3] END algorithm=kd_tree, n_neighbors=2, weights=uniform;, score=0.640 total time= 7.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=4, weights=distance;, score=0.641 total time= 7.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=7, weights=uniform;, score=0.666 total time= 7.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=10, weights=uniform;, score=0.663 total time= 7.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=12, weights=distance;, score=0.666 total time= 7.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=15, weights=uniform;, score=0.661 total time= 7.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=18, weights=uniform;, score=0.661 total time= 7.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=20, weights=distance;, score=0.667 total time= 7.4min
[CV 2/3] END algorithm=brute, n_neighbors=10, weights=distance;, score=0.666 total time=  27.1s
[CV 2/3] END algorithm=brute, n_neighbors=13, weights=uniform;, score=0.664 total time=  29.6s
[CV 3/3] END algorithm=brute, n_neighbors=15, weights=distance;, score=0.668 total time=  29.5s
[CV 1/3] END algorithm=brute, n_neighbors=18, weights=distance;, score=0.663 total time=  29.5s
[CV 2/3] END class_weight=balanced, gamma=scale, kernel=sigmoid;, score=0.560 total time=68.4min
[CV 2/3] END class_weight=balanced, gamma=auto, kernel=rbf;, score=0.213 total time=85.5min
[CV 3/3] END class_weight=None, gamma=auto, kernel=poly;, score=0.661 total time=33.6min
[CV 3/3] END algorithm=auto, n_neighbors=2, weights=uniform;, score=0.661 total time=  35.4s
[CV 1/3] END algorithm=auto, n_neighbors=5, weights=uniform;, score=0.659 total time=  35.6s
[CV 1/3] END algorithm=auto, n_neighbors=8, weights=uniform;, score=0.662 total time=  35.1s
[CV 3/3] END algorithm=auto, n_neighbors=10, weights=uniform;, score=0.661 total time=  35.0s
[CV 1/3] END algorithm=auto, n_neighbors=12, weights=distance;, score=0.664 total time=  34.9s
[CV 3/3] END algorithm=auto, n_neighbors=15, weights=uniform;, score=0.661 total time=  35.1s
[CV 2/3] END algorithm=auto, n_neighbors=18, weights=uniform;, score=0.665 total time=  34.7s
[CV 2/3] END algorithm=auto, n_neighbors=20, weights=distance;, score=0.667 total time=  34.2s
[CV 2/3] END algorithm=ball_tree, n_neighbors=3, weights=uniform;, score=0.636 total time= 5.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=5, weights=distance;, score=0.656 total time= 5.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=8, weights=uniform;, score=0.664 total time= 5.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=11, weights=uniform;, score=0.663 total time= 5.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=13, weights=distance;, score=0.663 total time= 5.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=16, weights=uniform;, score=0.665 total time= 5.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=18, weights=distance;, score=0.665 total time= 5.5min
[CV 1/3] END algorithm=kd_tree, n_neighbors=1, weights=distance;, score=0.503 total time= 7.1min
[CV 2/3] END algorithm=kd_tree, n_neighbors=4, weights=uniform;, score=0.660 total time= 7.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=7, weights=uniform;, score=0.661 total time= 7.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=9, weights=distance;, score=0.668 total time= 7.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=12, weights=distance;, score=0.664 total time= 7.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=15, weights=uniform;, score=0.666 total time= 7.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=17, weights=distance;, score=0.664 total time= 7.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=20, weights=uniform;, score=0.664 total time= 7.4min
[CV 2/3] END algorithm=brute, n_neighbors=9, weights=uniform;, score=0.664 total time=  28.3s
[CV 2/3] END algorithm=brute, n_neighbors=11, weights=distance;, score=0.664 total time=  29.6s
[CV 3/3] END algorithm=brute, n_neighbors=14, weights=uniform;, score=0.661 total time=  29.7s
[CV 1/3] END algorithm=brute, n_neighbors=17, weights=uniform;, score=0.661 total time=  29.5s
[CV 2/3] END algorithm=brute, n_neighbors=19, weights=distance;, score=0.668 total time=  24.2s
[CV 2/3] END class_weight=balanced, gamma=scale, kernel=poly;, score=0.666 total time=75.2min
[CV 2/3] END class_weight=None, gamma=scale, kernel=sigmoid;, score=0.669 total time=49.2min
[CV 3/3] END class_weight=None, gamma=scale, kernel=poly;, score=0.663 total time=69.1min
[CV 3/3] END algorithm=auto, n_neighbors=3, weights=uniform;, score=0.661 total time=  35.6s
[CV 3/3] END algorithm=auto, n_neighbors=5, weights=distance;, score=0.656 total time=  35.0s
[CV 1/3] END algorithm=auto, n_neighbors=6, weights=distance;, score=0.659 total time=  34.7s
[CV 2/3] END algorithm=auto, n_neighbors=9, weights=uniform;, score=0.664 total time=  34.2s
[CV 3/3] END algorithm=auto, n_neighbors=11, weights=distance;, score=0.666 total time=  33.8s
[CV 1/3] END algorithm=auto, n_neighbors=14, weights=distance;, score=0.664 total time=  33.3s
[CV 2/3] END algorithm=auto, n_neighbors=17, weights=uniform;, score=0.666 total time=  33.4s
[CV 3/3] END algorithm=auto, n_neighbors=19, weights=distance;, score=0.665 total time=  33.3s
[CV 1/3] END algorithm=ball_tree, n_neighbors=2, weights=distance;, score=0.503 total time= 5.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=5, weights=uniform;, score=0.661 total time= 5.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=7, weights=distance;, score=0.668 total time= 5.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=10, weights=distance;, score=0.663 total time= 5.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=13, weights=uniform;, score=0.664 total time= 5.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=15, weights=distance;, score=0.668 total time= 5.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=18, weights=distance;, score=0.663 total time= 5.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=1, weights=uniform;, score=0.619 total time= 7.2min
[CV 3/3] END algorithm=kd_tree, n_neighbors=3, weights=distance;, score=0.654 total time= 7.3min
[CV 1/3] END algorithm=kd_tree, n_neighbors=6, weights=distance;, score=0.659 total time= 7.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=9, weights=uniform;, score=0.664 total time= 7.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=12, weights=uniform;, score=0.659 total time= 7.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=15, weights=uniform;, score=0.661 total time= 7.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=17, weights=distance;, score=0.666 total time= 7.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=20, weights=distance;, score=0.663 total time= 7.4min
[CV 2/3] END algorithm=brute, n_neighbors=9, weights=distance;, score=0.664 total time=  29.7s
[CV 2/3] END algorithm=brute, n_neighbors=12, weights=uniform;, score=0.662 total time=  29.8s
[CV 3/3] END algorithm=brute, n_neighbors=14, weights=distance;, score=0.667 total time=  29.6s
[CV 1/3] END algorithm=brute, n_neighbors=17, weights=distance;, score=0.664 total time=  29.6s
[CV 2/3] END algorithm=brute, n_neighbors=20, weights=uniform;, score=0.664 total time=  20.7s
[CV 1/3] END class_weight=balanced, gamma=scale, kernel=rbf;, score=0.629 total time=84.2min
[CV 1/3] END class_weight=None, gamma=scale, kernel=poly;, score=0.662 total time=74.4min
[CV 1/3] END class_weight=None, gamma=auto, kernel=rbf;, score=0.661 total time=35.7min
[CV 3/3] END algorithm=auto, n_neighbors=2, weights=distance;, score=0.596 total time=  35.6s
[CV 2/3] END algorithm=auto, n_neighbors=5, weights=distance;, score=0.660 total time=  35.5s
[CV 3/3] END algorithm=auto, n_neighbors=8, weights=uniform;, score=0.664 total time=  35.7s
[CV 1/3] END algorithm=auto, n_neighbors=11, weights=distance;, score=0.664 total time=  35.4s
[CV 3/3] END algorithm=auto, n_neighbors=13, weights=distance;, score=0.668 total time=  35.5s
[CV 1/3] END algorithm=auto, n_neighbors=16, weights=distance;, score=0.664 total time=  35.1s
[CV 2/3] END algorithm=auto, n_neighbors=19, weights=uniform;, score=0.665 total time=  34.9s
[CV 1/3] END algorithm=ball_tree, n_neighbors=1, weights=distance;, score=0.503 total time= 5.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=4, weights=distance;, score=0.630 total time= 5.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=7, weights=uniform;, score=0.661 total time= 5.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=9, weights=distance;, score=0.668 total time= 5.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=12, weights=distance;, score=0.664 total time= 5.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=15, weights=uniform;, score=0.666 total time= 5.4min
[CV 3/3] END algorithm=ball_tree, n_neighbors=17, weights=distance;, score=0.666 total time= 5.4min
[CV 1/3] END algorithm=ball_tree, n_neighbors=20, weights=distance;, score=0.663 total time= 5.2min
[CV 2/3] END algorithm=kd_tree, n_neighbors=3, weights=uniform;, score=0.636 total time= 7.3min
[CV 3/3] END algorithm=kd_tree, n_neighbors=5, weights=distance;, score=0.656 total time= 7.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=8, weights=distance;, score=0.658 total time= 7.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=11, weights=uniform;, score=0.663 total time= 7.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=13, weights=distance;, score=0.668 total time= 7.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=16, weights=distance;, score=0.664 total time= 7.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=19, weights=uniform;, score=0.665 total time= 7.5min
[CV 2/3] END algorithm=brute, n_neighbors=2, weights=uniform;, score=0.663 total time=  30.8s
[CV 1/3] END algorithm=brute, n_neighbors=3, weights=distance;, score=0.615 total time=  30.4s
[CV 3/3] END algorithm=brute, n_neighbors=4, weights=distance;, score=0.653 total time=  30.3s
[CV 2/3] END algorithm=brute, n_neighbors=6, weights=uniform;, score=0.664 total time=  29.9s
[CV 1/3] END algorithm=brute, n_neighbors=7, weights=distance;, score=0.663 total time=  30.0s
[CV 3/3] END algorithm=brute, n_neighbors=9, weights=distance;, score=0.668 total time=  29.7s
[CV 1/3] END algorithm=brute, n_neighbors=12, weights=distance;, score=0.664 total time=  29.7s
[CV 2/3] END algorithm=brute, n_neighbors=15, weights=uniform;, score=0.666 total time=  30.0s
[CV 3/3] END algorithm=brute, n_neighbors=17, weights=distance;, score=0.666 total time=  30.0s
[CV 1/3] END algorithm=brute, n_neighbors=20, weights=distance;, score=0.663 total time=  21.9s
[CV 2/3] END class_weight=balanced, gamma=auto, kernel=sigmoid;, score=0.213 total time=77.2min
[CV 3/3] END class_weight=None, gamma=scale, kernel=sigmoid;, score=0.659 total time=50.0min
[CV 2/3] END class_weight=None, gamma=scale, kernel=rbf;, score=0.666 total time=67.3min
[CV 3/3] END algorithm=auto, n_neighbors=1, weights=distance;, score=0.596 total time=  35.6s
[CV 3/3] END algorithm=auto, n_neighbors=5, weights=uniform;, score=0.660 total time=  35.6s
[CV 1/3] END algorithm=auto, n_neighbors=8, weights=distance;, score=0.658 total time=  35.5s
[CV 1/3] END algorithm=auto, n_neighbors=11, weights=uniform;, score=0.664 total time=  35.8s
[CV 2/3] END algorithm=auto, n_neighbors=14, weights=uniform;, score=0.665 total time=  35.7s
[CV 3/3] END algorithm=auto, n_neighbors=16, weights=distance;, score=0.666 total time=  35.6s
[CV 1/3] END algorithm=auto, n_neighbors=19, weights=distance;, score=0.663 total time=  35.6s
[CV 1/3] END algorithm=ball_tree, n_neighbors=2, weights=uniform;, score=0.640 total time= 5.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=4, weights=distance;, score=0.653 total time= 5.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=7, weights=distance;, score=0.663 total time= 5.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=10, weights=uniform;, score=0.660 total time= 5.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=12, weights=distance;, score=0.666 total time= 5.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=15, weights=distance;, score=0.664 total time= 5.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=18, weights=uniform;, score=0.665 total time= 5.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=20, weights=distance;, score=0.665 total time= 5.2min
[CV 1/3] END algorithm=kd_tree, n_neighbors=3, weights=distance;, score=0.615 total time= 7.3min
[CV 2/3] END algorithm=kd_tree, n_neighbors=6, weights=uniform;, score=0.664 total time= 7.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=8, weights=distance;, score=0.667 total time= 7.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=11, weights=distance;, score=0.664 total time= 7.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=14, weights=uniform;, score=0.665 total time= 7.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=16, weights=distance;, score=0.666 total time= 7.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=19, weights=distance;, score=0.663 total time= 7.4min
[CV 1/3] END algorithm=brute, n_neighbors=2, weights=uniform;, score=0.640 total time=  29.9s
[CV 3/3] END algorithm=brute, n_neighbors=3, weights=uniform;, score=0.661 total time=  29.7s
[CV 2/3] END algorithm=brute, n_neighbors=4, weights=distance;, score=0.641 total time=  29.6s
[CV 1/3] END algorithm=brute, n_neighbors=6, weights=uniform;, score=0.661 total time=  29.7s
[CV 3/3] END algorithm=brute, n_neighbors=7, weights=uniform;, score=0.666 total time=  29.6s
[CV 3/3] END algorithm=brute, n_neighbors=9, weights=uniform;, score=0.664 total time=  30.0s
[CV 1/3] END algorithm=brute, n_neighbors=12, weights=uniform;, score=0.659 total time=  29.7s
[CV 2/3] END algorithm=brute, n_neighbors=14, weights=distance;, score=0.668 total time=  29.5s
[CV 3/3] END algorithm=brute, n_neighbors=17, weights=uniform;, score=0.661 total time=  29.9s
[CV 1/3] END algorithm=brute, n_neighbors=20, weights=uniform;, score=0.661 total time=  24.6s
[CV 2/3] END class_weight=balanced, gamma=scale, kernel=rbf;, score=0.625 total time=85.9min
[CV 2/3] END class_weight=None, gamma=scale, kernel=poly;, score=0.663 total time=73.3min
[CV 2/3] END class_weight=None, gamma=auto, kernel=rbf;, score=0.661 total time=35.4min
[CV 1/3] END algorithm=auto, n_neighbors=3, weights=uniform;, score=0.634 total time=  35.7s
[CV 2/3] END algorithm=auto, n_neighbors=6, weights=uniform;, score=0.664 total time=  35.5s
[CV 2/3] END algorithm=auto, n_neighbors=8, weights=distance;, score=0.660 total time=  35.5s
[CV 2/3] END algorithm=auto, n_neighbors=11, weights=uniform;, score=0.663 total time=  35.7s
[CV 1/3] END algorithm=auto, n_neighbors=14, weights=uniform;, score=0.661 total time=  35.7s
[CV 2/3] END algorithm=auto, n_neighbors=16, weights=distance;, score=0.668 total time=  35.6s
[CV 3/3] END algorithm=auto, n_neighbors=19, weights=uniform;, score=0.661 total time=  35.6s
[CV 2/3] END algorithm=ball_tree, n_neighbors=2, weights=uniform;, score=0.663 total time= 5.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=4, weights=distance;, score=0.641 total time= 5.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=7, weights=uniform;, score=0.666 total time= 5.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=10, weights=uniform;, score=0.663 total time= 5.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=12, weights=distance;, score=0.666 total time= 5.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=15, weights=uniform;, score=0.661 total time= 5.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=18, weights=uniform;, score=0.661 total time= 5.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=20, weights=distance;, score=0.667 total time= 5.2min
[CV 3/3] END algorithm=kd_tree, n_neighbors=3, weights=uniform;, score=0.661 total time= 7.3min
[CV 1/3] END algorithm=kd_tree, n_neighbors=6, weights=uniform;, score=0.661 total time= 7.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=8, weights=distance;, score=0.660 total time= 7.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=11, weights=uniform;, score=0.664 total time= 7.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=14, weights=uniform;, score=0.661 total time= 7.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=16, weights=distance;, score=0.668 total time= 7.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=19, weights=uniform;, score=0.661 total time= 7.4min
[CV 3/3] END algorithm=brute, n_neighbors=1, weights=distance;, score=0.596 total time=  27.5s
[CV 2/3] END algorithm=brute, n_neighbors=3, weights=uniform;, score=0.636 total time=  29.6s
[CV 1/3] END algorithm=brute, n_neighbors=4, weights=distance;, score=0.630 total time=  29.6s
[CV 3/3] END algorithm=brute, n_neighbors=5, weights=distance;, score=0.656 total time=  29.5s
[CV 2/3] END algorithm=brute, n_neighbors=7, weights=uniform;, score=0.661 total time=  29.5s
[CV 2/3] END algorithm=brute, n_neighbors=8, weights=distance;, score=0.660 total time=  29.4s
[CV 3/3] END algorithm=brute, n_neighbors=11, weights=uniform;, score=0.664 total time=  29.4s
[CV 1/3] END algorithm=brute, n_neighbors=14, weights=uniform;, score=0.661 total time=  29.3s
[CV 2/3] END algorithm=brute, n_neighbors=16, weights=distance;, score=0.668 total time=  29.4s
[CV 3/3] END algorithm=brute, n_neighbors=19, weights=uniform;, score=0.661 total time=  26.6s
[CV 1/3] END class_weight=balanced, gamma=scale, kernel=poly;, score=0.666 total time=73.9min
[CV 3/3] END class_weight=balanced, gamma=auto, kernel=rbf;, score=0.213 total time=88.9min
[CV 3/3] END class_weight=None, gamma=auto, kernel=rbf;, score=0.661 total time=32.9min
[CV 1/3] END algorithm=auto, n_neighbors=3, weights=distance;, score=0.615 total time=  35.4s
[CV 3/3] END algorithm=auto, n_neighbors=4, weights=distance;, score=0.653 total time=  35.3s
[CV 1/3] END algorithm=auto, n_neighbors=7, weights=uniform;, score=0.662 total time=  35.5s
[CV 2/3] END algorithm=auto, n_neighbors=10, weights=distance;, score=0.666 total time=  35.2s
[CV 2/3] END algorithm=auto, n_neighbors=13, weights=uniform;, score=0.664 total time=  35.2s
[CV 3/3] END algorithm=auto, n_neighbors=15, weights=distance;, score=0.668 total time=  35.1s
[CV 1/3] END algorithm=auto, n_neighbors=18, weights=distance;, score=0.663 total time=  34.9s
[CV 2/3] END algorithm=ball_tree, n_neighbors=1, weights=uniform;, score=0.619 total time= 5.4min
[CV 3/3] END algorithm=ball_tree, n_neighbors=3, weights=distance;, score=0.654 total time= 5.4min
[CV 1/3] END algorithm=ball_tree, n_neighbors=6, weights=distance;, score=0.659 total time= 5.4min
[CV 2/3] END algorithm=ball_tree, n_neighbors=9, weights=uniform;, score=0.664 total time= 5.4min
[CV 3/3] END algorithm=ball_tree, n_neighbors=11, weights=distance;, score=0.666 total time= 5.4min
[CV 1/3] END algorithm=ball_tree, n_neighbors=14, weights=distance;, score=0.664 total time= 5.4min
[CV 2/3] END algorithm=ball_tree, n_neighbors=17, weights=uniform;, score=0.666 total time= 5.4min
[CV 3/3] END algorithm=ball_tree, n_neighbors=19, weights=distance;, score=0.665 total time= 5.2min
[CV 1/3] END algorithm=kd_tree, n_neighbors=2, weights=distance;, score=0.503 total time= 7.3min
[CV 3/3] END algorithm=kd_tree, n_neighbors=5, weights=uniform;, score=0.660 total time= 7.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=8, weights=uniform;, score=0.662 total time= 7.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=10, weights=distance;, score=0.666 total time= 7.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=13, weights=uniform;, score=0.662 total time= 7.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=16, weights=uniform;, score=0.661 total time= 7.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=18, weights=distance;, score=0.665 total time= 7.4min
[CV 1/3] END algorithm=brute, n_neighbors=1, weights=distance;, score=0.503 total time=  31.3s
[CV 1/3] END algorithm=brute, n_neighbors=3, weights=uniform;, score=0.634 total time=  31.3s
[CV 3/3] END algorithm=brute, n_neighbors=4, weights=uniform;, score=0.664 total time=  30.8s
[CV 2/3] END algorithm=brute, n_neighbors=5, weights=distance;, score=0.660 total time=  30.4s
[CV 1/3] END algorithm=brute, n_neighbors=7, weights=uniform;, score=0.662 total time=  30.5s
[CV 3/3] END algorithm=brute, n_neighbors=8, weights=uniform;, score=0.664 total time=  30.3s
[CV 1/3] END algorithm=brute, n_neighbors=11, weights=uniform;, score=0.664 total time=  30.5s
[CV 2/3] END algorithm=brute, n_neighbors=13, weights=distance;, score=0.665 total time=  30.0s
[CV 3/3] END algorithm=brute, n_neighbors=16, weights=uniform;, score=0.661 total time=  30.0s
[CV 1/3] END algorithm=brute, n_neighbors=19, weights=uniform;, score=0.661 total time=  29.0s
[CV 3/3] END class_weight=balanced, gamma=scale, kernel=linear;, score=0.642 total time=66.1min
[CV 2/3] END class_weight=balanced, gamma=auto, kernel=linear;, score=0.592 total time=65.5min
[CV 3/3] END class_weight=None, gamma=scale, kernel=rbf;, score=0.665 total time=64.8min
[CV 1/3] END algorithm=auto, n_neighbors=2, weights=distance;, score=0.503 total time=  35.3s
[CV 2/3] END algorithm=auto, n_neighbors=3, weights=distance;, score=0.630 total time=  35.4s
[CV 3/3] END algorithm=auto, n_neighbors=6, weights=distance;, score=0.665 total time=  35.5s
[CV 1/3] END algorithm=auto, n_neighbors=10, weights=uniform;, score=0.663 total time=  35.4s
[CV 1/3] END algorithm=auto, n_neighbors=13, weights=distance;, score=0.663 total time=  35.6s
[CV 1/3] END algorithm=auto, n_neighbors=16, weights=uniform;, score=0.661 total time=  35.4s
[CV 3/3] END algorithm=auto, n_neighbors=18, weights=distance;, score=0.665 total time=  35.3s
[CV 2/3] END algorithm=ball_tree, n_neighbors=1, weights=distance;, score=0.619 total time= 5.4min
[CV 1/3] END algorithm=ball_tree, n_neighbors=4, weights=uniform;, score=0.649 total time= 5.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=6, weights=distance;, score=0.656 total time= 5.4min
[CV 3/3] END algorithm=ball_tree, n_neighbors=9, weights=uniform;, score=0.664 total time= 5.4min
[CV 2/3] END algorithm=ball_tree, n_neighbors=12, weights=uniform;, score=0.662 total time= 5.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=14, weights=distance;, score=0.667 total time= 5.4min
[CV 1/3] END algorithm=ball_tree, n_neighbors=17, weights=distance;, score=0.664 total time= 5.4min
[CV 2/3] END algorithm=ball_tree, n_neighbors=20, weights=uniform;, score=0.664 total time= 5.2min
[CV 3/3] END algorithm=kd_tree, n_neighbors=2, weights=distance;, score=0.596 total time= 7.3min
[CV 2/3] END algorithm=kd_tree, n_neighbors=5, weights=uniform;, score=0.661 total time= 7.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=7, weights=distance;, score=0.668 total time= 7.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=10, weights=distance;, score=0.663 total time= 7.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=13, weights=uniform;, score=0.664 total time= 7.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=15, weights=distance;, score=0.668 total time= 7.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=18, weights=uniform;, score=0.661 total time= 7.4min
[CV 1/3] END algorithm=brute, n_neighbors=1, weights=uniform;, score=0.503 total time=  29.0s
[CV 1/3] END algorithm=brute, n_neighbors=2, weights=distance;, score=0.503 total time=  29.6s
[CV 2/3] END algorithm=brute, n_neighbors=3, weights=distance;, score=0.630 total time=  29.6s
[CV 1/3] END algorithm=brute, n_neighbors=5, weights=uniform;, score=0.659 total time=  29.7s
[CV 3/3] END algorithm=brute, n_neighbors=6, weights=uniform;, score=0.665 total time=  29.9s
[CV 2/3] END algorithm=brute, n_neighbors=7, weights=distance;, score=0.662 total time=  29.8s
[CV 1/3] END algorithm=brute, n_neighbors=10, weights=uniform;, score=0.663 total time=  29.7s
[CV 2/3] END algorithm=brute, n_neighbors=12, weights=distance;, score=0.666 total time=  29.4s
[CV 3/3] END algorithm=brute, n_neighbors=15, weights=uniform;, score=0.661 total time=  29.6s
[CV 1/3] END algorithm=brute, n_neighbors=18, weights=uniform;, score=0.661 total time=  29.8s
[CV 2/3] END algorithm=brute, n_neighbors=20, weights=distance;, score=0.667 total time=  20.9s
[CV 1/3] END class_weight=balanced, gamma=auto, kernel=sigmoid;, score=0.213 total time=78.4min
[CV 2/3] END class_weight=None, gamma=scale, kernel=linear;, score=0.613 total time=68.4min
[CV 3/3] END class_weight=None, gamma=auto, kernel=linear;, score=0.646 total time=49.8min
[CV 1/3] END algorithm=auto, n_neighbors=2, weights=uniform;, score=0.640 total time=  35.4s
[CV 1/3] END algorithm=auto, n_neighbors=4, weights=distance;, score=0.630 total time=  34.9s
[CV 3/3] END algorithm=auto, n_neighbors=6, weights=uniform;, score=0.665 total time=  34.5s
[CV 1/3] END algorithm=auto, n_neighbors=9, weights=uniform;, score=0.662 total time=  34.1s
[CV 2/3] END algorithm=auto, n_neighbors=11, weights=distance;, score=0.664 total time=  33.4s
[CV 3/3] END algorithm=auto, n_neighbors=14, weights=uniform;, score=0.661 total time=  33.5s
[CV 1/3] END algorithm=auto, n_neighbors=17, weights=uniform;, score=0.661 total time=  33.2s
[CV 2/3] END algorithm=auto, n_neighbors=19, weights=distance;, score=0.668 total time=  33.3s
[CV 3/3] END algorithm=ball_tree, n_neighbors=2, weights=uniform;, score=0.661 total time= 5.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=5, weights=uniform;, score=0.659 total time= 5.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=7, weights=distance;, score=0.662 total time= 5.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=10, weights=uniform;, score=0.661 total time= 5.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=13, weights=uniform;, score=0.662 total time= 5.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=15, weights=distance;, score=0.668 total time= 5.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=18, weights=uniform;, score=0.661 total time= 5.5min
[CV 1/3] END algorithm=kd_tree, n_neighbors=1, weights=uniform;, score=0.503 total time= 7.1min
[CV 2/3] END algorithm=kd_tree, n_neighbors=3, weights=distance;, score=0.630 total time= 7.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=6, weights=uniform;, score=0.665 total time= 7.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=9, weights=uniform;, score=0.662 total time= 7.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=11, weights=distance;, score=0.666 total time= 7.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=14, weights=distance;, score=0.667 total time= 7.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=17, weights=distance;, score=0.668 total time= 7.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=20, weights=uniform;, score=0.661 total time= 7.4min
[CV 1/3] END algorithm=brute, n_neighbors=9, weights=distance;, score=0.661 total time=  30.8s
[CV 3/3] END algorithm=brute, n_neighbors=12, weights=uniform;, score=0.661 total time=  30.9s
[CV 1/3] END algorithm=brute, n_neighbors=15, weights=uniform;, score=0.661 total time=  30.5s
[CV 2/3] END algorithm=brute, n_neighbors=17, weights=distance;, score=0.668 total time=  30.1s
[CV 3/3] END algorithm=brute, n_neighbors=20, weights=uniform;, score=0.661 total time=  24.0s
[CV 3/3] END class_weight=balanced, gamma=auto, kernel=sigmoid;, score=0.213 total time=74.7min
[CV 1/3] END class_weight=None, gamma=scale, kernel=sigmoid;, score=0.668 total time=50.3min
[CV 1/3] END class_weight=None, gamma=scale, kernel=rbf;, score=0.666 total time=72.4min
[CV 2/3] END algorithm=auto, n_neighbors=2, weights=uniform;, score=0.663 total time=  35.6s
[CV 1/3] END algorithm=auto, n_neighbors=5, weights=distance;, score=0.651 total time=  35.5s
[CV 3/3] END algorithm=auto, n_neighbors=7, weights=distance;, score=0.668 total time=  35.1s
[CV 2/3] END algorithm=auto, n_neighbors=9, weights=distance;, score=0.664 total time=  34.8s
[CV 1/3] END algorithm=auto, n_neighbors=12, weights=uniform;, score=0.659 total time=  34.7s
[CV 2/3] END algorithm=auto, n_neighbors=14, weights=distance;, score=0.668 total time=  34.6s
[CV 3/3] END algorithm=auto, n_neighbors=17, weights=uniform;, score=0.661 total time=  34.2s
[CV 1/3] END algorithm=auto, n_neighbors=20, weights=uniform;, score=0.661 total time=  34.4s
[CV 2/3] END algorithm=ball_tree, n_neighbors=2, weights=distance;, score=0.619 total time= 5.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=5, weights=distance;, score=0.651 total time= 5.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=8, weights=distance;, score=0.660 total time= 5.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=11, weights=uniform;, score=0.664 total time= 5.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=14, weights=uniform;, score=0.661 total time= 5.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=16, weights=distance;, score=0.668 total time= 5.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=19, weights=uniform;, score=0.661 total time= 5.5min
[CV 2/3] END algorithm=kd_tree, n_neighbors=2, weights=uniform;, score=0.663 total time= 7.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=4, weights=distance;, score=0.653 total time= 7.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=7, weights=distance;, score=0.663 total time= 7.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=10, weights=uniform;, score=0.660 total time= 7.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=12, weights=distance;, score=0.666 total time= 7.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=15, weights=distance;, score=0.664 total time= 7.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=18, weights=uniform;, score=0.665 total time= 7.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=20, weights=distance;, score=0.665 total time= 7.4min
[CV 2/3] END algorithm=brute, n_neighbors=11, weights=uniform;, score=0.663 total time=  29.5s
[CV 3/3] END algorithm=brute, n_neighbors=13, weights=distance;, score=0.668 total time=  29.4s
[CV 1/3] END algorithm=brute, n_neighbors=16, weights=distance;, score=0.664 total time=  29.6s
[CV 2/3] END algorithm=brute, n_neighbors=19, weights=uniform;, score=0.665 total time=  27.5s
[CV 2/3] END class_weight=balanced, gamma=scale, kernel=linear;, score=0.592 total time=66.7min
[CV 1/3] END class_weight=balanced, gamma=auto, kernel=poly;, score=0.213 total time=76.3min
[CV 1/3] END class_weight=None, gamma=auto, kernel=linear;, score=0.604 total time=55.3min
[CV 1/3] END algorithm=auto, n_neighbors=1, weights=distance;, score=0.503 total time=  35.5s
[CV 2/3] END algorithm=auto, n_neighbors=5, weights=uniform;, score=0.661 total time=  35.6s
[CV 2/3] END algorithm=auto, n_neighbors=8, weights=uniform;, score=0.662 total time=  35.6s
[CV 3/3] END algorithm=auto, n_neighbors=11, weights=uniform;, score=0.664 total time=  35.5s
[CV 2/3] END algorithm=auto, n_neighbors=13, weights=distance;, score=0.665 total time=  35.3s
[CV 3/3] END algorithm=auto, n_neighbors=16, weights=uniform;, score=0.661 total time=  34.9s
[CV 2/3] END algorithm=auto, n_neighbors=18, weights=distance;, score=0.668 total time=  34.6s
[CV 3/3] END algorithm=ball_tree, n_neighbors=1, weights=uniform;, score=0.596 total time= 5.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=4, weights=uniform;, score=0.664 total time= 5.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=7, weights=uniform;, score=0.662 total time= 5.5min
[CV 2/3] END algorithm=ball_tree, n_neighbors=9, weights=distance;, score=0.664 total time= 5.5min
[CV 3/3] END algorithm=ball_tree, n_neighbors=12, weights=uniform;, score=0.661 total time= 5.5min
[CV 1/3] END algorithm=ball_tree, n_neighbors=15, weights=uniform;, score=0.661 total time= 5.4min
[CV 2/3] END algorithm=ball_tree, n_neighbors=17, weights=distance;, score=0.668 total time= 5.4min
[CV 3/3] END algorithm=ball_tree, n_neighbors=20, weights=uniform;, score=0.661 total time= 5.2min
[CV 1/3] END algorithm=kd_tree, n_neighbors=3, weights=uniform;, score=0.634 total time= 7.3min
[CV 2/3] END algorithm=kd_tree, n_neighbors=5, weights=distance;, score=0.660 total time= 7.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=8, weights=uniform;, score=0.664 total time= 7.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=11, weights=uniform;, score=0.664 total time= 7.4min
[CV 2/3] END algorithm=kd_tree, n_neighbors=13, weights=distance;, score=0.665 total time= 7.4min
[CV 3/3] END algorithm=kd_tree, n_neighbors=16, weights=uniform;, score=0.661 total time= 7.4min
[CV 1/3] END algorithm=kd_tree, n_neighbors=19, weights=uniform;, score=0.661 total time= 7.4min
[CV 2/3] END algorithm=brute, n_neighbors=1, weights=distance;, score=0.619 total time=  23.2s
[CV 3/3] END algorithm=brute, n_neighbors=2, weights=uniform;, score=0.661 total time=  30.8s
[CV 3/3] END algorithm=brute, n_neighbors=3, weights=distance;, score=0.654 total time=  30.6s
[CV 2/3] END algorithm=brute, n_neighbors=5, weights=uniform;, score=0.661 total time=  30.3s
[CV 1/3] END algorithm=brute, n_neighbors=6, weights=distance;, score=0.659 total time=  30.0s
[CV 3/3] END algorithm=brute, n_neighbors=7, weights=distance;, score=0.668 total time=  30.0s
[CV 2/3] END algorithm=brute, n_neighbors=10, weights=uniform;, score=0.660 total time=  30.1s
[CV 3/3] END algorithm=brute, n_neighbors=12, weights=distance;, score=0.666 total time=  29.8s
[CV 1/3] END algorithm=brute, n_neighbors=15, weights=distance;, score=0.664 total time=  29.8s
[CV 2/3] END algorithm=brute, n_neighbors=18, weights=uniform;, score=0.665 total time=  30.1s
[CV 3/3] END algorithm=brute, n_neighbors=20, weights=distance;, score=0.665 total time=  20.0s
[CV 1/3] END class_weight=balanced, gamma=auto, kernel=linear;, score=0.593 total time=66.7min
[CV 2/3] END class_weight=balanced, gamma=auto, kernel=poly;, score=0.213 total time=77.7min
[CV 2/3] END class_weight=None, gamma=auto, kernel=linear;, score=0.613 total time=54.2min
saving: KNN_summary_and_desc_1637299057 as png
saving: DT_summary_and_desc_1637299225 as png
Fitting 3 folds for each of 16 candidates, totalling 48 fits
saving: SVC_summary_and_desc_1637317010 as png
Fitting 3 folds for each of 168 candidates, totalling 504 fits
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=hinge, penalty=l2;, score=0.485 total time=  14.4s
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=log, penalty=elasticnet;, score=0.518 total time= 1.4min
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=perceptron, penalty=l1;, score=0.578 total time= 1.3min
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=hinge, penalty=elasticnet;, score=0.627 total time= 2.0min
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=squared_hinge, penalty=l2;, score=0.640 total time=  15.7s
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=squared_hinge, penalty=elasticnet;, score=0.622 total time= 1.4min
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=squared_loss, penalty=l1;, score=0.384 total time= 6.5min
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=perceptron, penalty=l2;, score=0.594 total time=  16.2s
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=perceptron, penalty=l1;, score=0.580 total time= 2.1min
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=huber, penalty=l1;, score=0.633 total time= 1.7min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=hinge, penalty=elasticnet;, score=0.584 total time= 5.3min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=modified_huber, penalty=elasticnet;, score=0.630 total time= 6.3min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_loss, penalty=l2;, score=0.375 total time=25.5min
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=squared_hinge, penalty=elasticnet;, score=0.660 total time=  47.6s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=squared_loss, penalty=l2;, score=0.661 total time=  19.6s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=squared_loss, penalty=l1;, score=0.364 total time=  19.4s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=squared_loss, penalty=elasticnet;, score=0.661 total time=  20.3s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=squared_loss, penalty=elasticnet;, score=0.661 total time=  20.2s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=huber, penalty=l2;, score=0.661 total time=  10.4s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=huber, penalty=l2;, score=0.661 total time=  10.4s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=huber, penalty=l1;, score=0.661 total time=  17.1s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=huber, penalty=elasticnet;, score=0.661 total time=  17.1s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=huber, penalty=elasticnet;, score=0.661 total time=  17.1s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=hinge, penalty=l2;, score=0.660 total time=  46.9s
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=hinge, penalty=l2;, score=0.660 total time=  45.2s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=hinge, penalty=l1;, score=0.661 total time= 1.3min
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=hinge, penalty=elasticnet;, score=0.661 total time= 1.3min
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=log, penalty=l2;, score=0.661 total time=  34.8s
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=log, penalty=l2;, score=0.660 total time=  36.2s
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=log, penalty=l1;, score=0.661 total time=  52.0s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=modified_huber, penalty=l2;, score=0.651 total time=  52.7s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=modified_huber, penalty=l1;, score=0.661 total time= 2.2min
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=squared_hinge, penalty=l2;, score=0.481 total time=  58.1s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=squared_hinge, penalty=l1;, score=0.602 total time= 2.3min
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=perceptron, penalty=l2;, score=0.599 total time=  37.0s
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=perceptron, penalty=l1;, score=0.661 total time= 1.2min
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=squared_loss, penalty=l2;, score=0.634 total time= 1.6min
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=huber, penalty=l2;, score=0.661 total time=  14.6s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=huber, penalty=l2;, score=0.661 total time=  15.0s
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=huber, penalty=l2;, score=0.661 total time=  13.5s
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=huber, penalty=l1;, score=0.661 total time=  20.6s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=huber, penalty=l1;, score=0.661 total time=  20.6s
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=huber, penalty=l1;, score=0.661 total time=  20.9s
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=huber, penalty=elasticnet;, score=0.661 total time=  20.4s
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=hinge, penalty=l1;, score=0.661 total time= 2.7min
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=log, penalty=l2;, score=0.661 total time= 2.0min
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=log, penalty=elasticnet;, score=0.661 total time= 3.5min
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=modified_huber, penalty=elasticnet;, score=0.661 total time= 3.5min
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=squared_hinge, penalty=elasticnet;, score=0.661 total time= 3.9min
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=perceptron, penalty=l1;, score=0.661 total time= 2.7min
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=squared_loss, penalty=l2;, score=0.661 total time= 2.6min
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=huber, penalty=l2;, score=0.661 total time= 1.8min
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=huber, penalty=l1;, score=0.661 total time= 2.9min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=hinge, penalty=elasticnet;, score=0.639 total time= 1.3min
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=squared_hinge, penalty=l2;, score=0.619 total time=   8.1s
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=squared_hinge, penalty=l1;, score=0.642 total time= 1.1min
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=huber, penalty=l2;, score=0.153 total time=  11.5s
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=huber, penalty=elasticnet;, score=0.318 total time= 2.0min
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=modified_huber, penalty=l1;, score=0.628 total time= 1.8min
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=squared_loss, penalty=l2;, score=0.294 total time= 2.8min
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=log, penalty=l2;, score=0.591 total time=  32.8s
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=log, penalty=l1;, score=0.587 total time= 1.6min
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=modified_huber, penalty=elasticnet;, score=0.596 total time= 1.8min
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=perceptron, penalty=l2;, score=0.587 total time=  21.0s
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=perceptron, penalty=l1;, score=0.618 total time= 1.5min
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=huber, penalty=l2;, score=0.604 total time=  53.7s
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=huber, penalty=elasticnet;, score=0.626 total time= 2.3min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=log, penalty=l2;, score=0.636 total time= 2.2min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=log, penalty=elasticnet;, score=0.644 total time= 7.1min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_hinge, penalty=elasticnet;, score=0.620 total time=26.9min
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=perceptron, penalty=l2;, score=0.626 total time=   6.2s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=perceptron, penalty=l1;, score=0.661 total time=  14.5s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=perceptron, penalty=l1;, score=0.126 total time=  14.5s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=perceptron, penalty=elasticnet;, score=0.661 total time=  14.9s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=squared_loss, penalty=l2;, score=0.660 total time=  18.2s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=squared_loss, penalty=l1;, score=0.657 total time= 7.0min
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=log, penalty=l1;, score=0.661 total time=  52.2s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=log, penalty=elasticnet;, score=0.661 total time=  59.1s
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=modified_huber, penalty=l1;, score=0.613 total time= 1.9min
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=modified_huber, penalty=elasticnet;, score=0.661 total time= 2.1min
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=squared_hinge, penalty=elasticnet;, score=0.661 total time= 2.3min
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=perceptron, penalty=l1;, score=0.661 total time= 1.3min
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=squared_loss, penalty=l2;, score=0.660 total time= 1.4min
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=squared_loss, penalty=elasticnet;, score=0.661 total time= 1.8min
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=huber, penalty=elasticnet;, score=0.661 total time=  20.9s
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=hinge, penalty=l2;, score=0.661 total time= 1.5min
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=hinge, penalty=elasticnet;, score=0.661 total time= 2.6min
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=log, penalty=elasticnet;, score=0.661 total time= 3.5min
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=modified_huber, penalty=l2;, score=0.660 total time= 2.1min
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=squared_hinge, penalty=l2;, score=0.663 total time= 1.9min
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=squared_hinge, penalty=l2;, score=0.660 total time= 1.7min
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=perceptron, penalty=l2;, score=0.581 total time=  57.2s
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=perceptron, penalty=l2;, score=0.631 total time= 1.1min
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=perceptron, penalty=l1;, score=0.661 total time= 2.5min
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=squared_loss, penalty=l2;, score=0.660 total time= 2.4min
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=huber, penalty=l2;, score=0.661 total time= 1.9min
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=huber, penalty=l2;, score=0.661 total time= 1.8min
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=huber, penalty=elasticnet;, score=0.661 total time= 2.6min
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=hinge, penalty=l1;, score=0.613 total time= 1.3min
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=squared_hinge, penalty=l1;, score=0.621 total time= 1.2min
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=huber, penalty=l1;, score=0.140 total time= 1.8min
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=modified_huber, penalty=l2;, score=0.622 total time=  15.1s
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=modified_huber, penalty=l1;, score=0.620 total time= 2.1min
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=squared_loss, penalty=elasticnet;, score=0.372 total time= 3.0min
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=log, penalty=l2;, score=0.623 total time=  34.3s
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=log, penalty=l1;, score=0.615 total time= 2.0min
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_hinge, penalty=l1;, score=0.620 total time= 1.4min
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_loss, penalty=l2;, score=0.250 total time= 2.2min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=hinge, penalty=l2;, score=0.578 total time=  45.3s
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=hinge, penalty=l2;, score=0.627 total time=  45.6s
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=hinge, penalty=elasticnet;, score=0.639 total time= 5.7min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_hinge, penalty=l2;, score=0.615 total time= 3.1min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_hinge, penalty=elasticnet;, score=0.576 total time=46.0min
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=squared_loss, penalty=l1;, score=0.325 total time= 4.5min
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=hinge, penalty=l1;, score=0.661 total time= 2.8min
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=log, penalty=l1;, score=0.661 total time= 4.0min
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=modified_huber, penalty=l1;, score=0.661 total time= 3.9min
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=squared_hinge, penalty=l1;, score=0.623 total time= 7.8min
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=squared_loss, penalty=elasticnet;, score=0.661 total time= 3.9min
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=huber, penalty=l1;, score=0.661 total time= 3.0min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=log, penalty=l1;, score=0.566 total time= 1.9min
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=squared_loss, penalty=l2;, score=0.226 total time=  11.2s
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=squared_loss, penalty=l1;, score=0.540 total time=  30.4s
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=huber, penalty=l1;, score=0.150 total time= 2.1min
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=modified_huber, penalty=elasticnet;, score=0.629 total time= 1.6min
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=squared_loss, penalty=l2;, score=0.544 total time= 2.6min
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=hinge, penalty=l1;, score=0.613 total time= 1.8min
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=log, penalty=elasticnet;, score=0.595 total time= 1.7min
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_hinge, penalty=elasticnet;, score=0.613 total time= 1.5min
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_loss, penalty=l1;, score=0.300 total time=  32.0s
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_loss, penalty=elasticnet;, score=0.285 total time= 4.7min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=log, penalty=l1;, score=0.609 total time= 6.9min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_hinge, penalty=l1;, score=0.632 total time= 9.4min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=huber, penalty=l2;, score=0.629 total time= 2.5min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=huber, penalty=l1;, score=0.661 total time= 5.3min
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=hinge, penalty=l2;, score=0.661 total time=  10.2s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=hinge, penalty=l2;, score=0.661 total time=   8.8s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=hinge, penalty=l2;, score=0.126 total time=   9.6s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=hinge, penalty=l1;, score=0.213 total time=  19.2s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=hinge, penalty=l1;, score=0.661 total time=  19.1s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=hinge, penalty=l1;, score=0.661 total time=  24.9s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=hinge, penalty=elasticnet;, score=0.661 total time=  21.1s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=hinge, penalty=elasticnet;, score=0.661 total time=  24.9s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=hinge, penalty=elasticnet;, score=0.661 total time=  29.7s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=log, penalty=l2;, score=0.126 total time=  24.8s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=log, penalty=l2;, score=0.661 total time=  16.2s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=log, penalty=l1;, score=0.661 total time=  23.0s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=log, penalty=elasticnet;, score=0.661 total time=  31.9s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=modified_huber, penalty=l2;, score=0.213 total time=  12.4s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=modified_huber, penalty=l2;, score=0.126 total time=  10.4s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=modified_huber, penalty=elasticnet;, score=0.661 total time=  35.7s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=squared_hinge, penalty=l1;, score=0.642 total time= 1.2min
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=perceptron, penalty=elasticnet;, score=0.661 total time=  25.5s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=squared_loss, penalty=l1;, score=0.279 total time=  30.6s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=squared_loss, penalty=elasticnet;, score=0.661 total time=  25.8s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=huber, penalty=elasticnet;, score=0.661 total time=  22.1s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=hinge, penalty=l2;, score=0.661 total time=  11.0s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=hinge, penalty=elasticnet;, score=0.661 total time=  16.4s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=log, penalty=l1;, score=0.661 total time=  19.7s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=log, penalty=elasticnet;, score=0.661 total time=  19.6s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=modified_huber, penalty=l1;, score=0.661 total time=  23.8s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=squared_hinge, penalty=l2;, score=0.655 total time=  27.8s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=squared_hinge, penalty=l1;, score=0.513 total time=39.2min
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=squared_loss, penalty=l2;, score=0.661 total time= 2.4min
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=squared_loss, penalty=elasticnet;, score=0.661 total time= 3.9min
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=huber, penalty=l1;, score=0.661 total time= 3.0min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=log, penalty=l2;, score=0.502 total time=  23.3s
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=modified_huber, penalty=l2;, score=0.660 total time=  11.6s
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=modified_huber, penalty=l1;, score=0.628 total time= 1.8min
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=squared_loss, penalty=elasticnet;, score=0.533 total time=  33.8s
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=hinge, penalty=l1;, score=0.636 total time= 1.5min
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=modified_huber, penalty=l2;, score=0.647 total time=  15.1s
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=modified_huber, penalty=elasticnet;, score=0.569 total time= 1.5min
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=perceptron, penalty=elasticnet;, score=0.620 total time= 1.4min
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=huber, penalty=l1;, score=0.632 total time= 1.8min
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=log, penalty=l2;, score=0.606 total time=  38.5s
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=log, penalty=l1;, score=0.591 total time= 1.9min
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_hinge, penalty=l1;, score=0.572 total time= 1.6min
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=perceptron, penalty=elasticnet;, score=0.585 total time= 1.3min
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_loss, penalty=elasticnet;, score=0.261 total time= 5.3min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=log, penalty=elasticnet;, score=0.597 total time= 7.6min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=perceptron, penalty=l2;, score=0.582 total time=  46.8s
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_loss, penalty=l2;, score=0.272 total time=25.5min
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=squared_hinge, penalty=elasticnet;, score=0.657 total time= 1.9min
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=squared_loss, penalty=elasticnet;, score=0.661 total time=  29.3s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=huber, penalty=l2;, score=0.661 total time=  11.4s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=huber, penalty=l1;, score=0.661 total time=  17.8s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=huber, penalty=l1;, score=0.661 total time=  17.8s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=huber, penalty=elasticnet;, score=0.661 total time=  17.8s
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=hinge, penalty=l2;, score=0.661 total time= 1.1min
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=hinge, penalty=l1;, score=0.661 total time= 1.3min
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=hinge, penalty=l1;, score=0.661 total time= 1.4min
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=hinge, penalty=elasticnet;, score=0.661 total time= 1.5min
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=log, penalty=elasticnet;, score=0.661 total time= 1.1min
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=modified_huber, penalty=l2;, score=0.652 total time= 1.1min
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=modified_huber, penalty=elasticnet;, score=0.589 total time= 2.6min
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=squared_hinge, penalty=l1;, score=0.582 total time= 1.6min
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=squared_hinge, penalty=elasticnet;, score=0.660 total time= 2.3min
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=perceptron, penalty=elasticnet;, score=0.649 total time= 1.4min
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=squared_loss, penalty=l1;, score=0.269 total time=  33.7s
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=squared_loss, penalty=elasticnet;, score=0.661 total time= 1.7min
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=huber, penalty=elasticnet;, score=0.661 total time=  21.2s
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=hinge, penalty=l2;, score=0.661 total time= 1.5min
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=log, penalty=l2;, score=0.661 total time= 2.2min
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=log, penalty=l1;, score=0.661 total time= 3.7min
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=modified_huber, penalty=l2;, score=0.662 total time= 2.0min
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=modified_huber, penalty=elasticnet;, score=0.661 total time= 3.8min
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=perceptron, penalty=l2;, score=0.604 total time= 1.0min
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=perceptron, penalty=l1;, score=0.213 total time= 2.8min
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=perceptron, penalty=elasticnet;, score=0.661 total time= 2.7min
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=squared_loss, penalty=elasticnet;, score=0.661 total time= 4.0min
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=huber, penalty=elasticnet;, score=0.661 total time= 2.8min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=log, penalty=l1;, score=0.630 total time= 1.5min
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=perceptron, penalty=l2;, score=0.633 total time=  11.8s
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=perceptron, penalty=l1;, score=0.599 total time= 1.2min
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=hinge, penalty=l1;, score=0.623 total time= 1.3min
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=log, penalty=elasticnet;, score=0.639 total time= 1.6min
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=perceptron, penalty=elasticnet;, score=0.603 total time= 1.5min
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=huber, penalty=l1;, score=0.640 total time= 1.7min
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=hinge, penalty=elasticnet;, score=0.571 total time= 1.9min
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=modified_huber, penalty=l2;, score=0.572 total time=  15.7s
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=modified_huber, penalty=l1;, score=0.595 total time= 2.9min
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_loss, penalty=l1;, score=0.420 total time= 9.1min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_hinge, penalty=l2;, score=0.616 total time= 5.2min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=perceptron, penalty=elasticnet;, score=0.578 total time= 5.8min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=huber, penalty=l2;, score=0.584 total time= 2.4min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=huber, penalty=l1;, score=0.664 total time= 5.3min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=huber, penalty=elasticnet;, score=0.636 total time= 6.0min
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=modified_huber, penalty=l1;, score=0.661 total time=  19.8s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=modified_huber, penalty=elasticnet;, score=0.213 total time=  25.1s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=squared_hinge, penalty=l1;, score=0.559 total time= 1.3min
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=perceptron, penalty=elasticnet;, score=0.661 total time=  20.9s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=squared_loss, penalty=l2;, score=0.185 total time=  18.7s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=squared_loss, penalty=elasticnet;, score=0.445 total time=  37.3s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=huber, penalty=l1;, score=0.661 total time=  21.4s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=hinge, penalty=l2;, score=0.661 total time=  10.8s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=hinge, penalty=l1;, score=0.661 total time=  16.4s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=log, penalty=l2;, score=0.661 total time=  14.3s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=log, penalty=elasticnet;, score=0.661 total time=  19.8s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=modified_huber, penalty=l2;, score=0.661 total time=  22.3s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=modified_huber, penalty=elasticnet;, score=0.661 total time=  24.6s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=squared_hinge, penalty=l1;, score=0.513 total time=48.9min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=hinge, penalty=l2;, score=0.640 total time=  17.6s
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=modified_huber, penalty=l2;, score=0.467 total time=  11.7s
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=modified_huber, penalty=l1;, score=0.593 total time= 1.9min
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=squared_loss, penalty=elasticnet;, score=0.206 total time=  33.9s
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=hinge, penalty=elasticnet;, score=0.622 total time= 1.7min
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=modified_huber, penalty=elasticnet;, score=0.611 total time= 1.7min
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=squared_loss, penalty=l1;, score=0.245 total time=14.8min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=modified_huber, penalty=l2;, score=0.596 total time=  46.8s
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=modified_huber, penalty=l1;, score=0.615 total time= 6.0min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=perceptron, penalty=l2;, score=0.633 total time=  47.0s
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_loss, penalty=l1;, score=0.330 total time=74.0min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=hinge, penalty=elasticnet;, score=0.656 total time= 1.2min
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=squared_hinge, penalty=l2;, score=0.595 total time=  11.2s
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=squared_hinge, penalty=elasticnet;, score=0.563 total time= 1.1min
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=huber, penalty=l2;, score=0.219 total time=  11.5s
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=huber, penalty=l1;, score=0.555 total time= 2.5min
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=squared_hinge, penalty=l1;, score=0.639 total time= 1.5min
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=squared_loss, penalty=l1;, score=0.391 total time=11.2min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=log, penalty=l2;, score=0.605 total time= 2.3min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=log, penalty=l1;, score=0.632 total time= 7.0min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_hinge, penalty=elasticnet;, score=0.611 total time=20.4min
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=log, penalty=elasticnet;, score=0.661 total time=  21.5s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=modified_huber, penalty=l2;, score=0.661 total time=  11.4s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=modified_huber, penalty=l1;, score=0.126 total time=  16.4s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=squared_hinge, penalty=l2;, score=0.126 total time=  12.0s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=squared_hinge, penalty=l2;, score=0.661 total time=   9.6s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=squared_hinge, penalty=l1;, score=0.617 total time= 1.7min
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=squared_loss, penalty=l1;, score=0.428 total time=  30.4s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=huber, penalty=l2;, score=0.126 total time=  16.2s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=huber, penalty=l1;, score=0.661 total time=  21.0s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=huber, penalty=elasticnet;, score=0.661 total time=  20.4s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=hinge, penalty=elasticnet;, score=0.661 total time=  15.9s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=log, penalty=l2;, score=0.661 total time=  14.4s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=log, penalty=elasticnet;, score=0.661 total time=  19.8s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=modified_huber, penalty=l1;, score=0.661 total time=  25.3s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=modified_huber, penalty=elasticnet;, score=0.661 total time=  26.2s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=squared_hinge, penalty=l1;, score=0.521 total time=47.7min
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=huber, penalty=elasticnet;, score=0.661 total time= 2.2min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=log, penalty=elasticnet;, score=0.651 total time=  59.2s
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=modified_huber, penalty=elasticnet;, score=0.628 total time=  50.3s
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=perceptron, penalty=elasticnet;, score=0.543 total time= 1.6min
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=log, penalty=l1;, score=0.609 total time= 1.6min
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=squared_hinge, penalty=l1;, score=0.583 total time= 1.3min
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=squared_loss, penalty=l2;, score=0.325 total time= 1.8min
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=huber, penalty=elasticnet;, score=0.574 total time= 3.0min
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=modified_huber, penalty=l2;, score=0.603 total time=  14.1s
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=modified_huber, penalty=elasticnet;, score=0.613 total time= 1.7min
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=perceptron, penalty=l2;, score=0.557 total time=  14.3s
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=perceptron, penalty=l1;, score=0.548 total time= 2.2min
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=huber, penalty=l1;, score=0.621 total time= 1.7min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=hinge, penalty=elasticnet;, score=0.605 total time= 6.1min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_hinge, penalty=l1;, score=0.585 total time=16.9min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=huber, penalty=elasticnet;, score=0.644 total time= 6.2min
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=log, penalty=l2;, score=0.661 total time=  23.3s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=log, penalty=l1;, score=0.661 total time=  23.9s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=log, penalty=l1;, score=0.661 total time=  22.4s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=log, penalty=elasticnet;, score=0.661 total time=  23.2s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=modified_huber, penalty=l1;, score=0.661 total time=  20.4s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=modified_huber, penalty=elasticnet;, score=0.213 total time=  18.4s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=squared_hinge, penalty=l2;, score=0.126 total time=  13.3s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=squared_hinge, penalty=elasticnet;, score=0.661 total time=  26.2s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=perceptron, penalty=l2;, score=0.661 total time=  12.9s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=perceptron, penalty=l2;, score=0.661 total time=   8.2s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=perceptron, penalty=l1;, score=0.213 total time=  17.5s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=perceptron, penalty=elasticnet;, score=0.661 total time=  24.2s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=squared_loss, penalty=l2;, score=0.193 total time=  13.3s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=squared_loss, penalty=l1;, score=0.444 total time=  30.1s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=huber, penalty=l2;, score=0.657 total time=  13.1s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=huber, penalty=l1;, score=0.661 total time=  19.3s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=hinge, penalty=l2;, score=0.661 total time=  10.2s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=hinge, penalty=l1;, score=0.661 total time=  15.5s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=hinge, penalty=elasticnet;, score=0.661 total time=  15.6s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=log, penalty=l1;, score=0.661 total time=  20.2s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=modified_huber, penalty=l2;, score=0.663 total time=  20.7s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=modified_huber, penalty=l1;, score=0.661 total time=  22.7s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=squared_hinge, penalty=l2;, score=0.563 total time= 7.2min
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=hinge, penalty=elasticnet;, score=0.661 total time= 1.3min
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=log, penalty=l2;, score=0.657 total time=  50.9s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=log, penalty=l1;, score=0.661 total time=  53.2s
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=log, penalty=elasticnet;, score=0.661 total time= 1.1min
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=modified_huber, penalty=l1;, score=0.604 total time= 2.8min
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=squared_hinge, penalty=l2;, score=0.633 total time=  50.7s
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=squared_hinge, penalty=elasticnet;, score=0.661 total time= 2.2min
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=perceptron, penalty=l1;, score=0.661 total time= 1.4min
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=perceptron, penalty=elasticnet;, score=0.661 total time= 1.3min
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=squared_loss, penalty=l1;, score=0.298 total time= 3.8min
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=hinge, penalty=elasticnet;, score=0.661 total time= 2.7min
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=log, penalty=elasticnet;, score=0.661 total time= 3.5min
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=modified_huber, penalty=l1;, score=0.661 total time= 3.8min
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=squared_hinge, penalty=l1;, score=0.601 total time=20.6min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=log, penalty=l2;, score=0.587 total time=  24.5s
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=modified_huber, penalty=l2;, score=0.550 total time=  12.4s
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=modified_huber, penalty=elasticnet;, score=0.628 total time=  50.1s
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=squared_hinge, penalty=elasticnet;, score=0.503 total time=  39.4s
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=squared_loss, penalty=l2;, score=0.503 total time=  11.5s
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=squared_loss, penalty=elasticnet;, score=0.216 total time=  33.7s
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=hinge, penalty=l1;, score=0.586 total time= 1.4min
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=modified_huber, penalty=l2;, score=0.577 total time=  15.9s
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=modified_huber, penalty=l1;, score=0.599 total time= 1.7min
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=perceptron, penalty=elasticnet;, score=0.623 total time= 1.6min
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=huber, penalty=elasticnet;, score=0.629 total time= 2.7min
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=log, penalty=elasticnet;, score=0.566 total time= 1.8min
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_hinge, penalty=elasticnet;, score=0.580 total time= 1.4min
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_loss, penalty=l2;, score=0.316 total time= 1.3min
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=huber, penalty=l2;, score=0.582 total time=  47.5s
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=huber, penalty=elasticnet;, score=0.592 total time= 2.3min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=log, penalty=l1;, score=0.580 total time= 6.9min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_hinge, penalty=l1;, score=0.613 total time= 8.0min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_loss, penalty=l1;, score=0.360 total time=78.3min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=hinge, penalty=l2;, score=0.634 total time=  15.3s
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=log, penalty=elasticnet;, score=0.480 total time=  58.3s
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=squared_hinge, penalty=l2;, score=0.659 total time=  12.1s
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=squared_hinge, penalty=elasticnet;, score=0.526 total time=  40.0s
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=squared_loss, penalty=l2;, score=0.263 total time=  11.4s
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=squared_loss, penalty=l1;, score=0.180 total time=  30.4s
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=hinge, penalty=l2;, score=0.619 total time=  15.4s
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=log, penalty=l2;, score=0.615 total time=  31.6s
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=log, penalty=elasticnet;, score=0.611 total time= 1.6min
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=squared_hinge, penalty=elasticnet;, score=0.587 total time= 1.6min
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=squared_loss, penalty=elasticnet;, score=0.206 total time= 8.0min
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_loss, penalty=elasticnet;, score=0.234 total time= 6.4min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=modified_huber, penalty=l2;, score=0.606 total time=  54.1s
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=modified_huber, penalty=l1;, score=0.620 total time= 6.1min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=perceptron, penalty=l1;, score=0.602 total time= 5.4min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_loss, penalty=elasticnet;, score=0.315 total time=81.5min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=log, penalty=l1;, score=0.608 total time= 1.8min
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=perceptron, penalty=l1;, score=0.646 total time= 1.3min
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=log, penalty=l2;, score=0.645 total time=  30.8s
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=log, penalty=elasticnet;, score=0.620 total time= 1.7min
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=perceptron, penalty=l2;, score=0.565 total time=  11.9s
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=perceptron, penalty=l2;, score=0.637 total time=  13.3s
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=perceptron, penalty=l1;, score=0.635 total time= 1.1min
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=huber, penalty=l2;, score=0.601 total time= 1.6min
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=hinge, penalty=l2;, score=0.579 total time=  16.7s
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=hinge, penalty=l2;, score=0.629 total time=  15.5s
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=hinge, penalty=l1;, score=0.609 total time= 2.4min
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_hinge, penalty=l2;, score=0.570 total time=  11.4s
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_hinge, penalty=l2;, score=0.593 total time=  16.6s
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_hinge, penalty=l2;, score=0.596 total time=  15.0s
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_hinge, penalty=l1;, score=0.608 total time= 2.1min
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_loss, penalty=l1;, score=0.258 total time= 7.3min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=modified_huber, penalty=l2;, score=0.627 total time=  46.4s
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=modified_huber, penalty=l1;, score=0.621 total time= 6.1min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=perceptron, penalty=l1;, score=0.616 total time= 5.4min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_loss, penalty=elasticnet;, score=0.321 total time=83.0min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=log, penalty=l2;, score=0.629 total time=  32.1s
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=modified_huber, penalty=l1;, score=0.617 total time= 1.7min
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=squared_loss, penalty=l1;, score=0.460 total time=  30.1s
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=hinge, penalty=l2;, score=0.610 total time=  12.4s
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=hinge, penalty=elasticnet;, score=0.612 total time= 1.8min
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=squared_hinge, penalty=l2;, score=0.599 total time=  16.7s
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=squared_hinge, penalty=l1;, score=0.632 total time= 1.8min
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=squared_loss, penalty=elasticnet;, score=0.379 total time= 2.2min
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=hinge, penalty=elasticnet;, score=0.604 total time= 1.7min
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=log, penalty=elasticnet;, score=0.618 total time= 1.7min
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_hinge, penalty=elasticnet;, score=0.592 total time= 1.5min
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_loss, penalty=l2;, score=0.379 total time= 3.1min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=hinge, penalty=l1;, score=0.613 total time= 6.0min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_hinge, penalty=l2;, score=0.600 total time= 5.5min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=perceptron, penalty=elasticnet;, score=0.609 total time= 5.5min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_loss, penalty=elasticnet;, score=0.251 total time=83.0min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=hinge, penalty=l1;, score=0.578 total time= 1.3min
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=squared_hinge, penalty=l1;, score=0.628 total time= 1.2min
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=huber, penalty=l2;, score=0.272 total time=  11.4s
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=huber, penalty=elasticnet;, score=0.525 total time=  34.2s
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=log, penalty=l1;, score=0.592 total time= 1.7min
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=squared_hinge, penalty=l2;, score=0.637 total time=  15.7s
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=squared_hinge, penalty=elasticnet;, score=0.613 total time= 1.7min
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=huber, penalty=l2;, score=0.578 total time= 1.4min
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=huber, penalty=elasticnet;, score=0.626 total time= 2.9min
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=modified_huber, penalty=l1;, score=0.594 total time= 3.8min
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=huber, penalty=l2;, score=0.622 total time=  49.7s
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=hinge, penalty=l2;, score=0.607 total time=  44.9s
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=hinge, penalty=l1;, score=0.596 total time= 5.6min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=modified_huber, penalty=elasticnet;, score=0.585 total time= 5.9min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=perceptron, penalty=l1;, score=0.602 total time= 5.3min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_loss, penalty=l1;, score=0.375 total time=53.0min
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=squared_hinge, penalty=l2;, score=0.662 total time= 1.9min
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=squared_hinge, penalty=elasticnet;, score=0.661 total time= 3.9min
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=perceptron, penalty=elasticnet;, score=0.661 total time= 2.8min
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=squared_loss, penalty=l1;, score=0.285 total time=34.2min
saving: SGD_summary_and_desc_1637325224 as png
Fitting 3 folds for each of 24 candidates, totalling 72 fits
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=hinge, penalty=elasticnet;, score=0.660 total time=  51.2s
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=modified_huber, penalty=elasticnet;, score=0.495 total time=  56.8s
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=perceptron, penalty=elasticnet;, score=0.510 total time= 1.0min
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=hinge, penalty=l2;, score=0.640 total time=  13.6s
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=log, penalty=l2;, score=0.592 total time=  30.4s
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=log, penalty=l1;, score=0.622 total time= 2.1min
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=perceptron, penalty=l1;, score=0.625 total time= 1.5min
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=huber, penalty=l1;, score=0.612 total time= 2.0min
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=hinge, penalty=elasticnet;, score=0.620 total time= 1.9min
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=modified_huber, penalty=l2;, score=0.594 total time=  16.4s
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=modified_huber, penalty=elasticnet;, score=0.575 total time= 2.1min
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=perceptron, penalty=elasticnet;, score=0.558 total time= 2.1min
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=huber, penalty=elasticnet;, score=0.605 total time= 2.5min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=log, penalty=l2;, score=0.613 total time= 2.2min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=log, penalty=elasticnet;, score=0.621 total time= 7.4min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=perceptron, penalty=l2;, score=0.610 total time=  46.1s
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=perceptron, penalty=elasticnet;, score=0.626 total time= 5.5min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=huber, penalty=l2;, score=0.595 total time= 2.5min
[CV 1/3] END alpha=1e-05, learning_rate=adaptive, loss=huber, penalty=l1;, score=0.657 total time= 5.5min
[CV 3/3] END alpha=1e-05, learning_rate=adaptive, loss=huber, penalty=elasticnet;, score=0.639 total time= 6.8min
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=squared_hinge, penalty=elasticnet;, score=0.661 total time=  18.5s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=squared_hinge, penalty=elasticnet;, score=0.213 total time=  17.3s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=perceptron, penalty=l2;, score=0.661 total time=  10.8s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=perceptron, penalty=l1;, score=0.661 total time=  17.1s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=perceptron, penalty=l1;, score=0.213 total time=  24.8s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=squared_loss, penalty=l2;, score=0.190 total time=  16.3s
[CV 1/3] END alpha=0.05, learning_rate=constant, loss=squared_loss, penalty=elasticnet;, score=0.180 total time=  31.1s
[CV 3/3] END alpha=0.05, learning_rate=constant, loss=huber, penalty=l2;, score=0.126 total time=  18.0s
[CV 2/3] END alpha=0.05, learning_rate=constant, loss=huber, penalty=elasticnet;, score=0.661 total time=  27.4s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=hinge, penalty=l1;, score=0.661 total time=  16.3s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=log, penalty=l2;, score=0.661 total time=  14.7s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=log, penalty=l1;, score=0.661 total time=  20.7s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=modified_huber, penalty=l2;, score=0.660 total time=  20.8s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=modified_huber, penalty=elasticnet;, score=0.661 total time=  25.7s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=squared_hinge, penalty=l2;, score=0.656 total time=  39.6s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=squared_hinge, penalty=elasticnet;, score=0.577 total time=22.3min
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=hinge, penalty=l1;, score=0.661 total time= 2.8min
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=log, penalty=l2;, score=0.661 total time= 2.3min
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=modified_huber, penalty=l2;, score=0.663 total time= 2.1min
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=modified_huber, penalty=elasticnet;, score=0.661 total time= 3.8min
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=squared_hinge, penalty=elasticnet;, score=0.661 total time= 4.0min
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=perceptron, penalty=elasticnet;, score=0.571 total time= 2.8min
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=squared_loss, penalty=l1;, score=0.302 total time=39.6min
[CV 1/3] END activation=tanh, alpha=0.0001, learning_rate=constant, solver=sgd;, score=0.640 total time=87.9min
[CV 2/3] END activation=relu, alpha=0.0001, learning_rate=adaptive, solver=adam;, score=0.607 total time=10.5min
[CV 3/3] END activation=relu, alpha=0.05, learning_rate=constant, solver=adam;, score=0.648 total time= 9.9min
[CV 1/3] END activation=relu, alpha=0.05, learning_rate=adaptive, solver=adam;, score=0.623 total time= 8.7min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
[CV 3/3] END activation=tanh, alpha=0.0001, learning_rate=constant, solver=lbfgs;, score=0.623 total time= 3.7min
[CV 2/3] END activation=tanh, alpha=0.0001, learning_rate=adaptive, solver=lbfgs;, score=0.625 total time= 5.1min
[CV 2/3] END activation=tanh, alpha=0.05, learning_rate=constant, solver=adam;, score=0.617 total time= 7.6min
[CV 1/3] END activation=tanh, alpha=0.05, learning_rate=adaptive, solver=adam;, score=0.614 total time= 7.3min
[CV 3/3] END activation=tanh, alpha=0.05, learning_rate=adaptive, solver=lbfgs;, score=0.555 total time= 7.1min
[CV 3/3] END activation=relu, alpha=0.0001, learning_rate=constant, solver=sgd;, score=0.669 total time=88.3min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
[CV 2/3] END activation=tanh, alpha=0.0001, learning_rate=constant, solver=adam;, score=0.606 total time= 9.7min
[CV 1/3] END activation=tanh, alpha=0.05, learning_rate=adaptive, solver=sgd;, score=0.643 total time=88.9min
[CV 1/3] END activation=relu, alpha=0.05, learning_rate=constant, solver=lbfgs;, score=0.518 total time=12.2min
[CV 3/3] END activation=relu, alpha=0.05, learning_rate=adaptive, solver=adam;, score=0.643 total time= 9.2min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
[CV 1/3] END activation=tanh, alpha=0.0001, learning_rate=adaptive, solver=lbfgs;, score=0.605 total time= 5.0min
[CV 1/3] END activation=tanh, alpha=0.05, learning_rate=constant, solver=sgd;, score=0.643 total time=89.4min
[CV 3/3] END activation=relu, alpha=0.0001, learning_rate=adaptive, solver=lbfgs;, score=0.633 total time= 4.3min
[CV 2/3] END activation=relu, alpha=0.05, learning_rate=constant, solver=lbfgs;, score=0.609 total time=11.3min
[CV 2/3] END activation=relu, alpha=0.05, learning_rate=adaptive, solver=adam;, score=0.628 total time=10.4min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
[CV 2/3] END activation=tanh, alpha=0.0001, learning_rate=adaptive, solver=adam;, score=0.606 total time= 8.9min
[CV 2/3] END activation=tanh, alpha=0.05, learning_rate=constant, solver=lbfgs;, score=0.603 total time= 8.1min
[CV 3/3] END activation=tanh, alpha=0.05, learning_rate=adaptive, solver=adam;, score=0.650 total time= 7.8min
[CV 1/3] END activation=relu, alpha=0.0001, learning_rate=constant, solver=sgd;, score=0.644 total time=88.4min
[CV 1/3] END activation=relu, alpha=0.05, learning_rate=adaptive, solver=lbfgs;, score=0.542 total time= 9.2min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
[CV 1/3] END activation=tanh, alpha=0.0001, learning_rate=constant, solver=adam;, score=0.603 total time= 8.4min
[CV 1/3] END activation=tanh, alpha=0.05, learning_rate=constant, solver=adam;, score=0.617 total time= 7.5min
[CV 3/3] END activation=tanh, alpha=0.05, learning_rate=adaptive, solver=sgd;, score=0.665 total time=88.1min
[CV 3/3] END activation=relu, alpha=0.05, learning_rate=constant, solver=lbfgs;, score=0.545 total time= 9.5min
[CV 2/3] END activation=relu, alpha=0.05, learning_rate=adaptive, solver=lbfgs;, score=0.606 total time=12.5min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
[CV 1/3] END activation=tanh, alpha=0.0001, learning_rate=adaptive, solver=adam;, score=0.601 total time= 8.8min
[CV 3/3] END activation=tanh, alpha=0.05, learning_rate=constant, solver=adam;, score=0.641 total time= 9.8min
[CV 1/3] END activation=tanh, alpha=0.05, learning_rate=adaptive, solver=lbfgs;, score=0.565 total time= 7.9min
[CV 2/3] END activation=relu, alpha=0.0001, learning_rate=constant, solver=sgd;, score=0.651 total time=87.9min
[CV 3/3] END activation=relu, alpha=0.05, learning_rate=adaptive, solver=lbfgs;, score=0.534 total time=13.3min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
[CV 3/3] END activation=tanh, alpha=0.0001, learning_rate=adaptive, solver=adam;, score=0.620 total time= 9.7min
[CV 3/3] END activation=tanh, alpha=0.05, learning_rate=constant, solver=lbfgs;, score=0.564 total time= 7.0min
[CV 2/3] END activation=tanh, alpha=0.05, learning_rate=adaptive, solver=adam;, score=0.614 total time= 6.7min
[CV 2/3] END activation=tanh, alpha=0.05, learning_rate=adaptive, solver=lbfgs;, score=0.612 total time= 9.2min
[CV 1/3] END activation=relu, alpha=0.0001, learning_rate=constant, solver=adam;, score=0.597 total time= 8.0min
[CV 2/3] END activation=relu, alpha=0.0001, learning_rate=constant, solver=adam;, score=0.612 total time= 8.3min
[CV 3/3] END activation=relu, alpha=0.0001, learning_rate=constant, solver=adam;, score=0.624 total time= 8.0min
[CV 1/3] END activation=relu, alpha=0.0001, learning_rate=constant, solver=lbfgs;, score=0.599 total time= 6.4min
[CV 2/3] END activation=relu, alpha=0.0001, learning_rate=constant, solver=lbfgs;, score=0.626 total time= 6.0min
[CV 3/3] END activation=relu, alpha=0.0001, learning_rate=constant, solver=lbfgs;, score=0.613 total time= 8.6min
[CV 1/3] END activation=relu, alpha=0.0001, learning_rate=adaptive, solver=sgd;, score=0.642 total time=67.1min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
[CV 1/3] END activation=tanh, alpha=0.0001, learning_rate=adaptive, solver=sgd;, score=0.648 total time=86.9min
[CV 3/3] END activation=relu, alpha=0.0001, learning_rate=adaptive, solver=sgd;, score=0.669 total time=64.0min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
[CV 3/3] END activation=tanh, alpha=0.0001, learning_rate=constant, solver=sgd;, score=0.666 total time=86.7min
[CV 2/3] END activation=relu, alpha=0.0001, learning_rate=adaptive, solver=sgd;, score=0.647 total time=66.9min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=hinge, penalty=l1;, score=0.588 total time= 1.5min
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=perceptron, penalty=l2;, score=0.630 total time=   9.2s
[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=perceptron, penalty=l2;, score=0.618 total time=   9.8s
[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=perceptron, penalty=elasticnet;, score=0.582 total time=  51.7s
[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=huber, penalty=elasticnet;, score=0.415 total time= 2.7min
[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=perceptron, penalty=l2;, score=0.634 total time=  14.3s
[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=perceptron, penalty=l1;, score=0.585 total time= 1.4min
[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=huber, penalty=l2;, score=0.623 total time= 1.6min
[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=hinge, penalty=l2;, score=0.583 total time=  17.3s
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=hinge, penalty=l1;, score=0.583 total time= 2.3min
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=modified_huber, penalty=l1;, score=0.563 total time= 2.5min
[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=perceptron, penalty=elasticnet;, score=0.601 total time= 1.5min
[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=huber, penalty=l1;, score=0.609 total time= 1.7min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=hinge, penalty=l1;, score=0.608 total time= 5.5min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=modified_huber, penalty=elasticnet;, score=0.608 total time= 6.4min
[CV 2/3] END alpha=1e-05, learning_rate=adaptive, loss=squared_loss, penalty=l2;, score=0.297 total time=25.5min
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=perceptron, penalty=l2;, score=0.570 total time=   6.3s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=perceptron, penalty=l2;, score=0.642 total time=   6.3s
[CV 2/3] END alpha=0.05, learning_rate=optimal, loss=perceptron, penalty=l1;, score=0.213 total time=  15.3s
[CV 1/3] END alpha=0.05, learning_rate=optimal, loss=perceptron, penalty=elasticnet;, score=0.213 total time=  15.2s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=perceptron, penalty=elasticnet;, score=0.653 total time=  15.2s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=squared_loss, penalty=l2;, score=0.660 total time=  16.5s
[CV 3/3] END alpha=0.05, learning_rate=optimal, loss=squared_loss, penalty=l1;, score=0.620 total time= 8.1min
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=modified_huber, penalty=l2;, score=0.590 total time= 1.3min
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=modified_huber, penalty=elasticnet;, score=0.662 total time= 2.2min
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=squared_hinge, penalty=l2;, score=0.659 total time= 1.1min
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=squared_hinge, penalty=l1;, score=0.616 total time= 1.4min
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=perceptron, penalty=l2;, score=0.509 total time=  41.0s
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=perceptron, penalty=l2;, score=0.651 total time=  41.5s
[CV 1/3] END alpha=0.05, learning_rate=invscaling, loss=perceptron, penalty=elasticnet;, score=0.546 total time= 1.2min
[CV 3/3] END alpha=0.05, learning_rate=invscaling, loss=squared_loss, penalty=l2;, score=0.660 total time= 1.3min
[CV 2/3] END alpha=0.05, learning_rate=invscaling, loss=squared_loss, penalty=elasticnet;, score=0.661 total time= 2.0min
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=hinge, penalty=l2;, score=0.661 total time= 1.4min
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=hinge, penalty=elasticnet;, score=0.661 total time= 2.7min
[CV 3/3] END alpha=0.05, learning_rate=adaptive, loss=log, penalty=l1;, score=0.661 total time= 3.7min
[CV 1/3] END alpha=0.05, learning_rate=adaptive, loss=modified_huber, penalty=l1;, score=0.661 total time= 3.9min
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=squared_hinge, penalty=l1;, score=0.617 total time= 7.2min
[CV 2/3] END alpha=0.05, learning_rate=adaptive, loss=squared_loss, penalty=l1;, score=0.321 total time=40.9min
[CV 2/3] END activation=tanh, alpha=0.0001, learning_rate=constant, solver=sgd;, score=0.645 total time=87.3min
[CV 1/3] END activation=relu, alpha=0.0001, learning_rate=adaptive, solver=adam;, score=0.598 total time= 8.3min
[CV 2/3] END activation=relu, alpha=0.05, learning_rate=constant, solver=sgd;, score=0.650 total time=60.1min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
[CV 3/3] END activation=tanh, alpha=0.0001, learning_rate=adaptive, solver=sgd;, score=0.663 total time=88.9min
[CV 1/3] END activation=relu, alpha=0.0001, learning_rate=adaptive, solver=lbfgs;, score=0.584 total time= 6.6min
[CV 1/3] END activation=relu, alpha=0.05, learning_rate=constant, solver=sgd;, score=0.644 total time=61.2min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
[CV 3/3] END activation=tanh, alpha=0.0001, learning_rate=constant, solver=adam;, score=0.631 total time= 8.2min
[CV 3/3] END activation=tanh, alpha=0.05, learning_rate=constant, solver=sgd;, score=0.667 total time=88.3min
[CV 1/3] END activation=relu, alpha=0.05, learning_rate=constant, solver=adam;, score=0.619 total time= 8.6min
[CV 2/3] END activation=relu, alpha=0.05, learning_rate=adaptive, solver=sgd;, score=0.647 total time=55.2min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
[CV 2/3] END activation=tanh, alpha=0.0001, learning_rate=constant, solver=lbfgs;, score=0.624 total time= 4.8min
[CV 3/3] END activation=tanh, alpha=0.0001, learning_rate=adaptive, solver=lbfgs;, score=0.642 total time= 4.1min
[CV 1/3] END activation=tanh, alpha=0.05, learning_rate=constant, solver=lbfgs;, score=0.578 total time= 6.2min
[CV 2/3] END activation=tanh, alpha=0.05, learning_rate=adaptive, solver=sgd;, score=0.642 total time=89.1min
[CV 1/3] END activation=relu, alpha=0.05, learning_rate=adaptive, solver=sgd;, score=0.645 total time=56.2min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
[CV 2/3] END activation=tanh, alpha=0.0001, learning_rate=adaptive, solver=sgd;, score=0.642 total time=87.9min
[CV 3/3] END activation=relu, alpha=0.0001, learning_rate=adaptive, solver=adam;, score=0.621 total time= 8.1min
[CV 3/3] END activation=relu, alpha=0.05, learning_rate=constant, solver=sgd;, score=0.664 total time=68.2min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
[CV 1/3] END activation=tanh, alpha=0.0001, learning_rate=constant, solver=lbfgs;, score=0.623 total time= 5.1min
[CV 2/3] END activation=tanh, alpha=0.05, learning_rate=constant, solver=sgd;, score=0.651 total time=84.3min
[CV 2/3] END activation=relu, alpha=0.0001, learning_rate=adaptive, solver=lbfgs;, score=0.630 total time= 8.0min
[CV 2/3] END activation=relu, alpha=0.05, learning_rate=constant, solver=adam;, score=0.628 total time= 9.5min
[CV 3/3] END activation=relu, alpha=0.05, learning_rate=adaptive, solver=sgd;, score=0.667 total time=62.0min
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/home/dries/pipeline/dries/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
saving: MLP_summary_and_desc_1637338629 as png
saving all
Saving to: summary_and_desc_k-Nearest Neighbour_model_container_454816.2859110345
Saving to: summary_and_desc_Guassian Naive Bayes_model_container_454816.2861284457
Saving to: summary_and_desc_Multinominal Naive Bayes_model_container_454816.28613622615
Saving to: summary_and_desc_Decision Tree_model_container_454816.28614387574
Saving to: summary_and_desc_Support Vector Machine (classifier)_model_container_454816.28615131835
Saving to: summary_and_desc_Stochastic Gradient Descent_model_container_454816.28633688355
Saving to: summary_and_desc_Multi-layer Perceptron_model_container_454816.28634452616
saving: summary_and_desc_comparison_1637338631 as png
saving: variation_model_performance as png
saving: overall_all_acc_over_variation as png
saving: overall_all_acc_over_time as png
saving: overall_all_acc_over_col_bar as png
saving: overall_all_acc_over_col_line as png
Index contains duplicate entries, cannot reshape
saving: overall_best_no_dt_acc_over_variation as png
saving: overall_best_no_dt_acc_over_time as png
saving: overall_best_no_dt_acc_over_col_bar as png
saving: overall_best_no_dt_acc_over_col_line as png
saving: overall_best_no_dt_acc_over_col_heatmap as png
Something went wrong while printing data distribution
saving: overall_variation_timings as png
